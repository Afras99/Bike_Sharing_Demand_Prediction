{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0iTRwAocrRmg"
      },
      "source": [
        "# Predict Bike Sharing Demand with AutoGluon Template"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oAYPzP_OrRmj"
      },
      "source": [
        "## Project: Predict Bike Sharing Demand with AutoGluon\n",
        "This notebook is a template with each step that you need to complete for the project.\n",
        "\n",
        "Please fill in your code where there are explicit `?` markers in the notebook. You are welcome to add more cells and code as you see fit.\n",
        "\n",
        "Once you have completed all the code implementations, please export your notebook as a HTML file so the reviews can view your code. Make sure you have all outputs correctly outputted.\n",
        "\n",
        "`File-> Export Notebook As... -> Export Notebook as HTML`\n",
        "\n",
        "There is a writeup to complete as well after all code implememtation is done. Please answer all questions and attach the necessary tables and charts. You can complete the writeup in either markdown or PDF.\n",
        "\n",
        "Completing the code template and writeup template will cover all of the rubric points for this project.\n",
        "\n",
        "The rubric contains \"Stand Out Suggestions\" for enhancing the project beyond the minimum requirements. The stand out suggestions are optional. If you decide to pursue the \"stand out suggestions\", you can include the code in this notebook and also discuss the results in the writeup file."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ERyimqgPrRmj"
      },
      "source": [
        "## Step 1: Create an account with Kaggle"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PKzI9Q--rRmk"
      },
      "source": [
        "### Create Kaggle Account and download API key\n",
        "Below is example of steps to get the API username and key. Each student will have their own username and key."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pEZdcUFhrRmk"
      },
      "source": [
        "1. Open account settings.\n",
        "2. Scroll down to API and click Create New API Token.\n",
        "3. Open up `kaggle.json` and use the username and key."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ktywMq9yrRmk"
      },
      "source": [
        "## Step 2: Download the Kaggle dataset using the kaggle python library"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u6NR7jhKrRmk"
      },
      "source": [
        "### Open up Sagemaker Studio and use starter template"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u0ickIwVrRmk"
      },
      "source": [
        "1. Notebook should be using a `ml.t3.medium` instance (2 vCPU + 4 GiB)\n",
        "2. Notebook should be using kernal: `Python 3 (MXNet 1.8 Python 3.7 CPU Optimized)`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cf3jWp1MrRmk"
      },
      "source": [
        "### Install packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t-ajZp0ZrRml",
        "outputId": "6e895665-a9ba-413b-f52c-236d7800dab8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pip in /usr/local/lib/python3.10/dist-packages (23.1.2)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (67.8.0)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (0.40.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: mxnet<2.0.0 in /usr/local/lib/python3.10/dist-packages (1.9.1)\n",
            "Requirement already satisfied: bokeh==2.0.1 in /usr/local/lib/python3.10/dist-packages (2.0.1)\n",
            "Requirement already satisfied: PyYAML>=3.10 in /usr/local/lib/python3.10/dist-packages (from bokeh==2.0.1) (6.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.10/dist-packages (from bokeh==2.0.1) (2.8.2)\n",
            "Requirement already satisfied: Jinja2>=2.7 in /usr/local/lib/python3.10/dist-packages (from bokeh==2.0.1) (3.1.2)\n",
            "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.10/dist-packages (from bokeh==2.0.1) (1.22.4)\n",
            "Requirement already satisfied: pillow>=4.0 in /usr/local/lib/python3.10/dist-packages (from bokeh==2.0.1) (9.5.0)\n",
            "Requirement already satisfied: packaging>=16.8 in /usr/local/lib/python3.10/dist-packages (from bokeh==2.0.1) (23.1)\n",
            "Requirement already satisfied: tornado>=5 in /usr/local/lib/python3.10/dist-packages (from bokeh==2.0.1) (6.3.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.10/dist-packages (from bokeh==2.0.1) (4.5.0)\n",
            "Requirement already satisfied: requests<3,>=2.20.0 in /usr/local/lib/python3.10/dist-packages (from mxnet<2.0.0) (2.27.1)\n",
            "Requirement already satisfied: graphviz<0.9.0,>=0.8.1 in /usr/local/lib/python3.10/dist-packages (from mxnet<2.0.0) (0.8.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from Jinja2>=2.7->bokeh==2.0.1) (2.1.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.1->bokeh==2.0.1) (1.16.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.20.0->mxnet<2.0.0) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.20.0->mxnet<2.0.0) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.20.0->mxnet<2.0.0) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.20.0->mxnet<2.0.0) (3.4)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: autogluon in /usr/local/lib/python3.10/dist-packages (0.7.0)\n",
            "Requirement already satisfied: autogluon.core[all]==0.7.0 in /usr/local/lib/python3.10/dist-packages (from autogluon) (0.7.0)\n",
            "Requirement already satisfied: autogluon.features==0.7.0 in /usr/local/lib/python3.10/dist-packages (from autogluon) (0.7.0)\n",
            "Requirement already satisfied: autogluon.tabular[all]==0.7.0 in /usr/local/lib/python3.10/dist-packages (from autogluon) (0.7.0)\n",
            "Requirement already satisfied: autogluon.multimodal==0.7.0 in /usr/local/lib/python3.10/dist-packages (from autogluon) (0.7.0)\n",
            "Requirement already satisfied: autogluon.timeseries[all]==0.7.0 in /usr/local/lib/python3.10/dist-packages (from autogluon) (0.7.0)\n",
            "Requirement already satisfied: numpy<1.27,>=1.21 in /usr/local/lib/python3.10/dist-packages (from autogluon.core[all]==0.7.0->autogluon) (1.22.4)\n",
            "Requirement already satisfied: scipy<1.12,>=1.5.4 in /usr/local/lib/python3.10/dist-packages (from autogluon.core[all]==0.7.0->autogluon) (1.10.1)\n",
            "Requirement already satisfied: scikit-learn<1.3,>=1.0 in /usr/local/lib/python3.10/dist-packages (from autogluon.core[all]==0.7.0->autogluon) (1.2.2)\n",
            "Requirement already satisfied: networkx<3.0,>=2.3 in /usr/local/lib/python3.10/dist-packages (from autogluon.core[all]==0.7.0->autogluon) (2.8.8)\n",
            "Requirement already satisfied: pandas<1.6,>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from autogluon.core[all]==0.7.0->autogluon) (1.5.3)\n",
            "Requirement already satisfied: tqdm<5,>=4.38 in /usr/local/lib/python3.10/dist-packages (from autogluon.core[all]==0.7.0->autogluon) (4.65.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from autogluon.core[all]==0.7.0->autogluon) (2.27.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from autogluon.core[all]==0.7.0->autogluon) (3.7.1)\n",
            "Requirement already satisfied: boto3<2,>=1.10 in /usr/local/lib/python3.10/dist-packages (from autogluon.core[all]==0.7.0->autogluon) (1.26.147)\n",
            "Requirement already satisfied: autogluon.common==0.7.0 in /usr/local/lib/python3.10/dist-packages (from autogluon.core[all]==0.7.0->autogluon) (0.7.0)\n",
            "Requirement already satisfied: hyperopt<0.2.8,>=0.2.7 in /usr/local/lib/python3.10/dist-packages (from autogluon.core[all]==0.7.0->autogluon) (0.2.7)\n",
            "Requirement already satisfied: ray[tune]<2.3,>=2.2 in /usr/local/lib/python3.10/dist-packages (from autogluon.core[all]==0.7.0->autogluon) (2.2.0)\n",
            "Requirement already satisfied: Pillow<9.6,>=9.3 in /usr/local/lib/python3.10/dist-packages (from autogluon.multimodal==0.7.0->autogluon) (9.5.0)\n",
            "Requirement already satisfied: jsonschema<4.18,>=4.14 in /usr/local/lib/python3.10/dist-packages (from autogluon.multimodal==0.7.0->autogluon) (4.17.3)\n",
            "Requirement already satisfied: seqeval<1.3.0,>=1.2.2 in /usr/local/lib/python3.10/dist-packages (from autogluon.multimodal==0.7.0->autogluon) (1.2.2)\n",
            "Requirement already satisfied: evaluate<0.4.0,>=0.2.2 in /usr/local/lib/python3.10/dist-packages (from autogluon.multimodal==0.7.0->autogluon) (0.3.0)\n",
            "Requirement already satisfied: accelerate<0.17,>=0.9 in /usr/local/lib/python3.10/dist-packages (from autogluon.multimodal==0.7.0->autogluon) (0.16.0)\n",
            "Requirement already satisfied: timm<0.7.0,>=0.6.12 in /usr/local/lib/python3.10/dist-packages (from autogluon.multimodal==0.7.0->autogluon) (0.6.13)\n",
            "Requirement already satisfied: torch<1.14,>=1.9 in /usr/local/lib/python3.10/dist-packages (from autogluon.multimodal==0.7.0->autogluon) (1.13.1)\n",
            "Requirement already satisfied: torchvision<0.15.0 in /usr/local/lib/python3.10/dist-packages (from autogluon.multimodal==0.7.0->autogluon) (0.14.1)\n",
            "Requirement already satisfied: fairscale<0.4.14,>=0.4.5 in /usr/local/lib/python3.10/dist-packages (from autogluon.multimodal==0.7.0->autogluon) (0.4.13)\n",
            "Requirement already satisfied: scikit-image<0.20.0,>=0.19.1 in /usr/local/lib/python3.10/dist-packages (from autogluon.multimodal==0.7.0->autogluon) (0.19.3)\n",
            "Requirement already satisfied: pytorch-lightning<1.10.0,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from autogluon.multimodal==0.7.0->autogluon) (1.9.5)\n",
            "Requirement already satisfied: text-unidecode<1.4,>=1.3 in /usr/local/lib/python3.10/dist-packages (from autogluon.multimodal==0.7.0->autogluon) (1.3)\n",
            "Requirement already satisfied: torchmetrics<0.9.0,>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from autogluon.multimodal==0.7.0->autogluon) (0.8.2)\n",
            "Requirement already satisfied: transformers<4.27.0,>=4.23.0 in /usr/local/lib/python3.10/dist-packages (from autogluon.multimodal==0.7.0->autogluon) (4.26.1)\n",
            "Requirement already satisfied: nptyping<2.5.0,>=1.4.4 in /usr/local/lib/python3.10/dist-packages (from autogluon.multimodal==0.7.0->autogluon) (2.4.1)\n",
            "Requirement already satisfied: omegaconf<2.3.0,>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from autogluon.multimodal==0.7.0->autogluon) (2.2.3)\n",
            "Requirement already satisfied: sentencepiece<0.2.0,>=0.1.95 in /usr/local/lib/python3.10/dist-packages (from autogluon.multimodal==0.7.0->autogluon) (0.1.99)\n",
            "Requirement already satisfied: pytorch-metric-learning<2.0,>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from autogluon.multimodal==0.7.0->autogluon) (1.7.3)\n",
            "Requirement already satisfied: nlpaug<1.2.0,>=1.1.10 in /usr/local/lib/python3.10/dist-packages (from autogluon.multimodal==0.7.0->autogluon) (1.1.11)\n",
            "Requirement already satisfied: nltk<4.0.0,>=3.4.5 in /usr/local/lib/python3.10/dist-packages (from autogluon.multimodal==0.7.0->autogluon) (3.8.1)\n",
            "Requirement already satisfied: openmim<0.4.0,>0.1.5 in /usr/local/lib/python3.10/dist-packages (from autogluon.multimodal==0.7.0->autogluon) (0.3.7)\n",
            "Requirement already satisfied: defusedxml<0.7.2,>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from autogluon.multimodal==0.7.0->autogluon) (0.7.1)\n",
            "Requirement already satisfied: jinja2<3.2,>=3.0.3 in /usr/local/lib/python3.10/dist-packages (from autogluon.multimodal==0.7.0->autogluon) (3.1.2)\n",
            "Requirement already satisfied: tensorboard<3,>=2.9 in /usr/local/lib/python3.10/dist-packages (from autogluon.multimodal==0.7.0->autogluon) (2.12.2)\n",
            "Requirement already satisfied: pytesseract<0.3.11,>=0.3.9 in /usr/local/lib/python3.10/dist-packages (from autogluon.multimodal==0.7.0->autogluon) (0.3.10)\n",
            "Requirement already satisfied: catboost<1.2,>=1.0 in /usr/local/lib/python3.10/dist-packages (from autogluon.tabular[all]==0.7.0->autogluon) (1.1.1)\n",
            "Requirement already satisfied: lightgbm<3.4,>=3.3 in /usr/local/lib/python3.10/dist-packages (from autogluon.tabular[all]==0.7.0->autogluon) (3.3.5)\n",
            "Requirement already satisfied: xgboost<1.8,>=1.6 in /usr/local/lib/python3.10/dist-packages (from autogluon.tabular[all]==0.7.0->autogluon) (1.7.5)\n",
            "Requirement already satisfied: fastai<2.8,>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from autogluon.tabular[all]==0.7.0->autogluon) (2.7.12)\n",
            "Requirement already satisfied: joblib<2,>=1.1 in /usr/local/lib/python3.10/dist-packages (from autogluon.timeseries[all]==0.7.0->autogluon) (1.2.0)\n",
            "Requirement already satisfied: statsmodels<0.14,>=0.13.0 in /usr/local/lib/python3.10/dist-packages (from autogluon.timeseries[all]==0.7.0->autogluon) (0.13.5)\n",
            "Requirement already satisfied: gluonts<0.13,>=0.12.0 in /usr/local/lib/python3.10/dist-packages (from autogluon.timeseries[all]==0.7.0->autogluon) (0.12.8)\n",
            "Requirement already satisfied: statsforecast<1.5,>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from autogluon.timeseries[all]==0.7.0->autogluon) (1.4.0)\n",
            "Requirement already satisfied: ujson<6,>=5 in /usr/local/lib/python3.10/dist-packages (from autogluon.timeseries[all]==0.7.0->autogluon) (5.7.0)\n",
            "Requirement already satisfied: sktime<0.16,>=0.14 in /usr/local/lib/python3.10/dist-packages (from autogluon.timeseries[all]==0.7.0->autogluon) (0.15.1)\n",
            "Requirement already satisfied: tbats<2,>=1.1 in /usr/local/lib/python3.10/dist-packages (from autogluon.timeseries[all]==0.7.0->autogluon) (1.1.3)\n",
            "Requirement already satisfied: pmdarima<1.9,>=1.8.2 in /usr/local/lib/python3.10/dist-packages (from autogluon.timeseries[all]==0.7.0->autogluon) (1.8.5)\n",
            "Requirement already satisfied: psutil<6,>=5.7.3 in /usr/local/lib/python3.10/dist-packages (from autogluon.common==0.7.0->autogluon.core[all]==0.7.0->autogluon) (5.9.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from autogluon.common==0.7.0->autogluon.core[all]==0.7.0->autogluon) (67.8.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate<0.17,>=0.9->autogluon.multimodal==0.7.0->autogluon) (23.1)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate<0.17,>=0.9->autogluon.multimodal==0.7.0->autogluon) (6.0)\n",
            "Requirement already satisfied: botocore<1.30.0,>=1.29.147 in /usr/local/lib/python3.10/dist-packages (from boto3<2,>=1.10->autogluon.core[all]==0.7.0->autogluon) (1.29.147)\n",
            "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from boto3<2,>=1.10->autogluon.core[all]==0.7.0->autogluon) (1.0.1)\n",
            "Requirement already satisfied: s3transfer<0.7.0,>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from boto3<2,>=1.10->autogluon.core[all]==0.7.0->autogluon) (0.6.1)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.10/dist-packages (from catboost<1.2,>=1.0->autogluon.tabular[all]==0.7.0->autogluon) (0.8.4)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.10/dist-packages (from catboost<1.2,>=1.0->autogluon.tabular[all]==0.7.0->autogluon) (5.13.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from catboost<1.2,>=1.0->autogluon.tabular[all]==0.7.0->autogluon) (1.16.0)\n",
            "Requirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from evaluate<0.4.0,>=0.2.2->autogluon.multimodal==0.7.0->autogluon) (2.12.0)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.10/dist-packages (from evaluate<0.4.0,>=0.2.2->autogluon.multimodal==0.7.0->autogluon) (0.3.6)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from evaluate<0.4.0,>=0.2.2->autogluon.multimodal==0.7.0->autogluon) (3.2.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from evaluate<0.4.0,>=0.2.2->autogluon.multimodal==0.7.0->autogluon) (0.70.14)\n",
            "Requirement already satisfied: fsspec[http]>=2021.05.0 in /usr/local/lib/python3.10/dist-packages (from evaluate<0.4.0,>=0.2.2->autogluon.multimodal==0.7.0->autogluon) (2023.4.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from evaluate<0.4.0,>=0.2.2->autogluon.multimodal==0.7.0->autogluon) (0.15.1)\n",
            "Requirement already satisfied: responses<0.19 in /usr/local/lib/python3.10/dist-packages (from evaluate<0.4.0,>=0.2.2->autogluon.multimodal==0.7.0->autogluon) (0.18.0)\n",
            "Requirement already satisfied: pip in /usr/local/lib/python3.10/dist-packages (from fastai<2.8,>=2.3.1->autogluon.tabular[all]==0.7.0->autogluon) (23.1.2)\n",
            "Requirement already satisfied: fastdownload<2,>=0.0.5 in /usr/local/lib/python3.10/dist-packages (from fastai<2.8,>=2.3.1->autogluon.tabular[all]==0.7.0->autogluon) (0.0.7)\n",
            "Requirement already satisfied: fastcore<1.6,>=1.5.29 in /usr/local/lib/python3.10/dist-packages (from fastai<2.8,>=2.3.1->autogluon.tabular[all]==0.7.0->autogluon) (1.5.29)\n",
            "Requirement already satisfied: fastprogress>=0.2.4 in /usr/local/lib/python3.10/dist-packages (from fastai<2.8,>=2.3.1->autogluon.tabular[all]==0.7.0->autogluon) (1.0.3)\n",
            "Requirement already satisfied: spacy<4 in /usr/local/lib/python3.10/dist-packages (from fastai<2.8,>=2.3.1->autogluon.tabular[all]==0.7.0->autogluon) (3.5.2)\n",
            "Requirement already satisfied: pydantic~=1.7 in /usr/local/lib/python3.10/dist-packages (from gluonts<0.13,>=0.12.0->autogluon.timeseries[all]==0.7.0->autogluon) (1.10.7)\n",
            "Requirement already satisfied: toolz~=0.10 in /usr/local/lib/python3.10/dist-packages (from gluonts<0.13,>=0.12.0->autogluon.timeseries[all]==0.7.0->autogluon) (0.12.0)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.10/dist-packages (from gluonts<0.13,>=0.12.0->autogluon.timeseries[all]==0.7.0->autogluon) (4.5.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.10/dist-packages (from hyperopt<0.2.8,>=0.2.7->autogluon.core[all]==0.7.0->autogluon) (0.18.3)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.10/dist-packages (from hyperopt<0.2.8,>=0.2.7->autogluon.core[all]==0.7.0->autogluon) (2.2.1)\n",
            "Requirement already satisfied: py4j in /usr/local/lib/python3.10/dist-packages (from hyperopt<0.2.8,>=0.2.7->autogluon.core[all]==0.7.0->autogluon) (0.10.9.7)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2<3.2,>=3.0.3->autogluon.multimodal==0.7.0->autogluon) (2.1.2)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema<4.18,>=4.14->autogluon.multimodal==0.7.0->autogluon) (23.1.0)\n",
            "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema<4.18,>=4.14->autogluon.multimodal==0.7.0->autogluon) (0.19.3)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (from lightgbm<3.4,>=3.3->autogluon.tabular[all]==0.7.0->autogluon) (0.40.0)\n",
            "Requirement already satisfied: gdown>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from nlpaug<1.2.0,>=1.1.10->autogluon.multimodal==0.7.0->autogluon) (4.6.6)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.4.5->autogluon.multimodal==0.7.0->autogluon) (8.1.3)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.4.5->autogluon.multimodal==0.7.0->autogluon) (2022.10.31)\n",
            "Requirement already satisfied: antlr4-python3-runtime==4.9.* in /usr/local/lib/python3.10/dist-packages (from omegaconf<2.3.0,>=2.1.1->autogluon.multimodal==0.7.0->autogluon) (4.9.3)\n",
            "Requirement already satisfied: colorama in /usr/local/lib/python3.10/dist-packages (from openmim<0.4.0,>0.1.5->autogluon.multimodal==0.7.0->autogluon) (0.4.6)\n",
            "Requirement already satisfied: model-index in /usr/local/lib/python3.10/dist-packages (from openmim<0.4.0,>0.1.5->autogluon.multimodal==0.7.0->autogluon) (0.1.11)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from openmim<0.4.0,>0.1.5->autogluon.multimodal==0.7.0->autogluon) (13.3.4)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.10/dist-packages (from openmim<0.4.0,>0.1.5->autogluon.multimodal==0.7.0->autogluon) (0.8.10)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas<1.6,>=1.4.1->autogluon.core[all]==0.7.0->autogluon) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<1.6,>=1.4.1->autogluon.core[all]==0.7.0->autogluon) (2022.7.1)\n",
            "Requirement already satisfied: Cython!=0.29.18,>=0.29 in /usr/local/lib/python3.10/dist-packages (from pmdarima<1.9,>=1.8.2->autogluon.timeseries[all]==0.7.0->autogluon) (0.29.34)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from pmdarima<1.9,>=1.8.2->autogluon.timeseries[all]==0.7.0->autogluon) (1.26.15)\n",
            "Requirement already satisfied: lightning-utilities>=0.6.0.post0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning<1.10.0,>=1.9.0->autogluon.multimodal==0.7.0->autogluon) (0.8.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from ray[tune]<2.3,>=2.2->autogluon.core[all]==0.7.0->autogluon) (3.12.0)\n",
            "Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from ray[tune]<2.3,>=2.2->autogluon.core[all]==0.7.0->autogluon) (1.0.5)\n",
            "Requirement already satisfied: protobuf!=3.19.5,>=3.15.3 in /usr/local/lib/python3.10/dist-packages (from ray[tune]<2.3,>=2.2->autogluon.core[all]==0.7.0->autogluon) (3.20.3)\n",
            "Requirement already satisfied: aiosignal in /usr/local/lib/python3.10/dist-packages (from ray[tune]<2.3,>=2.2->autogluon.core[all]==0.7.0->autogluon) (1.3.1)\n",
            "Requirement already satisfied: frozenlist in /usr/local/lib/python3.10/dist-packages (from ray[tune]<2.3,>=2.2->autogluon.core[all]==0.7.0->autogluon) (1.3.3)\n",
            "Requirement already satisfied: virtualenv>=20.0.24 in /usr/local/lib/python3.10/dist-packages (from ray[tune]<2.3,>=2.2->autogluon.core[all]==0.7.0->autogluon) (20.23.0)\n",
            "Requirement already satisfied: grpcio>=1.42.0 in /usr/local/lib/python3.10/dist-packages (from ray[tune]<2.3,>=2.2->autogluon.core[all]==0.7.0->autogluon) (1.54.0)\n",
            "Requirement already satisfied: tensorboardX>=1.9 in /usr/local/lib/python3.10/dist-packages (from ray[tune]<2.3,>=2.2->autogluon.core[all]==0.7.0->autogluon) (2.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->autogluon.core[all]==0.7.0->autogluon) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->autogluon.core[all]==0.7.0->autogluon) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->autogluon.core[all]==0.7.0->autogluon) (3.4)\n",
            "Requirement already satisfied: imageio>=2.4.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image<0.20.0,>=0.19.1->autogluon.multimodal==0.7.0->autogluon) (2.25.1)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.10/dist-packages (from scikit-image<0.20.0,>=0.19.1->autogluon.multimodal==0.7.0->autogluon) (2023.4.12)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image<0.20.0,>=0.19.1->autogluon.multimodal==0.7.0->autogluon) (1.4.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn<1.3,>=1.0->autogluon.core[all]==0.7.0->autogluon) (3.1.0)\n",
            "Requirement already satisfied: deprecated>=1.2.13 in /usr/local/lib/python3.10/dist-packages (from sktime<0.16,>=0.14->autogluon.timeseries[all]==0.7.0->autogluon) (1.2.14)\n",
            "Requirement already satisfied: numba>=0.55 in /usr/local/lib/python3.10/dist-packages (from sktime<0.16,>=0.14->autogluon.timeseries[all]==0.7.0->autogluon) (0.56.4)\n",
            "Requirement already satisfied: patsy>=0.5.2 in /usr/local/lib/python3.10/dist-packages (from statsmodels<0.14,>=0.13.0->autogluon.timeseries[all]==0.7.0->autogluon) (0.5.3)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard<3,>=2.9->autogluon.multimodal==0.7.0->autogluon) (1.4.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<3,>=2.9->autogluon.multimodal==0.7.0->autogluon) (2.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<3,>=2.9->autogluon.multimodal==0.7.0->autogluon) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<3,>=2.9->autogluon.multimodal==0.7.0->autogluon) (3.4.3)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<3,>=2.9->autogluon.multimodal==0.7.0->autogluon) (0.7.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<3,>=2.9->autogluon.multimodal==0.7.0->autogluon) (1.8.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<3,>=2.9->autogluon.multimodal==0.7.0->autogluon) (2.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /usr/local/lib/python3.10/dist-packages (from torch<1.14,>=1.9->autogluon.multimodal==0.7.0->autogluon) (11.7.99)\n",
            "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /usr/local/lib/python3.10/dist-packages (from torch<1.14,>=1.9->autogluon.multimodal==0.7.0->autogluon) (8.5.0.96)\n",
            "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /usr/local/lib/python3.10/dist-packages (from torch<1.14,>=1.9->autogluon.multimodal==0.7.0->autogluon) (11.10.3.66)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /usr/local/lib/python3.10/dist-packages (from torch<1.14,>=1.9->autogluon.multimodal==0.7.0->autogluon) (11.7.99)\n",
            "Requirement already satisfied: pyDeprecate==0.3.* in /usr/local/lib/python3.10/dist-packages (from torchmetrics<0.9.0,>=0.8.0->autogluon.multimodal==0.7.0->autogluon) (0.3.2)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers<4.27.0,>=4.23.0->autogluon.multimodal==0.7.0->autogluon) (0.13.3)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->autogluon.core[all]==0.7.0->autogluon) (1.0.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->autogluon.core[all]==0.7.0->autogluon) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->autogluon.core[all]==0.7.0->autogluon) (4.39.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->autogluon.core[all]==0.7.0->autogluon) (1.4.4)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->autogluon.core[all]==0.7.0->autogluon) (3.0.9)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate<0.4.0,>=0.2.2->autogluon.multimodal==0.7.0->autogluon) (9.0.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate<0.4.0,>=0.2.2->autogluon.multimodal==0.7.0->autogluon) (3.8.4)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.10/dist-packages (from deprecated>=1.2.13->sktime<0.16,>=0.14->autogluon.timeseries[all]==0.7.0->autogluon) (1.14.1)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from gdown>=4.0.0->nlpaug<1.2.0,>=1.1.10->autogluon.multimodal==0.7.0->autogluon) (4.11.2)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<3,>=2.9->autogluon.multimodal==0.7.0->autogluon) (5.3.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<3,>=2.9->autogluon.multimodal==0.7.0->autogluon) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<3,>=2.9->autogluon.multimodal==0.7.0->autogluon) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<3,>=2.9->autogluon.multimodal==0.7.0->autogluon) (1.3.1)\n",
            "Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.55->sktime<0.16,>=0.14->autogluon.timeseries[all]==0.7.0->autogluon) (0.39.1)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==0.7.0->autogluon) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==0.7.0->autogluon) (1.0.4)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==0.7.0->autogluon) (1.0.9)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==0.7.0->autogluon) (2.0.7)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==0.7.0->autogluon) (3.0.8)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /usr/local/lib/python3.10/dist-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==0.7.0->autogluon) (8.1.9)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==0.7.0->autogluon) (1.1.1)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==0.7.0->autogluon) (2.4.6)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==0.7.0->autogluon) (2.0.8)\n",
            "Requirement already satisfied: typer<0.8.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==0.7.0->autogluon) (0.7.0)\n",
            "Requirement already satisfied: pathy>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==0.7.0->autogluon) (0.10.1)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==0.7.0->autogluon) (6.3.0)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==0.7.0->autogluon) (3.3.0)\n",
            "Requirement already satisfied: distlib<1,>=0.3.6 in /usr/local/lib/python3.10/dist-packages (from virtualenv>=20.0.24->ray[tune]<2.3,>=2.2->autogluon.core[all]==0.7.0->autogluon) (0.3.6)\n",
            "Requirement already satisfied: platformdirs<4,>=3.2 in /usr/local/lib/python3.10/dist-packages (from virtualenv>=20.0.24->ray[tune]<2.3,>=2.2->autogluon.core[all]==0.7.0->autogluon) (3.3.0)\n",
            "Requirement already satisfied: ordered-set in /usr/local/lib/python3.10/dist-packages (from model-index->openmim<0.4.0,>0.1.5->autogluon.multimodal==0.7.0->autogluon) (4.1.0)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from plotly->catboost<1.2,>=1.0->autogluon.tabular[all]==0.7.0->autogluon) (8.2.2)\n",
            "Requirement already satisfied: markdown-it-py<3.0.0,>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->openmim<0.4.0,>0.1.5->autogluon.multimodal==0.7.0->autogluon) (2.2.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->openmim<0.4.0,>0.1.5->autogluon.multimodal==0.7.0->autogluon) (2.14.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate<0.4.0,>=0.2.2->autogluon.multimodal==0.7.0->autogluon) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate<0.4.0,>=0.2.2->autogluon.multimodal==0.7.0->autogluon) (4.0.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate<0.4.0,>=0.2.2->autogluon.multimodal==0.7.0->autogluon) (1.9.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py<3.0.0,>=2.2.0->rich->openmim<0.4.0,>0.1.5->autogluon.multimodal==0.7.0->autogluon) (0.1.2)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<3,>=2.9->autogluon.multimodal==0.7.0->autogluon) (0.5.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<3,>=2.9->autogluon.multimodal==0.7.0->autogluon) (3.2.2)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==0.7.0->autogluon) (0.7.9)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==0.7.0->autogluon) (0.0.4)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->gdown>=4.0.0->nlpaug<1.2.0,>=1.1.10->autogluon.multimodal==0.7.0->autogluon) (2.4.1)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from requests->autogluon.core[all]==0.7.0->autogluon) (1.7.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install -U pip\n",
        "!pip install -U setuptools wheel\n",
        "!pip install -U \"mxnet<2.0.0\" bokeh==2.0.1\n",
        "!pip install autogluon --no-cache-dir\n",
        "# Without --no-cache-dir, smaller aws instances may have trouble installing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CQrMrnGbrRmm"
      },
      "source": [
        "### Setup Kaggle API Key"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PsKCiLgCrRmm"
      },
      "outputs": [],
      "source": [
        "# create the .kaggle directory and an empty kaggle.json file\n",
        "!mkdir -p /root/.kaggle\n",
        "!touch /root/.kaggle/kaggle.json\n",
        "!chmod 600 /root/.kaggle/kaggle.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rPa-FJ5qrRmm"
      },
      "outputs": [],
      "source": [
        "# Fill in your user name and key from creating the kaggle account and API token file\n",
        "import json\n",
        "kaggle_username = \"afrasaboobackerp\"\n",
        "kaggle_key = \"15859931801dc9a24982fbde863355de\"\n",
        "\n",
        "# Save API token the kaggle.json file\n",
        "with open(\"/root/.kaggle/kaggle.json\", \"w\") as f:\n",
        "    f.write(json.dumps({\"username\": kaggle_username, \"key\": kaggle_key}))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dBe2KkcjrRmm"
      },
      "source": [
        "### Download and explore dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p4gjPvcJrRmm"
      },
      "source": [
        "### Go to the bike sharing demand competition and agree to the terms\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HDAmlq2orRmn",
        "outputId": "a468f643-d553-4cbb-9026-dbf301a2384e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading bike-sharing-demand.zip to /content\n",
            "\r  0% 0.00/189k [00:00<?, ?B/s]\n",
            "\r100% 189k/189k [00:00<00:00, 68.1MB/s]\n",
            "Archive:  bike-sharing-demand.zip\n",
            "  inflating: sampleSubmission.csv    \n",
            "  inflating: test.csv                \n",
            "  inflating: train.csv               \n"
          ]
        }
      ],
      "source": [
        "# Download the dataset, it will be in a .zip file so you'll need to unzip it as well.\n",
        "!kaggle competitions download -c bike-sharing-demand\n",
        "# If you already downloaded it you can use the -o command to overwrite the file\n",
        "!unzip -o bike-sharing-demand.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GwkymHJfrRmn"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from autogluon.tabular import TabularPredictor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "jNdeVwAfrRmn",
        "outputId": "b2722e04-964c-4b59-8ba2-b7496fe41a04"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "             datetime  season  holiday  workingday  weather  temp   atemp  \\\n",
              "0 2011-01-01 00:00:00       1        0           0        1  9.84  14.395   \n",
              "1 2011-01-01 01:00:00       1        0           0        1  9.02  13.635   \n",
              "2 2011-01-01 02:00:00       1        0           0        1  9.02  13.635   \n",
              "3 2011-01-01 03:00:00       1        0           0        1  9.84  14.395   \n",
              "4 2011-01-01 04:00:00       1        0           0        1  9.84  14.395   \n",
              "\n",
              "   humidity  windspeed  casual  registered  count  \n",
              "0        81        0.0       3          13     16  \n",
              "1        80        0.0       8          32     40  \n",
              "2        80        0.0       5          27     32  \n",
              "3        75        0.0       3          10     13  \n",
              "4        75        0.0       0           1      1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8bfa9bfd-f5dd-41c6-b5b5-90c6329f4530\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>datetime</th>\n",
              "      <th>season</th>\n",
              "      <th>holiday</th>\n",
              "      <th>workingday</th>\n",
              "      <th>weather</th>\n",
              "      <th>temp</th>\n",
              "      <th>atemp</th>\n",
              "      <th>humidity</th>\n",
              "      <th>windspeed</th>\n",
              "      <th>casual</th>\n",
              "      <th>registered</th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2011-01-01 00:00:00</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>9.84</td>\n",
              "      <td>14.395</td>\n",
              "      <td>81</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3</td>\n",
              "      <td>13</td>\n",
              "      <td>16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2011-01-01 01:00:00</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>9.02</td>\n",
              "      <td>13.635</td>\n",
              "      <td>80</td>\n",
              "      <td>0.0</td>\n",
              "      <td>8</td>\n",
              "      <td>32</td>\n",
              "      <td>40</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2011-01-01 02:00:00</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>9.02</td>\n",
              "      <td>13.635</td>\n",
              "      <td>80</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5</td>\n",
              "      <td>27</td>\n",
              "      <td>32</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2011-01-01 03:00:00</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>9.84</td>\n",
              "      <td>14.395</td>\n",
              "      <td>75</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3</td>\n",
              "      <td>10</td>\n",
              "      <td>13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2011-01-01 04:00:00</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>9.84</td>\n",
              "      <td>14.395</td>\n",
              "      <td>75</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8bfa9bfd-f5dd-41c6-b5b5-90c6329f4530')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-8bfa9bfd-f5dd-41c6-b5b5-90c6329f4530 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-8bfa9bfd-f5dd-41c6-b5b5-90c6329f4530');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "# Create the train dataset in pandas by reading the csv\n",
        "# Set the parsing of the datetime column so you can use some of the `dt` features in pandas later\n",
        "train = pd.read_csv('/content/train.csv', parse_dates=['datetime'])\n",
        "train.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        },
        "id": "pfMZ8B7KrRmn",
        "outputId": "7e0cef95-b4be-4326-aa97-8b30bee24e2c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "             season       holiday    workingday       weather         temp  \\\n",
              "count  10886.000000  10886.000000  10886.000000  10886.000000  10886.00000   \n",
              "mean       2.506614      0.028569      0.680875      1.418427     20.23086   \n",
              "std        1.116174      0.166599      0.466159      0.633839      7.79159   \n",
              "min        1.000000      0.000000      0.000000      1.000000      0.82000   \n",
              "25%        2.000000      0.000000      0.000000      1.000000     13.94000   \n",
              "50%        3.000000      0.000000      1.000000      1.000000     20.50000   \n",
              "75%        4.000000      0.000000      1.000000      2.000000     26.24000   \n",
              "max        4.000000      1.000000      1.000000      4.000000     41.00000   \n",
              "\n",
              "              atemp      humidity     windspeed        casual    registered  \\\n",
              "count  10886.000000  10886.000000  10886.000000  10886.000000  10886.000000   \n",
              "mean      23.655084     61.886460     12.799395     36.021955    155.552177   \n",
              "std        8.474601     19.245033      8.164537     49.960477    151.039033   \n",
              "min        0.760000      0.000000      0.000000      0.000000      0.000000   \n",
              "25%       16.665000     47.000000      7.001500      4.000000     36.000000   \n",
              "50%       24.240000     62.000000     12.998000     17.000000    118.000000   \n",
              "75%       31.060000     77.000000     16.997900     49.000000    222.000000   \n",
              "max       45.455000    100.000000     56.996900    367.000000    886.000000   \n",
              "\n",
              "              count  \n",
              "count  10886.000000  \n",
              "mean     191.574132  \n",
              "std      181.144454  \n",
              "min        1.000000  \n",
              "25%       42.000000  \n",
              "50%      145.000000  \n",
              "75%      284.000000  \n",
              "max      977.000000  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1b7b36be-6008-495c-9479-cd9c2d143e1b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>season</th>\n",
              "      <th>holiday</th>\n",
              "      <th>workingday</th>\n",
              "      <th>weather</th>\n",
              "      <th>temp</th>\n",
              "      <th>atemp</th>\n",
              "      <th>humidity</th>\n",
              "      <th>windspeed</th>\n",
              "      <th>casual</th>\n",
              "      <th>registered</th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>10886.000000</td>\n",
              "      <td>10886.000000</td>\n",
              "      <td>10886.000000</td>\n",
              "      <td>10886.000000</td>\n",
              "      <td>10886.00000</td>\n",
              "      <td>10886.000000</td>\n",
              "      <td>10886.000000</td>\n",
              "      <td>10886.000000</td>\n",
              "      <td>10886.000000</td>\n",
              "      <td>10886.000000</td>\n",
              "      <td>10886.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>2.506614</td>\n",
              "      <td>0.028569</td>\n",
              "      <td>0.680875</td>\n",
              "      <td>1.418427</td>\n",
              "      <td>20.23086</td>\n",
              "      <td>23.655084</td>\n",
              "      <td>61.886460</td>\n",
              "      <td>12.799395</td>\n",
              "      <td>36.021955</td>\n",
              "      <td>155.552177</td>\n",
              "      <td>191.574132</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>1.116174</td>\n",
              "      <td>0.166599</td>\n",
              "      <td>0.466159</td>\n",
              "      <td>0.633839</td>\n",
              "      <td>7.79159</td>\n",
              "      <td>8.474601</td>\n",
              "      <td>19.245033</td>\n",
              "      <td>8.164537</td>\n",
              "      <td>49.960477</td>\n",
              "      <td>151.039033</td>\n",
              "      <td>181.144454</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.82000</td>\n",
              "      <td>0.760000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>13.94000</td>\n",
              "      <td>16.665000</td>\n",
              "      <td>47.000000</td>\n",
              "      <td>7.001500</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>36.000000</td>\n",
              "      <td>42.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>3.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>20.50000</td>\n",
              "      <td>24.240000</td>\n",
              "      <td>62.000000</td>\n",
              "      <td>12.998000</td>\n",
              "      <td>17.000000</td>\n",
              "      <td>118.000000</td>\n",
              "      <td>145.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>4.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>26.24000</td>\n",
              "      <td>31.060000</td>\n",
              "      <td>77.000000</td>\n",
              "      <td>16.997900</td>\n",
              "      <td>49.000000</td>\n",
              "      <td>222.000000</td>\n",
              "      <td>284.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>4.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>41.00000</td>\n",
              "      <td>45.455000</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>56.996900</td>\n",
              "      <td>367.000000</td>\n",
              "      <td>886.000000</td>\n",
              "      <td>977.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1b7b36be-6008-495c-9479-cd9c2d143e1b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-1b7b36be-6008-495c-9479-cd9c2d143e1b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-1b7b36be-6008-495c-9479-cd9c2d143e1b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "# Simple output of the train dataset to view some of the min/max/varition of the dataset features.\n",
        "train.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "7cZDv4DvrRmn",
        "outputId": "72ca5e56-c116-4f3f-a77a-58d808c3d4e9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "             datetime  season  holiday  workingday  weather   temp   atemp  \\\n",
              "0 2011-01-20 00:00:00       1        0           1        1  10.66  11.365   \n",
              "1 2011-01-20 01:00:00       1        0           1        1  10.66  13.635   \n",
              "2 2011-01-20 02:00:00       1        0           1        1  10.66  13.635   \n",
              "3 2011-01-20 03:00:00       1        0           1        1  10.66  12.880   \n",
              "4 2011-01-20 04:00:00       1        0           1        1  10.66  12.880   \n",
              "\n",
              "   humidity  windspeed  \n",
              "0        56    26.0027  \n",
              "1        56     0.0000  \n",
              "2        56     0.0000  \n",
              "3        56    11.0014  \n",
              "4        56    11.0014  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-dc5df793-eb72-4d39-8474-03d73600df22\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>datetime</th>\n",
              "      <th>season</th>\n",
              "      <th>holiday</th>\n",
              "      <th>workingday</th>\n",
              "      <th>weather</th>\n",
              "      <th>temp</th>\n",
              "      <th>atemp</th>\n",
              "      <th>humidity</th>\n",
              "      <th>windspeed</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2011-01-20 00:00:00</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>10.66</td>\n",
              "      <td>11.365</td>\n",
              "      <td>56</td>\n",
              "      <td>26.0027</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2011-01-20 01:00:00</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>10.66</td>\n",
              "      <td>13.635</td>\n",
              "      <td>56</td>\n",
              "      <td>0.0000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2011-01-20 02:00:00</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>10.66</td>\n",
              "      <td>13.635</td>\n",
              "      <td>56</td>\n",
              "      <td>0.0000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2011-01-20 03:00:00</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>10.66</td>\n",
              "      <td>12.880</td>\n",
              "      <td>56</td>\n",
              "      <td>11.0014</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2011-01-20 04:00:00</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>10.66</td>\n",
              "      <td>12.880</td>\n",
              "      <td>56</td>\n",
              "      <td>11.0014</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-dc5df793-eb72-4d39-8474-03d73600df22')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-dc5df793-eb72-4d39-8474-03d73600df22 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-dc5df793-eb72-4d39-8474-03d73600df22');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "# Create the test pandas dataframe in pandas by reading the csv, remember to parse the datetime!\n",
        "test = pd.read_csv('/content/test.csv', parse_dates=['datetime'])\n",
        "test.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "vAYQJzCErRmn",
        "outputId": "4c83f462-f856-493f-c967-956d6385887e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "             datetime  count\n",
              "0 2011-01-20 00:00:00      0\n",
              "1 2011-01-20 01:00:00      0\n",
              "2 2011-01-20 02:00:00      0\n",
              "3 2011-01-20 03:00:00      0\n",
              "4 2011-01-20 04:00:00      0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1f1e9773-fd41-417b-91f4-3c79ca0ddf9e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>datetime</th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2011-01-20 00:00:00</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2011-01-20 01:00:00</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2011-01-20 02:00:00</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2011-01-20 03:00:00</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2011-01-20 04:00:00</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1f1e9773-fd41-417b-91f4-3c79ca0ddf9e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-1f1e9773-fd41-417b-91f4-3c79ca0ddf9e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-1f1e9773-fd41-417b-91f4-3c79ca0ddf9e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "# Same thing as train and test dataset\n",
        "submission = pd.read_csv('/content/sampleSubmission.csv', parse_dates=['datetime'])\n",
        "submission.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FYoTu6carRmo"
      },
      "source": [
        "## Step 3: Train a model using AutoGluon’s Tabular Prediction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aAmG4PaUrRmo"
      },
      "source": [
        "Requirements:\n",
        "* We are prediting `count`, so it is the label we are setting.\n",
        "* Ignore `casual` and `registered` columns as they are also not present in the test dataset.\n",
        "* Use the `root_mean_squared_error` as the metric to use for evaluation.\n",
        "* Set a time limit of 10 minutes (600 seconds).\n",
        "* Use the preset `best_quality` to focus on creating the best model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Ccqx7PkrRmo",
        "outputId": "40addac7-c93d-4427-fb1c-aa2388e0c09e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No path specified. Models will be saved in: \"AutogluonModels/ag-20230606_184320/\"\n",
            "Presets specified: ['best_quality']\n",
            "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=20\n",
            "Beginning AutoGluon training ... Time limit = 600s\n",
            "AutoGluon will save models to \"AutogluonModels/ag-20230606_184320/\"\n",
            "AutoGluon Version:  0.7.0\n",
            "Python Version:     3.10.11\n",
            "Operating System:   Linux\n",
            "Platform Machine:   x86_64\n",
            "Platform Version:   #1 SMP Sat Apr 29 09:15:28 UTC 2023\n",
            "Train Data Rows:    10886\n",
            "Train Data Columns: 9\n",
            "Label Column: count\n",
            "Preprocessing data ...\n",
            "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == int and many unique label-values observed).\n",
            "\tLabel info (max, min, mean, stddev): (977, 1, 191.57413, 181.14445)\n",
            "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
            "Using Feature Generators to preprocess the data ...\n",
            "Fitting AutoMLPipelineFeatureGenerator...\n",
            "\tAvailable Memory:                    12211.23 MB\n",
            "\tTrain Data (Original)  Memory Usage: 0.78 MB (0.0% of available memory)\n",
            "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
            "\tStage 1 Generators:\n",
            "\t\tFitting AsTypeFeatureGenerator...\n",
            "\t\t\tNote: Converting 2 features to boolean dtype as they only contain 2 unique values.\n",
            "\tStage 2 Generators:\n",
            "\t\tFitting FillNaFeatureGenerator...\n",
            "\tStage 3 Generators:\n",
            "\t\tFitting IdentityFeatureGenerator...\n",
            "\t\tFitting DatetimeFeatureGenerator...\n",
            "\tStage 4 Generators:\n",
            "\t\tFitting DropUniqueFeatureGenerator...\n",
            "\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t('datetime', []) : 1 | ['datetime']\n",
            "\t\t('float', [])    : 3 | ['temp', 'atemp', 'windspeed']\n",
            "\t\t('int', [])      : 5 | ['season', 'holiday', 'workingday', 'weather', 'humidity']\n",
            "\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t('float', [])                : 3 | ['temp', 'atemp', 'windspeed']\n",
            "\t\t('int', [])                  : 3 | ['season', 'weather', 'humidity']\n",
            "\t\t('int', ['bool'])            : 2 | ['holiday', 'workingday']\n",
            "\t\t('int', ['datetime_as_int']) : 5 | ['datetime', 'datetime.year', 'datetime.month', 'datetime.day', 'datetime.dayofweek']\n",
            "\t0.1s = Fit runtime\n",
            "\t9 features in original data used to generate 13 features in processed data.\n",
            "\tTrain Data (Processed) Memory Usage: 0.98 MB (0.0% of available memory)\n",
            "Data preprocessing and feature engineering runtime = 0.16s ...\n",
            "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
            "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
            "\tTo change this, specify the eval_metric parameter of Predictor()\n",
            "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
            "Fitting 11 L1 models ...\n",
            "Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 399.79s of the 599.83s of remaining time.\n",
            "\t-101.5462\t = Validation score   (-root_mean_squared_error)\n",
            "\t0.04s\t = Training   runtime\n",
            "\t0.07s\t = Validation runtime\n",
            "Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 395.56s of the 595.6s of remaining time.\n",
            "\t-84.1251\t = Validation score   (-root_mean_squared_error)\n",
            "\t0.06s\t = Training   runtime\n",
            "\t0.07s\t = Validation runtime\n",
            "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 395.39s of the 595.43s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
            "\t-131.4609\t = Validation score   (-root_mean_squared_error)\n",
            "\t90.46s\t = Training   runtime\n",
            "\t18.09s\t = Validation runtime\n",
            "Fitting model: LightGBM_BAG_L1 ... Training model for up to 286.15s of the 486.18s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
            "\t-131.0542\t = Validation score   (-root_mean_squared_error)\n",
            "\t42.41s\t = Training   runtime\n",
            "\t2.43s\t = Validation runtime\n",
            "Fitting model: RandomForestMSE_BAG_L1 ... Training model for up to 238.11s of the 438.15s of remaining time.\n",
            "\t-116.5484\t = Validation score   (-root_mean_squared_error)\n",
            "\t14.99s\t = Training   runtime\n",
            "\t0.79s\t = Validation runtime\n",
            "Fitting model: CatBoost_BAG_L1 ... Training model for up to 220.65s of the 420.69s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
            "\t-130.7181\t = Validation score   (-root_mean_squared_error)\n",
            "\t181.23s\t = Training   runtime\n",
            "\t0.42s\t = Validation runtime\n",
            "Fitting model: ExtraTreesMSE_BAG_L1 ... Training model for up to 32.84s of the 232.87s of remaining time.\n",
            "\t-124.6007\t = Validation score   (-root_mean_squared_error)\n",
            "\t10.65s\t = Training   runtime\n",
            "\t0.77s\t = Validation runtime\n",
            "Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 19.74s of the 219.78s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
            "\t-143.5549\t = Validation score   (-root_mean_squared_error)\n",
            "\t51.85s\t = Training   runtime\n",
            "\t0.53s\t = Validation runtime\n",
            "Completed 1/20 k-fold bagging repeats ...\n",
            "Fitting model: WeightedEnsemble_L2 ... Training model for up to 360.0s of the 163.91s of remaining time.\n",
            "\t-84.1251\t = Validation score   (-root_mean_squared_error)\n",
            "\t0.96s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Fitting 9 L2 models ...\n",
            "Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 162.88s of the 162.8s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
            "\t-60.3328\t = Validation score   (-root_mean_squared_error)\n",
            "\t83.25s\t = Training   runtime\n",
            "\t7.86s\t = Validation runtime\n",
            "Fitting model: LightGBM_BAG_L2 ... Training model for up to 64.69s of the 64.63s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
            "\t-55.0016\t = Validation score   (-root_mean_squared_error)\n",
            "\t36.81s\t = Training   runtime\n",
            "\t0.42s\t = Validation runtime\n",
            "Fitting model: RandomForestMSE_BAG_L2 ... Training model for up to 23.66s of the 23.59s of remaining time.\n",
            "\t-53.4569\t = Validation score   (-root_mean_squared_error)\n",
            "\t44.84s\t = Training   runtime\n",
            "\t0.91s\t = Validation runtime\n",
            "Completed 1/20 k-fold bagging repeats ...\n",
            "Fitting model: WeightedEnsemble_L3 ... Training model for up to 360.0s of the -23.73s of remaining time.\n",
            "\t-53.1189\t = Validation score   (-root_mean_squared_error)\n",
            "\t0.33s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "AutoGluon training complete, total runtime = 624.1s ... Best model: \"WeightedEnsemble_L3\"\n",
            "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20230606_184320/\")\n"
          ]
        }
      ],
      "source": [
        "train = train.drop(columns=['casual', 'registered'])\n",
        "predictor = TabularPredictor(label='count', eval_metric='root_mean_squared_error').fit(train, time_limit=600,\n",
        "                             presets='best_quality')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oLaC1XfurRmo"
      },
      "source": [
        "### Review AutoGluon's training run with ranking of models that did the best."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ExjavFhvrRmo",
        "outputId": "f4c790f0-477b-4226-b1ce-981039c1f935"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "*** Summary of fit() ***\n",
            "Estimated performance of each model:\n",
            "                     model   score_val  pred_time_val    fit_time  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
            "0      WeightedEnsemble_L3  -53.118942      32.350498  556.910509                0.001059           0.326913            3       True         13\n",
            "1   RandomForestMSE_BAG_L2  -53.456949      24.067576  436.527609                0.906628          44.844980            2       True         12\n",
            "2          LightGBM_BAG_L2  -55.001598      23.582039  428.489779                0.421091          36.807150            2       True         11\n",
            "3        LightGBMXT_BAG_L2  -60.332795      31.021721  474.931467                7.860773          83.248838            2       True         10\n",
            "4    KNeighborsDist_BAG_L1  -84.125061       0.068346    0.057381                0.068346           0.057381            1       True          2\n",
            "5      WeightedEnsemble_L2  -84.125061       0.069667    1.021446                0.001321           0.964066            2       True          9\n",
            "6    KNeighborsUnif_BAG_L1 -101.546199       0.070704    0.040951                0.070704           0.040951            1       True          1\n",
            "7   RandomForestMSE_BAG_L1 -116.548359       0.791600   14.992298                0.791600          14.992298            1       True          5\n",
            "8     ExtraTreesMSE_BAG_L1 -124.600676       0.766238   10.651675                0.766238          10.651675            1       True          7\n",
            "9          CatBoost_BAG_L1 -130.718127       0.420337  181.229062                0.420337         181.229062            1       True          6\n",
            "10         LightGBM_BAG_L1 -131.054162       2.425261   42.406789                2.425261          42.406789            1       True          4\n",
            "11       LightGBMXT_BAG_L1 -131.460909      18.088925   90.457347               18.088925          90.457347            1       True          3\n",
            "12  NeuralNetFastAI_BAG_L1 -143.554929       0.529537   51.847125                0.529537          51.847125            1       True          8\n",
            "Number of models trained: 13\n",
            "Types of models trained:\n",
            "{'StackerEnsembleModel_KNN', 'StackerEnsembleModel_NNFastAiTabular', 'StackerEnsembleModel_LGB', 'WeightedEnsembleModel', 'StackerEnsembleModel_RF', 'StackerEnsembleModel_XT', 'StackerEnsembleModel_CatBoost'}\n",
            "Bagging used: True  (with 8 folds)\n",
            "Multi-layer stack-ensembling used: True  (with 3 levels)\n",
            "Feature Metadata (Processed):\n",
            "(raw dtype, special dtypes):\n",
            "('float', [])                : 3 | ['temp', 'atemp', 'windspeed']\n",
            "('int', [])                  : 3 | ['season', 'weather', 'humidity']\n",
            "('int', ['bool'])            : 2 | ['holiday', 'workingday']\n",
            "('int', ['datetime_as_int']) : 5 | ['datetime', 'datetime.year', 'datetime.month', 'datetime.day', 'datetime.dayofweek']\n",
            "*** End of fit() summary ***\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/autogluon/core/utils/plots.py:138: UserWarning: AutoGluon summary plots cannot be created because bokeh is not installed. To see plots, please do: \"pip install bokeh==2.0.1\"\n",
            "  warnings.warn('AutoGluon summary plots cannot be created because bokeh is not installed. To see plots, please do: \"pip install bokeh==2.0.1\"')\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'model_types': {'KNeighborsUnif_BAG_L1': 'StackerEnsembleModel_KNN',\n",
              "  'KNeighborsDist_BAG_L1': 'StackerEnsembleModel_KNN',\n",
              "  'LightGBMXT_BAG_L1': 'StackerEnsembleModel_LGB',\n",
              "  'LightGBM_BAG_L1': 'StackerEnsembleModel_LGB',\n",
              "  'RandomForestMSE_BAG_L1': 'StackerEnsembleModel_RF',\n",
              "  'CatBoost_BAG_L1': 'StackerEnsembleModel_CatBoost',\n",
              "  'ExtraTreesMSE_BAG_L1': 'StackerEnsembleModel_XT',\n",
              "  'NeuralNetFastAI_BAG_L1': 'StackerEnsembleModel_NNFastAiTabular',\n",
              "  'WeightedEnsemble_L2': 'WeightedEnsembleModel',\n",
              "  'LightGBMXT_BAG_L2': 'StackerEnsembleModel_LGB',\n",
              "  'LightGBM_BAG_L2': 'StackerEnsembleModel_LGB',\n",
              "  'RandomForestMSE_BAG_L2': 'StackerEnsembleModel_RF',\n",
              "  'WeightedEnsemble_L3': 'WeightedEnsembleModel'},\n",
              " 'model_performance': {'KNeighborsUnif_BAG_L1': -101.54619908446061,\n",
              "  'KNeighborsDist_BAG_L1': -84.12506123181602,\n",
              "  'LightGBMXT_BAG_L1': -131.46090891834504,\n",
              "  'LightGBM_BAG_L1': -131.054161598899,\n",
              "  'RandomForestMSE_BAG_L1': -116.54835939455667,\n",
              "  'CatBoost_BAG_L1': -130.71812687733896,\n",
              "  'ExtraTreesMSE_BAG_L1': -124.60067564699747,\n",
              "  'NeuralNetFastAI_BAG_L1': -143.55492877509926,\n",
              "  'WeightedEnsemble_L2': -84.12506123181602,\n",
              "  'LightGBMXT_BAG_L2': -60.3327950543609,\n",
              "  'LightGBM_BAG_L2': -55.00159822684081,\n",
              "  'RandomForestMSE_BAG_L2': -53.45694924574564,\n",
              "  'WeightedEnsemble_L3': -53.11894175635079},\n",
              " 'model_best': 'WeightedEnsemble_L3',\n",
              " 'model_paths': {'KNeighborsUnif_BAG_L1': 'AutogluonModels/ag-20230606_184320/models/KNeighborsUnif_BAG_L1/',\n",
              "  'KNeighborsDist_BAG_L1': 'AutogluonModels/ag-20230606_184320/models/KNeighborsDist_BAG_L1/',\n",
              "  'LightGBMXT_BAG_L1': 'AutogluonModels/ag-20230606_184320/models/LightGBMXT_BAG_L1/',\n",
              "  'LightGBM_BAG_L1': 'AutogluonModels/ag-20230606_184320/models/LightGBM_BAG_L1/',\n",
              "  'RandomForestMSE_BAG_L1': 'AutogluonModels/ag-20230606_184320/models/RandomForestMSE_BAG_L1/',\n",
              "  'CatBoost_BAG_L1': 'AutogluonModels/ag-20230606_184320/models/CatBoost_BAG_L1/',\n",
              "  'ExtraTreesMSE_BAG_L1': 'AutogluonModels/ag-20230606_184320/models/ExtraTreesMSE_BAG_L1/',\n",
              "  'NeuralNetFastAI_BAG_L1': 'AutogluonModels/ag-20230606_184320/models/NeuralNetFastAI_BAG_L1/',\n",
              "  'WeightedEnsemble_L2': 'AutogluonModels/ag-20230606_184320/models/WeightedEnsemble_L2/',\n",
              "  'LightGBMXT_BAG_L2': 'AutogluonModels/ag-20230606_184320/models/LightGBMXT_BAG_L2/',\n",
              "  'LightGBM_BAG_L2': 'AutogluonModels/ag-20230606_184320/models/LightGBM_BAG_L2/',\n",
              "  'RandomForestMSE_BAG_L2': 'AutogluonModels/ag-20230606_184320/models/RandomForestMSE_BAG_L2/',\n",
              "  'WeightedEnsemble_L3': 'AutogluonModels/ag-20230606_184320/models/WeightedEnsemble_L3/'},\n",
              " 'model_fit_times': {'KNeighborsUnif_BAG_L1': 0.04095149040222168,\n",
              "  'KNeighborsDist_BAG_L1': 0.05738067626953125,\n",
              "  'LightGBMXT_BAG_L1': 90.45734739303589,\n",
              "  'LightGBM_BAG_L1': 42.40678858757019,\n",
              "  'RandomForestMSE_BAG_L1': 14.992298364639282,\n",
              "  'CatBoost_BAG_L1': 181.22906231880188,\n",
              "  'ExtraTreesMSE_BAG_L1': 10.65167498588562,\n",
              "  'NeuralNetFastAI_BAG_L1': 51.84712529182434,\n",
              "  'WeightedEnsemble_L2': 0.9640655517578125,\n",
              "  'LightGBMXT_BAG_L2': 83.24883794784546,\n",
              "  'LightGBM_BAG_L2': 36.80714964866638,\n",
              "  'RandomForestMSE_BAG_L2': 44.84497952461243,\n",
              "  'WeightedEnsemble_L3': 0.32691311836242676},\n",
              " 'model_pred_times': {'KNeighborsUnif_BAG_L1': 0.07070398330688477,\n",
              "  'KNeighborsDist_BAG_L1': 0.06834602355957031,\n",
              "  'LightGBMXT_BAG_L1': 18.088924646377563,\n",
              "  'LightGBM_BAG_L1': 2.4252614974975586,\n",
              "  'RandomForestMSE_BAG_L1': 0.7915995121002197,\n",
              "  'CatBoost_BAG_L1': 0.4203372001647949,\n",
              "  'ExtraTreesMSE_BAG_L1': 0.7662384510040283,\n",
              "  'NeuralNetFastAI_BAG_L1': 0.5295372009277344,\n",
              "  'WeightedEnsemble_L2': 0.0013210773468017578,\n",
              "  'LightGBMXT_BAG_L2': 7.8607728481292725,\n",
              "  'LightGBM_BAG_L2': 0.42109060287475586,\n",
              "  'RandomForestMSE_BAG_L2': 0.906627893447876,\n",
              "  'WeightedEnsemble_L3': 0.0010585784912109375},\n",
              " 'num_bag_folds': 8,\n",
              " 'max_stack_level': 3,\n",
              " 'model_hyperparams': {'KNeighborsUnif_BAG_L1': {'use_orig_features': True,\n",
              "   'max_base_models': 25,\n",
              "   'max_base_models_per_type': 5,\n",
              "   'save_bag_folds': True,\n",
              "   'use_child_oof': True},\n",
              "  'KNeighborsDist_BAG_L1': {'use_orig_features': True,\n",
              "   'max_base_models': 25,\n",
              "   'max_base_models_per_type': 5,\n",
              "   'save_bag_folds': True,\n",
              "   'use_child_oof': True},\n",
              "  'LightGBMXT_BAG_L1': {'use_orig_features': True,\n",
              "   'max_base_models': 25,\n",
              "   'max_base_models_per_type': 5,\n",
              "   'save_bag_folds': True},\n",
              "  'LightGBM_BAG_L1': {'use_orig_features': True,\n",
              "   'max_base_models': 25,\n",
              "   'max_base_models_per_type': 5,\n",
              "   'save_bag_folds': True},\n",
              "  'RandomForestMSE_BAG_L1': {'use_orig_features': True,\n",
              "   'max_base_models': 25,\n",
              "   'max_base_models_per_type': 5,\n",
              "   'save_bag_folds': True,\n",
              "   'use_child_oof': True},\n",
              "  'CatBoost_BAG_L1': {'use_orig_features': True,\n",
              "   'max_base_models': 25,\n",
              "   'max_base_models_per_type': 5,\n",
              "   'save_bag_folds': True},\n",
              "  'ExtraTreesMSE_BAG_L1': {'use_orig_features': True,\n",
              "   'max_base_models': 25,\n",
              "   'max_base_models_per_type': 5,\n",
              "   'save_bag_folds': True,\n",
              "   'use_child_oof': True},\n",
              "  'NeuralNetFastAI_BAG_L1': {'use_orig_features': True,\n",
              "   'max_base_models': 25,\n",
              "   'max_base_models_per_type': 5,\n",
              "   'save_bag_folds': True},\n",
              "  'WeightedEnsemble_L2': {'use_orig_features': False,\n",
              "   'max_base_models': 25,\n",
              "   'max_base_models_per_type': 5,\n",
              "   'save_bag_folds': True},\n",
              "  'LightGBMXT_BAG_L2': {'use_orig_features': True,\n",
              "   'max_base_models': 25,\n",
              "   'max_base_models_per_type': 5,\n",
              "   'save_bag_folds': True},\n",
              "  'LightGBM_BAG_L2': {'use_orig_features': True,\n",
              "   'max_base_models': 25,\n",
              "   'max_base_models_per_type': 5,\n",
              "   'save_bag_folds': True},\n",
              "  'RandomForestMSE_BAG_L2': {'use_orig_features': True,\n",
              "   'max_base_models': 25,\n",
              "   'max_base_models_per_type': 5,\n",
              "   'save_bag_folds': True,\n",
              "   'use_child_oof': True},\n",
              "  'WeightedEnsemble_L3': {'use_orig_features': False,\n",
              "   'max_base_models': 25,\n",
              "   'max_base_models_per_type': 5,\n",
              "   'save_bag_folds': True}},\n",
              " 'leaderboard':                      model   score_val  pred_time_val    fit_time  \\\n",
              " 0      WeightedEnsemble_L3  -53.118942      32.350498  556.910509   \n",
              " 1   RandomForestMSE_BAG_L2  -53.456949      24.067576  436.527609   \n",
              " 2          LightGBM_BAG_L2  -55.001598      23.582039  428.489779   \n",
              " 3        LightGBMXT_BAG_L2  -60.332795      31.021721  474.931467   \n",
              " 4    KNeighborsDist_BAG_L1  -84.125061       0.068346    0.057381   \n",
              " 5      WeightedEnsemble_L2  -84.125061       0.069667    1.021446   \n",
              " 6    KNeighborsUnif_BAG_L1 -101.546199       0.070704    0.040951   \n",
              " 7   RandomForestMSE_BAG_L1 -116.548359       0.791600   14.992298   \n",
              " 8     ExtraTreesMSE_BAG_L1 -124.600676       0.766238   10.651675   \n",
              " 9          CatBoost_BAG_L1 -130.718127       0.420337  181.229062   \n",
              " 10         LightGBM_BAG_L1 -131.054162       2.425261   42.406789   \n",
              " 11       LightGBMXT_BAG_L1 -131.460909      18.088925   90.457347   \n",
              " 12  NeuralNetFastAI_BAG_L1 -143.554929       0.529537   51.847125   \n",
              " \n",
              "     pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  \\\n",
              " 0                 0.001059           0.326913            3       True   \n",
              " 1                 0.906628          44.844980            2       True   \n",
              " 2                 0.421091          36.807150            2       True   \n",
              " 3                 7.860773          83.248838            2       True   \n",
              " 4                 0.068346           0.057381            1       True   \n",
              " 5                 0.001321           0.964066            2       True   \n",
              " 6                 0.070704           0.040951            1       True   \n",
              " 7                 0.791600          14.992298            1       True   \n",
              " 8                 0.766238          10.651675            1       True   \n",
              " 9                 0.420337         181.229062            1       True   \n",
              " 10                2.425261          42.406789            1       True   \n",
              " 11               18.088925          90.457347            1       True   \n",
              " 12                0.529537          51.847125            1       True   \n",
              " \n",
              "     fit_order  \n",
              " 0          13  \n",
              " 1          12  \n",
              " 2          11  \n",
              " 3          10  \n",
              " 4           2  \n",
              " 5           9  \n",
              " 6           1  \n",
              " 7           5  \n",
              " 8           7  \n",
              " 9           6  \n",
              " 10          4  \n",
              " 11          3  \n",
              " 12          8  }"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "predictor.fit_summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cMMBOZcZrRmp"
      },
      "source": [
        "### Create predictions from test dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MVMuKmo4rRmp",
        "outputId": "3f512874-9d51-4fd8-ec21-edd37ad12d3f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0        24.126625\n",
              "1        42.795876\n",
              "2        46.516136\n",
              "3        48.195526\n",
              "4        51.434601\n",
              "           ...    \n",
              "6488    161.067322\n",
              "6489    161.118744\n",
              "6490    157.369751\n",
              "6491    154.005219\n",
              "6492    151.121735\n",
              "Name: count, Length: 6493, dtype: float32"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "predictions = predictor.predict(test)\n",
        "predictions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H1BzO_mfrRmp"
      },
      "source": [
        "#### NOTE: Kaggle will reject the submission if we don't set everything to be > 0."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i9rQUkhkrRmp",
        "outputId": "c6cd2eba-39bc-44c0-a60f-1414150ba95d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "count    6493.000000\n",
              "mean      100.506393\n",
              "std        89.955223\n",
              "min         3.417208\n",
              "25%        19.701641\n",
              "50%        63.291039\n",
              "75%       166.996796\n",
              "max       365.893127\n",
              "Name: count, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "# Describe the `predictions` series to see if there are any negative values\n",
        "predictions.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uB6AEuRtrRmp",
        "outputId": "add25003-6186-472a-e558-9a3a01be660d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "# How many negative values do we have?\n",
        "num_negative_values = (predictions < 0).sum().sum()\n",
        "num_negative_values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ydPgMINZrRmp"
      },
      "outputs": [],
      "source": [
        "# Set them to zero\n",
        "predictions[predictions < 0] = 0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BUtSEdu3rRmq"
      },
      "source": [
        "### Set predictions to submission dataframe, save, and submit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R28eAnPgrRmq"
      },
      "outputs": [],
      "source": [
        "submission['datetime'] = test['datetime']\n",
        "submission[\"count\"] = predictions\n",
        "submission.to_csv(\"submission.csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S2ihWAwQrRmq",
        "outputId": "9cf0c584-9437-4f51-c78d-ddced212b331"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100% 188k/188k [00:02<00:00, 65.1kB/s]\n",
            "Successfully submitted to Bike Sharing Demand"
          ]
        }
      ],
      "source": [
        "!kaggle competitions submit -c bike-sharing-demand -f submission.csv -m \"first raw submission\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OaqDujpYrRmq"
      },
      "source": [
        "#### View submission via the command line or in the web browser under the competition's page - `My Submissions`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kknPNnKSrRmq",
        "outputId": "ab6d412f-d81d-4e09-afce-801b3f91d239"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fileName                     date                 description                        status    publicScore  privateScore  \n",
            "---------------------------  -------------------  ---------------------------------  --------  -----------  ------------  \n",
            "submission.csv               2023-06-06 19:00:16  first raw submission               complete  1.80288      1.80288       \n",
            "submission_new_hpo.csv       2023-06-06 17:53:05  new features with hyperparameters  complete  0.55740      0.55740       \n",
            "submission_new_features.csv  2023-06-06 17:38:40  new features                       complete  0.63634      0.63634       \n",
            "submission.csv               2023-06-06 17:19:01  first raw submission               complete  1.79594      1.79594       \n"
          ]
        }
      ],
      "source": [
        "!kaggle competitions submissions -c bike-sharing-demand | tail -n +1 | head -n 6"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u0bkkYFErRmq"
      },
      "source": [
        "#### Initial score of `?`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B3CSDIIPrRmq"
      },
      "source": [
        "## Step 4: Exploratory Data Analysis and Creating an additional feature\n",
        "* Any additional feature will do, but a great suggestion would be to separate out the datetime into hour, day, or month parts."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 643
        },
        "id": "FpHei_gprRmz",
        "outputId": "a92c01da-7b91-4725-e485-3563f1ea813b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[<Axes: title={'center': 'datetime'}>,\n",
              "        <Axes: title={'center': 'season'}>,\n",
              "        <Axes: title={'center': 'holiday'}>],\n",
              "       [<Axes: title={'center': 'workingday'}>,\n",
              "        <Axes: title={'center': 'weather'}>,\n",
              "        <Axes: title={'center': 'temp'}>],\n",
              "       [<Axes: title={'center': 'atemp'}>,\n",
              "        <Axes: title={'center': 'humidity'}>,\n",
              "        <Axes: title={'center': 'windspeed'}>],\n",
              "       [<Axes: title={'center': 'count'}>, <Axes: >, <Axes: >]],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 12 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Create a histogram of all features to show the distribution of each one relative to the data. This is part of the exploritory data analysis\n",
        "train.hist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "KisGfV-QrRmz",
        "outputId": "1d226232-bd29-4998-c14b-76b60c480aae"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "             datetime  season  holiday  workingday  weather   temp   atemp  \\\n",
              "0 2011-01-20 00:00:00       1        0           1        1  10.66  11.365   \n",
              "1 2011-01-20 01:00:00       1        0           1        1  10.66  13.635   \n",
              "2 2011-01-20 02:00:00       1        0           1        1  10.66  13.635   \n",
              "3 2011-01-20 03:00:00       1        0           1        1  10.66  12.880   \n",
              "4 2011-01-20 04:00:00       1        0           1        1  10.66  12.880   \n",
              "\n",
              "   humidity  windspeed  Year  Month  Day  Hour  \n",
              "0        56    26.0027  2011      1   20     0  \n",
              "1        56     0.0000  2011      1   20     1  \n",
              "2        56     0.0000  2011      1   20     2  \n",
              "3        56    11.0014  2011      1   20     3  \n",
              "4        56    11.0014  2011      1   20     4  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f52fcc62-eef3-4521-8747-2e2a215dc348\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>datetime</th>\n",
              "      <th>season</th>\n",
              "      <th>holiday</th>\n",
              "      <th>workingday</th>\n",
              "      <th>weather</th>\n",
              "      <th>temp</th>\n",
              "      <th>atemp</th>\n",
              "      <th>humidity</th>\n",
              "      <th>windspeed</th>\n",
              "      <th>Year</th>\n",
              "      <th>Month</th>\n",
              "      <th>Day</th>\n",
              "      <th>Hour</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2011-01-20 00:00:00</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>10.66</td>\n",
              "      <td>11.365</td>\n",
              "      <td>56</td>\n",
              "      <td>26.0027</td>\n",
              "      <td>2011</td>\n",
              "      <td>1</td>\n",
              "      <td>20</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2011-01-20 01:00:00</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>10.66</td>\n",
              "      <td>13.635</td>\n",
              "      <td>56</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>2011</td>\n",
              "      <td>1</td>\n",
              "      <td>20</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2011-01-20 02:00:00</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>10.66</td>\n",
              "      <td>13.635</td>\n",
              "      <td>56</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>2011</td>\n",
              "      <td>1</td>\n",
              "      <td>20</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2011-01-20 03:00:00</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>10.66</td>\n",
              "      <td>12.880</td>\n",
              "      <td>56</td>\n",
              "      <td>11.0014</td>\n",
              "      <td>2011</td>\n",
              "      <td>1</td>\n",
              "      <td>20</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2011-01-20 04:00:00</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>10.66</td>\n",
              "      <td>12.880</td>\n",
              "      <td>56</td>\n",
              "      <td>11.0014</td>\n",
              "      <td>2011</td>\n",
              "      <td>1</td>\n",
              "      <td>20</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f52fcc62-eef3-4521-8747-2e2a215dc348')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f52fcc62-eef3-4521-8747-2e2a215dc348 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f52fcc62-eef3-4521-8747-2e2a215dc348');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "# create a new feature\n",
        "train['Year'] = train['datetime'].dt.year\n",
        "train['Month'] = train['datetime'].dt.month\n",
        "train['Day'] = train['datetime'].dt.day\n",
        "train['Hour'] = train['datetime'].dt.hour\n",
        "\n",
        "test['Year'] = test['datetime'].dt.year\n",
        "test['Month'] = test['datetime'].dt.month\n",
        "test['Day'] = test['datetime'].dt.day\n",
        "test['Hour'] = test['datetime'].dt.hour\n",
        "train.head()\n",
        "test.head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OZOU3lGJrRmz"
      },
      "source": [
        "## Make category types for these so models know they are not just numbers\n",
        "* AutoGluon originally sees these as ints, but in reality they are int representations of a category.\n",
        "* Setting the dtype to category will classify these as categories in AutoGluon."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5z26UV-QrRmz"
      },
      "outputs": [],
      "source": [
        "train[\"season\"] = train[\"season\"].astype(\"category\")\n",
        "train[\"weather\"] = train[\"weather\"].astype(\"category\")\n",
        "test[\"season\"] = test[\"season\"].astype(\"category\")\n",
        "test[\"weather\"] = test[\"weather\"].astype(\"category\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "qOE9tr2YrRmz",
        "outputId": "81afd30d-477c-4ff9-e4a6-864016c37dc5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "             datetime season  holiday  workingday weather  temp   atemp  \\\n",
              "0 2011-01-01 00:00:00      1        0           0       1  9.84  14.395   \n",
              "1 2011-01-01 01:00:00      1        0           0       1  9.02  13.635   \n",
              "2 2011-01-01 02:00:00      1        0           0       1  9.02  13.635   \n",
              "3 2011-01-01 03:00:00      1        0           0       1  9.84  14.395   \n",
              "4 2011-01-01 04:00:00      1        0           0       1  9.84  14.395   \n",
              "\n",
              "   humidity  windspeed  count  Year  Month  Day  Hour  \n",
              "0        81        0.0     16  2011      1    1     0  \n",
              "1        80        0.0     40  2011      1    1     1  \n",
              "2        80        0.0     32  2011      1    1     2  \n",
              "3        75        0.0     13  2011      1    1     3  \n",
              "4        75        0.0      1  2011      1    1     4  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-086cb9b8-3b61-4ee7-a185-b114afa57822\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>datetime</th>\n",
              "      <th>season</th>\n",
              "      <th>holiday</th>\n",
              "      <th>workingday</th>\n",
              "      <th>weather</th>\n",
              "      <th>temp</th>\n",
              "      <th>atemp</th>\n",
              "      <th>humidity</th>\n",
              "      <th>windspeed</th>\n",
              "      <th>count</th>\n",
              "      <th>Year</th>\n",
              "      <th>Month</th>\n",
              "      <th>Day</th>\n",
              "      <th>Hour</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2011-01-01 00:00:00</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>9.84</td>\n",
              "      <td>14.395</td>\n",
              "      <td>81</td>\n",
              "      <td>0.0</td>\n",
              "      <td>16</td>\n",
              "      <td>2011</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2011-01-01 01:00:00</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>9.02</td>\n",
              "      <td>13.635</td>\n",
              "      <td>80</td>\n",
              "      <td>0.0</td>\n",
              "      <td>40</td>\n",
              "      <td>2011</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2011-01-01 02:00:00</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>9.02</td>\n",
              "      <td>13.635</td>\n",
              "      <td>80</td>\n",
              "      <td>0.0</td>\n",
              "      <td>32</td>\n",
              "      <td>2011</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2011-01-01 03:00:00</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>9.84</td>\n",
              "      <td>14.395</td>\n",
              "      <td>75</td>\n",
              "      <td>0.0</td>\n",
              "      <td>13</td>\n",
              "      <td>2011</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2011-01-01 04:00:00</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>9.84</td>\n",
              "      <td>14.395</td>\n",
              "      <td>75</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>2011</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-086cb9b8-3b61-4ee7-a185-b114afa57822')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-086cb9b8-3b61-4ee7-a185-b114afa57822 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-086cb9b8-3b61-4ee7-a185-b114afa57822');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "# View are new feature\n",
        "train.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 660
        },
        "id": "QFs4dwOjrRm0",
        "outputId": "5f06b19d-5bf5-4f4a-ecde-a478e6ebf153"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[<Axes: title={'center': 'datetime'}>,\n",
              "        <Axes: title={'center': 'holiday'}>,\n",
              "        <Axes: title={'center': 'workingday'}>],\n",
              "       [<Axes: title={'center': 'temp'}>,\n",
              "        <Axes: title={'center': 'atemp'}>,\n",
              "        <Axes: title={'center': 'humidity'}>],\n",
              "       [<Axes: title={'center': 'windspeed'}>,\n",
              "        <Axes: title={'center': 'count'}>,\n",
              "        <Axes: title={'center': 'Year'}>],\n",
              "       [<Axes: title={'center': 'Month'}>,\n",
              "        <Axes: title={'center': 'Day'}>,\n",
              "        <Axes: title={'center': 'Hour'}>]], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 23
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 12 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# View histogram of all features again now with the hour feature\n",
        "train.hist()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pa_rq7I6rRm0"
      },
      "source": [
        "## Step 5: Rerun the model with the same settings as before, just with more features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hobPuzYSrRm0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c2346346-cf8c-43fa-d3b0-925e05951b0d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No path specified. Models will be saved in: \"AutogluonModels/ag-20230606_190207/\"\n",
            "Presets specified: ['best_quality']\n",
            "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=20\n",
            "Beginning AutoGluon training ... Time limit = 600s\n",
            "AutoGluon will save models to \"AutogluonModels/ag-20230606_190207/\"\n",
            "AutoGluon Version:  0.7.0\n",
            "Python Version:     3.10.11\n",
            "Operating System:   Linux\n",
            "Platform Machine:   x86_64\n",
            "Platform Version:   #1 SMP Sat Apr 29 09:15:28 UTC 2023\n",
            "Train Data Rows:    10886\n",
            "Train Data Columns: 13\n",
            "Label Column: count\n",
            "Preprocessing data ...\n",
            "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == int and many unique label-values observed).\n",
            "\tLabel info (max, min, mean, stddev): (977, 1, 191.57413, 181.14445)\n",
            "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
            "Using Feature Generators to preprocess the data ...\n",
            "Fitting AutoMLPipelineFeatureGenerator...\n",
            "\tAvailable Memory:                    11101.44 MB\n",
            "\tTrain Data (Original)  Memory Usage: 0.98 MB (0.0% of available memory)\n",
            "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
            "\tStage 1 Generators:\n",
            "\t\tFitting AsTypeFeatureGenerator...\n",
            "\t\t\tNote: Converting 3 features to boolean dtype as they only contain 2 unique values.\n",
            "\tStage 2 Generators:\n",
            "\t\tFitting FillNaFeatureGenerator...\n",
            "\tStage 3 Generators:\n",
            "\t\tFitting IdentityFeatureGenerator...\n",
            "\t\tFitting CategoryFeatureGenerator...\n",
            "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
            "\t\tFitting DatetimeFeatureGenerator...\n",
            "\tStage 4 Generators:\n",
            "\t\tFitting DropUniqueFeatureGenerator...\n",
            "\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t('category', []) : 2 | ['season', 'weather']\n",
            "\t\t('datetime', []) : 1 | ['datetime']\n",
            "\t\t('float', [])    : 3 | ['temp', 'atemp', 'windspeed']\n",
            "\t\t('int', [])      : 7 | ['holiday', 'workingday', 'humidity', 'Year', 'Month', ...]\n",
            "\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t('category', [])             : 2 | ['season', 'weather']\n",
            "\t\t('float', [])                : 3 | ['temp', 'atemp', 'windspeed']\n",
            "\t\t('int', [])                  : 4 | ['humidity', 'Month', 'Day', 'Hour']\n",
            "\t\t('int', ['bool'])            : 3 | ['holiday', 'workingday', 'Year']\n",
            "\t\t('int', ['datetime_as_int']) : 5 | ['datetime', 'datetime.year', 'datetime.month', 'datetime.day', 'datetime.dayofweek']\n",
            "\t0.1s = Fit runtime\n",
            "\t13 features in original data used to generate 17 features in processed data.\n",
            "\tTrain Data (Processed) Memory Usage: 1.1 MB (0.0% of available memory)\n",
            "Data preprocessing and feature engineering runtime = 0.21s ...\n",
            "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
            "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
            "\tTo change this, specify the eval_metric parameter of Predictor()\n",
            "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
            "Fitting 11 L1 models ...\n",
            "Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 399.76s of the 599.78s of remaining time.\n",
            "\t-101.5462\t = Validation score   (-root_mean_squared_error)\n",
            "\t0.04s\t = Training   runtime\n",
            "\t0.05s\t = Validation runtime\n",
            "Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 399.63s of the 599.65s of remaining time.\n",
            "\t-84.1251\t = Validation score   (-root_mean_squared_error)\n",
            "\t0.04s\t = Training   runtime\n",
            "\t0.06s\t = Validation runtime\n",
            "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 399.49s of the 599.51s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
            "\t-34.346\t = Validation score   (-root_mean_squared_error)\n",
            "\t127.07s\t = Training   runtime\n",
            "\t16.84s\t = Validation runtime\n",
            "Fitting model: LightGBM_BAG_L1 ... Training model for up to 265.89s of the 465.91s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
            "\t-33.9173\t = Validation score   (-root_mean_squared_error)\n",
            "\t58.64s\t = Training   runtime\n",
            "\t4.11s\t = Validation runtime\n",
            "Fitting model: RandomForestMSE_BAG_L1 ... Training model for up to 198.61s of the 398.63s of remaining time.\n",
            "\t-38.3061\t = Validation score   (-root_mean_squared_error)\n",
            "\t22.02s\t = Training   runtime\n",
            "\t0.6s\t = Validation runtime\n",
            "Fitting model: CatBoost_BAG_L1 ... Training model for up to 174.96s of the 374.98s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
            "\t-35.0004\t = Validation score   (-root_mean_squared_error)\n",
            "\t161.64s\t = Training   runtime\n",
            "\t0.25s\t = Validation runtime\n",
            "Fitting model: ExtraTreesMSE_BAG_L1 ... Training model for up to 6.1s of the 206.12s of remaining time.\n",
            "\t-38.3116\t = Validation score   (-root_mean_squared_error)\n",
            "\t13.44s\t = Training   runtime\n",
            "\t0.58s\t = Validation runtime\n",
            "Completed 1/20 k-fold bagging repeats ...\n",
            "Fitting model: WeightedEnsemble_L2 ... Training model for up to 360.0s of the 191.44s of remaining time.\n",
            "\t-32.2343\t = Validation score   (-root_mean_squared_error)\n",
            "\t0.39s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Fitting 9 L2 models ...\n",
            "Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 191.02s of the 191.01s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
            "\t-31.2744\t = Validation score   (-root_mean_squared_error)\n",
            "\t44.65s\t = Training   runtime\n",
            "\t1.36s\t = Validation runtime\n",
            "Fitting model: LightGBM_BAG_L2 ... Training model for up to 142.26s of the 142.24s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
            "\t-30.5589\t = Validation score   (-root_mean_squared_error)\n",
            "\t37.44s\t = Training   runtime\n",
            "\t0.38s\t = Validation runtime\n",
            "Fitting model: RandomForestMSE_BAG_L2 ... Training model for up to 100.2s of the 100.18s of remaining time.\n",
            "\t-31.6728\t = Validation score   (-root_mean_squared_error)\n",
            "\t56.69s\t = Training   runtime\n",
            "\t0.94s\t = Validation runtime\n",
            "Fitting model: CatBoost_BAG_L2 ... Training model for up to 40.97s of the 40.95s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
            "\t-31.0517\t = Validation score   (-root_mean_squared_error)\n",
            "\t50.75s\t = Training   runtime\n",
            "\t0.54s\t = Validation runtime\n",
            "Completed 1/20 k-fold bagging repeats ...\n",
            "Fitting model: WeightedEnsemble_L3 ... Training model for up to 360.0s of the -17.63s of remaining time.\n",
            "\t-30.336\t = Validation score   (-root_mean_squared_error)\n",
            "\t0.42s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "AutoGluon training complete, total runtime = 618.09s ... Best model: \"WeightedEnsemble_L3\"\n",
            "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20230606_190207/\")\n"
          ]
        }
      ],
      "source": [
        "predictor_new_features = TabularPredictor(label='count', eval_metric='root_mean_squared_error').fit(train, time_limit=600,\n",
        "                         presets='best_quality')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cuNfacZwrRm0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cac9775b-8cc7-4036-e3ea-090582fa96e0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "*** Summary of fit() ***\n",
            "Estimated performance of each model:\n",
            "                     model   score_val  pred_time_val    fit_time  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
            "0      WeightedEnsemble_L3  -30.335978      25.706091  572.850888                0.001059           0.417489            3       True         13\n",
            "1          LightGBM_BAG_L2  -30.558902      22.866322  420.337522                0.378548          37.439705            2       True         10\n",
            "2          CatBoost_BAG_L2  -31.051735      23.029320  433.649009                0.541546          50.751193            2       True         12\n",
            "3        LightGBMXT_BAG_L2  -31.274362      23.846333  427.552596                1.358559          44.654780            2       True          9\n",
            "4   RandomForestMSE_BAG_L2  -31.672755      23.426379  439.587720                0.938606          56.689904            2       True         11\n",
            "5      WeightedEnsemble_L2  -32.234277      21.858769  369.805561                0.000766           0.394217            2       True          8\n",
            "6          LightGBM_BAG_L1  -33.917339       4.111467   58.640366                4.111467          58.640366            1       True          4\n",
            "7        LightGBMXT_BAG_L1  -34.345997      16.835405  127.072782               16.835405         127.072782            1       True          3\n",
            "8          CatBoost_BAG_L1  -35.000378       0.250160  161.637249                0.250160         161.637249            1       True          6\n",
            "9   RandomForestMSE_BAG_L1  -38.306120       0.600857   22.021074                0.600857          22.021074            1       True          5\n",
            "10    ExtraTreesMSE_BAG_L1  -38.311570       0.578968   13.442902                0.578968          13.442902            1       True          7\n",
            "11   KNeighborsDist_BAG_L1  -84.125061       0.060113    0.039874                0.060113           0.039874            1       True          2\n",
            "12   KNeighborsUnif_BAG_L1 -101.546199       0.050803    0.043570                0.050803           0.043570            1       True          1\n",
            "Number of models trained: 13\n",
            "Types of models trained:\n",
            "{'StackerEnsembleModel_KNN', 'StackerEnsembleModel_LGB', 'WeightedEnsembleModel', 'StackerEnsembleModel_RF', 'StackerEnsembleModel_XT', 'StackerEnsembleModel_CatBoost'}\n",
            "Bagging used: True  (with 8 folds)\n",
            "Multi-layer stack-ensembling used: True  (with 3 levels)\n",
            "Feature Metadata (Processed):\n",
            "(raw dtype, special dtypes):\n",
            "('category', [])             : 2 | ['season', 'weather']\n",
            "('float', [])                : 3 | ['temp', 'atemp', 'windspeed']\n",
            "('int', [])                  : 4 | ['humidity', 'Month', 'Day', 'Hour']\n",
            "('int', ['bool'])            : 3 | ['holiday', 'workingday', 'Year']\n",
            "('int', ['datetime_as_int']) : 5 | ['datetime', 'datetime.year', 'datetime.month', 'datetime.day', 'datetime.dayofweek']\n",
            "*** End of fit() summary ***\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/autogluon/core/utils/plots.py:138: UserWarning: AutoGluon summary plots cannot be created because bokeh is not installed. To see plots, please do: \"pip install bokeh==2.0.1\"\n",
            "  warnings.warn('AutoGluon summary plots cannot be created because bokeh is not installed. To see plots, please do: \"pip install bokeh==2.0.1\"')\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'model_types': {'KNeighborsUnif_BAG_L1': 'StackerEnsembleModel_KNN',\n",
              "  'KNeighborsDist_BAG_L1': 'StackerEnsembleModel_KNN',\n",
              "  'LightGBMXT_BAG_L1': 'StackerEnsembleModel_LGB',\n",
              "  'LightGBM_BAG_L1': 'StackerEnsembleModel_LGB',\n",
              "  'RandomForestMSE_BAG_L1': 'StackerEnsembleModel_RF',\n",
              "  'CatBoost_BAG_L1': 'StackerEnsembleModel_CatBoost',\n",
              "  'ExtraTreesMSE_BAG_L1': 'StackerEnsembleModel_XT',\n",
              "  'WeightedEnsemble_L2': 'WeightedEnsembleModel',\n",
              "  'LightGBMXT_BAG_L2': 'StackerEnsembleModel_LGB',\n",
              "  'LightGBM_BAG_L2': 'StackerEnsembleModel_LGB',\n",
              "  'RandomForestMSE_BAG_L2': 'StackerEnsembleModel_RF',\n",
              "  'CatBoost_BAG_L2': 'StackerEnsembleModel_CatBoost',\n",
              "  'WeightedEnsemble_L3': 'WeightedEnsembleModel'},\n",
              " 'model_performance': {'KNeighborsUnif_BAG_L1': -101.54619908446061,\n",
              "  'KNeighborsDist_BAG_L1': -84.12506123181602,\n",
              "  'LightGBMXT_BAG_L1': -34.34599701170154,\n",
              "  'LightGBM_BAG_L1': -33.91733862651761,\n",
              "  'RandomForestMSE_BAG_L1': -38.30612025079756,\n",
              "  'CatBoost_BAG_L1': -35.000378307154975,\n",
              "  'ExtraTreesMSE_BAG_L1': -38.31157013220686,\n",
              "  'WeightedEnsemble_L2': -32.23427701331103,\n",
              "  'LightGBMXT_BAG_L2': -31.27436240289559,\n",
              "  'LightGBM_BAG_L2': -30.558901531571,\n",
              "  'RandomForestMSE_BAG_L2': -31.672754671107327,\n",
              "  'CatBoost_BAG_L2': -31.051734794699396,\n",
              "  'WeightedEnsemble_L3': -30.335977826460173},\n",
              " 'model_best': 'WeightedEnsemble_L3',\n",
              " 'model_paths': {'KNeighborsUnif_BAG_L1': 'AutogluonModels/ag-20230606_190207/models/KNeighborsUnif_BAG_L1/',\n",
              "  'KNeighborsDist_BAG_L1': 'AutogluonModels/ag-20230606_190207/models/KNeighborsDist_BAG_L1/',\n",
              "  'LightGBMXT_BAG_L1': 'AutogluonModels/ag-20230606_190207/models/LightGBMXT_BAG_L1/',\n",
              "  'LightGBM_BAG_L1': 'AutogluonModels/ag-20230606_190207/models/LightGBM_BAG_L1/',\n",
              "  'RandomForestMSE_BAG_L1': 'AutogluonModels/ag-20230606_190207/models/RandomForestMSE_BAG_L1/',\n",
              "  'CatBoost_BAG_L1': 'AutogluonModels/ag-20230606_190207/models/CatBoost_BAG_L1/',\n",
              "  'ExtraTreesMSE_BAG_L1': 'AutogluonModels/ag-20230606_190207/models/ExtraTreesMSE_BAG_L1/',\n",
              "  'WeightedEnsemble_L2': 'AutogluonModels/ag-20230606_190207/models/WeightedEnsemble_L2/',\n",
              "  'LightGBMXT_BAG_L2': 'AutogluonModels/ag-20230606_190207/models/LightGBMXT_BAG_L2/',\n",
              "  'LightGBM_BAG_L2': 'AutogluonModels/ag-20230606_190207/models/LightGBM_BAG_L2/',\n",
              "  'RandomForestMSE_BAG_L2': 'AutogluonModels/ag-20230606_190207/models/RandomForestMSE_BAG_L2/',\n",
              "  'CatBoost_BAG_L2': 'AutogluonModels/ag-20230606_190207/models/CatBoost_BAG_L2/',\n",
              "  'WeightedEnsemble_L3': 'AutogluonModels/ag-20230606_190207/models/WeightedEnsemble_L3/'},\n",
              " 'model_fit_times': {'KNeighborsUnif_BAG_L1': 0.04357004165649414,\n",
              "  'KNeighborsDist_BAG_L1': 0.039873600006103516,\n",
              "  'LightGBMXT_BAG_L1': 127.07278227806091,\n",
              "  'LightGBM_BAG_L1': 58.64036583900452,\n",
              "  'RandomForestMSE_BAG_L1': 22.021073579788208,\n",
              "  'CatBoost_BAG_L1': 161.6372492313385,\n",
              "  'ExtraTreesMSE_BAG_L1': 13.442901849746704,\n",
              "  'WeightedEnsemble_L2': 0.39421677589416504,\n",
              "  'LightGBMXT_BAG_L2': 44.65477967262268,\n",
              "  'LightGBM_BAG_L2': 37.43970537185669,\n",
              "  'RandomForestMSE_BAG_L2': 56.68990397453308,\n",
              "  'CatBoost_BAG_L2': 50.751193046569824,\n",
              "  'WeightedEnsemble_L3': 0.41748929023742676},\n",
              " 'model_pred_times': {'KNeighborsUnif_BAG_L1': 0.05080294609069824,\n",
              "  'KNeighborsDist_BAG_L1': 0.06011319160461426,\n",
              "  'LightGBMXT_BAG_L1': 16.835404634475708,\n",
              "  'LightGBM_BAG_L1': 4.111467361450195,\n",
              "  'RandomForestMSE_BAG_L1': 0.6008572578430176,\n",
              "  'CatBoost_BAG_L1': 0.25016045570373535,\n",
              "  'ExtraTreesMSE_BAG_L1': 0.578967809677124,\n",
              "  'WeightedEnsemble_L2': 0.0007660388946533203,\n",
              "  'LightGBMXT_BAG_L2': 1.3585593700408936,\n",
              "  'LightGBM_BAG_L2': 0.37854814529418945,\n",
              "  'RandomForestMSE_BAG_L2': 0.938605546951294,\n",
              "  'CatBoost_BAG_L2': 0.5415458679199219,\n",
              "  'WeightedEnsemble_L3': 0.0010585784912109375},\n",
              " 'num_bag_folds': 8,\n",
              " 'max_stack_level': 3,\n",
              " 'model_hyperparams': {'KNeighborsUnif_BAG_L1': {'use_orig_features': True,\n",
              "   'max_base_models': 25,\n",
              "   'max_base_models_per_type': 5,\n",
              "   'save_bag_folds': True,\n",
              "   'use_child_oof': True},\n",
              "  'KNeighborsDist_BAG_L1': {'use_orig_features': True,\n",
              "   'max_base_models': 25,\n",
              "   'max_base_models_per_type': 5,\n",
              "   'save_bag_folds': True,\n",
              "   'use_child_oof': True},\n",
              "  'LightGBMXT_BAG_L1': {'use_orig_features': True,\n",
              "   'max_base_models': 25,\n",
              "   'max_base_models_per_type': 5,\n",
              "   'save_bag_folds': True},\n",
              "  'LightGBM_BAG_L1': {'use_orig_features': True,\n",
              "   'max_base_models': 25,\n",
              "   'max_base_models_per_type': 5,\n",
              "   'save_bag_folds': True},\n",
              "  'RandomForestMSE_BAG_L1': {'use_orig_features': True,\n",
              "   'max_base_models': 25,\n",
              "   'max_base_models_per_type': 5,\n",
              "   'save_bag_folds': True,\n",
              "   'use_child_oof': True},\n",
              "  'CatBoost_BAG_L1': {'use_orig_features': True,\n",
              "   'max_base_models': 25,\n",
              "   'max_base_models_per_type': 5,\n",
              "   'save_bag_folds': True},\n",
              "  'ExtraTreesMSE_BAG_L1': {'use_orig_features': True,\n",
              "   'max_base_models': 25,\n",
              "   'max_base_models_per_type': 5,\n",
              "   'save_bag_folds': True,\n",
              "   'use_child_oof': True},\n",
              "  'WeightedEnsemble_L2': {'use_orig_features': False,\n",
              "   'max_base_models': 25,\n",
              "   'max_base_models_per_type': 5,\n",
              "   'save_bag_folds': True},\n",
              "  'LightGBMXT_BAG_L2': {'use_orig_features': True,\n",
              "   'max_base_models': 25,\n",
              "   'max_base_models_per_type': 5,\n",
              "   'save_bag_folds': True},\n",
              "  'LightGBM_BAG_L2': {'use_orig_features': True,\n",
              "   'max_base_models': 25,\n",
              "   'max_base_models_per_type': 5,\n",
              "   'save_bag_folds': True},\n",
              "  'RandomForestMSE_BAG_L2': {'use_orig_features': True,\n",
              "   'max_base_models': 25,\n",
              "   'max_base_models_per_type': 5,\n",
              "   'save_bag_folds': True,\n",
              "   'use_child_oof': True},\n",
              "  'CatBoost_BAG_L2': {'use_orig_features': True,\n",
              "   'max_base_models': 25,\n",
              "   'max_base_models_per_type': 5,\n",
              "   'save_bag_folds': True},\n",
              "  'WeightedEnsemble_L3': {'use_orig_features': False,\n",
              "   'max_base_models': 25,\n",
              "   'max_base_models_per_type': 5,\n",
              "   'save_bag_folds': True}},\n",
              " 'leaderboard':                      model   score_val  pred_time_val    fit_time  \\\n",
              " 0      WeightedEnsemble_L3  -30.335978      25.706091  572.850888   \n",
              " 1          LightGBM_BAG_L2  -30.558902      22.866322  420.337522   \n",
              " 2          CatBoost_BAG_L2  -31.051735      23.029320  433.649009   \n",
              " 3        LightGBMXT_BAG_L2  -31.274362      23.846333  427.552596   \n",
              " 4   RandomForestMSE_BAG_L2  -31.672755      23.426379  439.587720   \n",
              " 5      WeightedEnsemble_L2  -32.234277      21.858769  369.805561   \n",
              " 6          LightGBM_BAG_L1  -33.917339       4.111467   58.640366   \n",
              " 7        LightGBMXT_BAG_L1  -34.345997      16.835405  127.072782   \n",
              " 8          CatBoost_BAG_L1  -35.000378       0.250160  161.637249   \n",
              " 9   RandomForestMSE_BAG_L1  -38.306120       0.600857   22.021074   \n",
              " 10    ExtraTreesMSE_BAG_L1  -38.311570       0.578968   13.442902   \n",
              " 11   KNeighborsDist_BAG_L1  -84.125061       0.060113    0.039874   \n",
              " 12   KNeighborsUnif_BAG_L1 -101.546199       0.050803    0.043570   \n",
              " \n",
              "     pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  \\\n",
              " 0                 0.001059           0.417489            3       True   \n",
              " 1                 0.378548          37.439705            2       True   \n",
              " 2                 0.541546          50.751193            2       True   \n",
              " 3                 1.358559          44.654780            2       True   \n",
              " 4                 0.938606          56.689904            2       True   \n",
              " 5                 0.000766           0.394217            2       True   \n",
              " 6                 4.111467          58.640366            1       True   \n",
              " 7                16.835405         127.072782            1       True   \n",
              " 8                 0.250160         161.637249            1       True   \n",
              " 9                 0.600857          22.021074            1       True   \n",
              " 10                0.578968          13.442902            1       True   \n",
              " 11                0.060113           0.039874            1       True   \n",
              " 12                0.050803           0.043570            1       True   \n",
              " \n",
              "     fit_order  \n",
              " 0          13  \n",
              " 1          10  \n",
              " 2          12  \n",
              " 3           9  \n",
              " 4          11  \n",
              " 5           8  \n",
              " 6           4  \n",
              " 7           3  \n",
              " 8           6  \n",
              " 9           5  \n",
              " 10          7  \n",
              " 11          2  \n",
              " 12          1  }"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "predictor_new_features.fit_summary()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions_new = predictor_new_features.predict(test)\n",
        "predictions_new"
      ],
      "metadata": {
        "id": "T2dnN3oRNk8k",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6253b7b1-c370-4d34-823f-f7bf81cbb76c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0        15.429430\n",
              "1        11.192017\n",
              "2        10.440520\n",
              "3         9.353924\n",
              "4         8.240405\n",
              "           ...    \n",
              "6488    295.579285\n",
              "6489    211.223511\n",
              "6490    154.987183\n",
              "6491    111.588455\n",
              "6492     72.517509\n",
              "Name: count, Length: 6493, dtype: float32"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions_new.describe()"
      ],
      "metadata": {
        "id": "xpSHSRS8OxkX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a1acfd1d-9a2d-4c19-b56a-ae4e748d7220"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "count    6493.000000\n",
              "mean      163.081284\n",
              "std       143.176254\n",
              "min         2.899641\n",
              "25%        50.414772\n",
              "50%       125.630966\n",
              "75%       233.486786\n",
              "max       824.469238\n",
              "Name: count, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_negative_values_new = (predictions_new < 0).sum().sum()\n",
        "print(num_negative_values_new)"
      ],
      "metadata": {
        "id": "QkGtsz_ZOtI0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "51e14c35-c956-4320-b672-d9ee37112c87"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "la4tZEtYrRm0"
      },
      "outputs": [],
      "source": [
        "# Remember to set all negative values to zero\n",
        "\n",
        "predictions_new[predictions_new < 0] = 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "POXwUI_3rRm1"
      },
      "outputs": [],
      "source": [
        "# Same submitting predictions\n",
        "submission_new_features = pd.DataFrame()\n",
        "submission_new_features['datetime'] = test['datetime']\n",
        "submission_new_features[\"count\"] = predictions_new\n",
        "submission_new_features.to_csv(\"submission_new_features.csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FJBuGCc8rRm1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "33a731dc-2684-4324-d810-358e9ac57c46"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100% 188k/188k [00:03<00:00, 58.0kB/s]\n",
            "Successfully submitted to Bike Sharing Demand"
          ]
        }
      ],
      "source": [
        "!kaggle competitions submit -c bike-sharing-demand -f submission_new_features.csv -m \"new features\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7Ejtvz7IrRm1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "97405c86-732f-4e97-a47f-09bb25d47f8e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fileName                     date                 description                        status    publicScore  privateScore  \n",
            "---------------------------  -------------------  ---------------------------------  --------  -----------  ------------  \n",
            "submission_new_features.csv  2023-06-06 19:14:26  new features                       complete  0.62040      0.62040       \n",
            "submission.csv               2023-06-06 19:00:16  first raw submission               complete  1.80288      1.80288       \n",
            "submission_new_hpo.csv       2023-06-06 17:53:05  new features with hyperparameters  complete  0.55740      0.55740       \n",
            "submission_new_features.csv  2023-06-06 17:38:40  new features                       complete  0.63634      0.63634       \n"
          ]
        }
      ],
      "source": [
        "!kaggle competitions submissions -c bike-sharing-demand | tail -n +1 | head -n 6"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VF2ob91yrRm1"
      },
      "source": [
        "#### New Score of `?`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KhUgAai8rRm1"
      },
      "source": [
        "## Step 6: Hyper parameter optimization\n",
        "* There are many options for hyper parameter optimization.\n",
        "* Options are to change the AutoGluon higher level parameters or the individual model hyperparameters.\n",
        "* The hyperparameters of the models themselves that are in AutoGluon. Those need the `hyperparameter` and `hyperparameter_tune_kwargs` arguments."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from autogluon.tabular import TabularPredictor\n",
        "import autogluon.core as ag\n",
        "\n",
        "# Define the hyperparameters for NN with dropout, activation function, and learning rate\n",
        "nn_hyperparameters = {\n",
        "    'num_epochs': 10,\n",
        "    'layers': ag.space.Categorical([100], [1000], [200, 100], [300, 200, 100]),\n",
        "    'learning_rate': ag.space.Real(1e-4, 1e-2, default=1e-3),\n",
        "    'dropout_prob': ag.space.Real(0.0, 0.5, default=0.1),\n",
        "    'activation': ag.space.Categorical('relu', 'tanh')\n",
        "}\n",
        "\n",
        "# Define the hyperparameters for GBM with number of boosting rounds and learning rate\n",
        "gbm_hyperparameters = {\n",
        "    'num_boost_round' : ag.space.Int(lower=100, upper=500, default=100),\n",
        "    'num_leaves' : ag.space.Int(lower=6, upper=10),\n",
        "    'learning_rate': ag.space.Real(1e-4, 1e-2, default=1e-3)\n",
        "}\n",
        "#define xgb hyperparameters\n",
        "xgb_hyperparameters = {\n",
        "    'n_estimators' : ag.space.Int(lower=100, upper=500, default=100),\n",
        "    'max_depth' : ag.space.Int(lower=6, upper=10, default=6),\n",
        "    'eta' : ag.space.Real(lower=0.01, upper=0.3, log=True)\n",
        "}\n",
        "\n",
        "# Set the hyperparameter tune kwargs for Hyperband search strategy\n",
        "hyperparameter_tune_kwargs = {\n",
        "    'searcher': 'auto',\n",
        "    'max_trials': 15,\n",
        "    'scheduler': 'local'\n",
        "}\n",
        "\n",
        "# Fit the TabularPredictor with NN and GBM hyperparameters, including dropout, activation function, and Hyperband search strategy\n",
        "predictor_new_hpo = TabularPredictor(\n",
        "    label='count',\n",
        "    eval_metric='root_mean_squared_error',\n",
        "    problem_type='regression',\n",
        "    ).fit(\n",
        "    train,\n",
        "    time_limit=600,\n",
        "    hyperparameters={\n",
        "        'NN': nn_hyperparameters,\n",
        "        'GBM': gbm_hyperparameters,\n",
        "        'XGB' : xgb_hyperparameters\n",
        "    },\n",
        "    hyperparameter_tune_kwargs=hyperparameter_tune_kwargs,\n",
        "    presets='best_quality'\n",
        ")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "86pb27Y8ZbRr",
        "outputId": "3f7633e1-5c6a-4900-fae1-9a8d0b3d344f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No path specified. Models will be saved in: \"AutogluonModels/ag-20230606_191440/\"\n",
            "Presets specified: ['best_quality']\n",
            "Warning: hyperparameter tuning is currently experimental and may cause the process to hang.\n",
            "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=20\n",
            "Beginning AutoGluon training ... Time limit = 600s\n",
            "AutoGluon will save models to \"AutogluonModels/ag-20230606_191440/\"\n",
            "AutoGluon Version:  0.7.0\n",
            "Python Version:     3.10.11\n",
            "Operating System:   Linux\n",
            "Platform Machine:   x86_64\n",
            "Platform Version:   #1 SMP Sat Apr 29 09:15:28 UTC 2023\n",
            "Train Data Rows:    10886\n",
            "Train Data Columns: 13\n",
            "Label Column: count\n",
            "Preprocessing data ...\n",
            "Using Feature Generators to preprocess the data ...\n",
            "Fitting AutoMLPipelineFeatureGenerator...\n",
            "\tAvailable Memory:                    11043.52 MB\n",
            "\tTrain Data (Original)  Memory Usage: 0.98 MB (0.0% of available memory)\n",
            "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
            "\tStage 1 Generators:\n",
            "\t\tFitting AsTypeFeatureGenerator...\n",
            "\t\t\tNote: Converting 3 features to boolean dtype as they only contain 2 unique values.\n",
            "\tStage 2 Generators:\n",
            "\t\tFitting FillNaFeatureGenerator...\n",
            "\tStage 3 Generators:\n",
            "\t\tFitting IdentityFeatureGenerator...\n",
            "\t\tFitting CategoryFeatureGenerator...\n",
            "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
            "\t\tFitting DatetimeFeatureGenerator...\n",
            "\tStage 4 Generators:\n",
            "\t\tFitting DropUniqueFeatureGenerator...\n",
            "\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t('category', []) : 2 | ['season', 'weather']\n",
            "\t\t('datetime', []) : 1 | ['datetime']\n",
            "\t\t('float', [])    : 3 | ['temp', 'atemp', 'windspeed']\n",
            "\t\t('int', [])      : 7 | ['holiday', 'workingday', 'humidity', 'Year', 'Month', ...]\n",
            "\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t('category', [])             : 2 | ['season', 'weather']\n",
            "\t\t('float', [])                : 3 | ['temp', 'atemp', 'windspeed']\n",
            "\t\t('int', [])                  : 4 | ['humidity', 'Month', 'Day', 'Hour']\n",
            "\t\t('int', ['bool'])            : 3 | ['holiday', 'workingday', 'Year']\n",
            "\t\t('int', ['datetime_as_int']) : 5 | ['datetime', 'datetime.year', 'datetime.month', 'datetime.day', 'datetime.dayofweek']\n",
            "\t0.2s = Fit runtime\n",
            "\t13 features in original data used to generate 17 features in processed data.\n",
            "\tTrain Data (Processed) Memory Usage: 1.1 MB (0.0% of available memory)\n",
            "Data preprocessing and feature engineering runtime = 0.29s ...\n",
            "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
            "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
            "\tTo change this, specify the eval_metric parameter of Predictor()\n",
            "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
            "\tWARNING: \"NN\" model has been deprecated in v0.4.0 and renamed to \"NN_MXNET\". Starting in v0.6.0, specifying \"NN\" or \"NN_MXNET\" will raise an exception. Consider instead specifying \"NN_TORCH\".\n",
            "Fitting 3 L1 models ...\n",
            "Hyperparameter tuning model: LightGBM_BAG_L1 ... Tuning model for up to 119.91s of the 599.7s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
            "\tStopping HPO to satisfy time limit...\n",
            "Fitted model: LightGBM_BAG_L1/T1 ...\n",
            "\t-171.4455\t = Validation score   (-root_mean_squared_error)\n",
            "\t32.2s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Fitted model: LightGBM_BAG_L1/T2 ...\n",
            "\t-82.9132\t = Validation score   (-root_mean_squared_error)\n",
            "\t37.92s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Fitted model: LightGBM_BAG_L1/T3 ...\n",
            "\t-96.4464\t = Validation score   (-root_mean_squared_error)\n",
            "\t36.74s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Hyperparameter tuning model: XGBoost_BAG_L1 ... Tuning model for up to 119.91s of the 492.69s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
            "\tStopping HPO to satisfy time limit...\n",
            "Fitted model: XGBoost_BAG_L1/T1 ...\n",
            "\t-38.07\t = Validation score   (-root_mean_squared_error)\n",
            "\t26.71s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Fitted model: XGBoost_BAG_L1/T2 ...\n",
            "\t-35.2516\t = Validation score   (-root_mean_squared_error)\n",
            "\t44.25s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Fitted model: XGBoost_BAG_L1/T3 ...\n",
            "\t-35.1269\t = Validation score   (-root_mean_squared_error)\n",
            "\t33.37s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Hyperparameter tuning model: NeuralNetMXNet_BAG_L1 ... Tuning model for up to 119.91s of the 388.27s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
            "\u001b[36mray::_ray_fit()\u001b[39m (pid=16906, ip=172.28.0.12)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 374, in _ray_fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold,\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 703, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py\", line 156, in _fit\n",
            "    train_dataset, val_dataset = self.generate_datasets(X=X, y=y, params=params, X_val=X_val, y_val=y_val)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py\", line 446, in generate_datasets\n",
            "    train_dataset = self.process_train_data(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py\", line 511, in process_train_data\n",
            "    df = self.processor.fit_transform(df) # 2D numpy array\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n",
            "    data_to_wrap = f(self, X, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py\", line 727, in fit_transform\n",
            "    result = self._fit_transform(X, y, _fit_transform_one)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py\", line 658, in _fit_transform\n",
            "    return Parallel(n_jobs=self.n_jobs)(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\", line 63, in __call__\n",
            "    return super().__call__(iterable_with_config)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 1088, in __call__\n",
            "    while self.dispatch_one_batch(iterator):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 901, in dispatch_one_batch\n",
            "    self._dispatch(tasks)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 819, in _dispatch\n",
            "    job = self._backend.apply_async(batch, callback=cb)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
            "    result = ImmediateResult(func)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py\", line 597, in __init__\n",
            "    self.results = batch()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 288, in __call__\n",
            "    return [func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 288, in <listcomp>\n",
            "    return [func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\", line 123, in __call__\n",
            "    return self.function(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 893, in _fit_transform_one\n",
            "    res = transformer.fit_transform(X, y, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 437, in fit_transform\n",
            "    Xt = self._fit(X, y, **fit_params_steps)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 359, in _fit\n",
            "    X, fitted_transformer = fit_transform_one_cached(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/memory.py\", line 349, in __call__\n",
            "    return self.func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 893, in _fit_transform_one\n",
            "    res = transformer.fit_transform(X, y, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n",
            "    data_to_wrap = f(self, X, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/base.py\", line 878, in fit_transform\n",
            "    return self.fit(X, **fit_params).transform(X)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/impute/_base.py\", line 408, in fit\n",
            "    raise ValueError(\n",
            "ValueError: 'fill_value'=!missing! is invalid. Expected a numerical value when imputing numerical data\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 43, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 101, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 703, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 154, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 248, in _fit\n",
            "    self._fit_folds(X=X, y=y, model_base=model_base, X_pseudo=X_pseudo, y_pseudo=y_pseudo,\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 540, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 537, in after_all_folds_scheduled\n",
            "    raise processed_exception\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 505, in after_all_folds_scheduled\n",
            "    time_end_fit, predict_time, predict_1_time = self.ray.get(finished)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/client_mode_hook.py\", line 105, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/worker.py\", line 2309, in get\n",
            "    raise value.as_instanceof_cause()\n",
            "ray.exceptions.RayTaskError(ValueError): \u001b[36mray::_ray_fit()\u001b[39m (pid=16906, ip=172.28.0.12)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 374, in _ray_fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold,\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 703, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py\", line 156, in _fit\n",
            "    train_dataset, val_dataset = self.generate_datasets(X=X, y=y, params=params, X_val=X_val, y_val=y_val)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py\", line 446, in generate_datasets\n",
            "    train_dataset = self.process_train_data(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py\", line 511, in process_train_data\n",
            "    df = self.processor.fit_transform(df) # 2D numpy array\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n",
            "    data_to_wrap = f(self, X, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py\", line 727, in fit_transform\n",
            "    result = self._fit_transform(X, y, _fit_transform_one)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py\", line 658, in _fit_transform\n",
            "    return Parallel(n_jobs=self.n_jobs)(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\", line 63, in __call__\n",
            "    return super().__call__(iterable_with_config)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 1088, in __call__\n",
            "    while self.dispatch_one_batch(iterator):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 901, in dispatch_one_batch\n",
            "    self._dispatch(tasks)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 819, in _dispatch\n",
            "    job = self._backend.apply_async(batch, callback=cb)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
            "    result = ImmediateResult(func)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py\", line 597, in __init__\n",
            "    self.results = batch()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 288, in __call__\n",
            "    return [func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 288, in <listcomp>\n",
            "    return [func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\", line 123, in __call__\n",
            "    return self.function(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 893, in _fit_transform_one\n",
            "    res = transformer.fit_transform(X, y, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 437, in fit_transform\n",
            "    Xt = self._fit(X, y, **fit_params_steps)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 359, in _fit\n",
            "    X, fitted_transformer = fit_transform_one_cached(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/memory.py\", line 349, in __call__\n",
            "    return self.func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 893, in _fit_transform_one\n",
            "    res = transformer.fit_transform(X, y, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n",
            "    data_to_wrap = f(self, X, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/base.py\", line 878, in fit_transform\n",
            "    return self.fit(X, **fit_params).transform(X)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/impute/_base.py\", line 408, in fit\n",
            "    raise ValueError(\n",
            "ValueError: 'fill_value'=!missing! is invalid. Expected a numerical value when imputing numerical data\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
            "2023-06-06 19:18:23,710\tERROR worker.py:400 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
            "\u001b[36mray::_ray_fit()\u001b[39m (pid=17015, ip=172.28.0.12)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 374, in _ray_fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold,\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 703, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py\", line 156, in _fit\n",
            "    train_dataset, val_dataset = self.generate_datasets(X=X, y=y, params=params, X_val=X_val, y_val=y_val)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py\", line 446, in generate_datasets\n",
            "    train_dataset = self.process_train_data(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py\", line 511, in process_train_data\n",
            "    df = self.processor.fit_transform(df) # 2D numpy array\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n",
            "    data_to_wrap = f(self, X, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py\", line 727, in fit_transform\n",
            "    result = self._fit_transform(X, y, _fit_transform_one)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py\", line 658, in _fit_transform\n",
            "    return Parallel(n_jobs=self.n_jobs)(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\", line 63, in __call__\n",
            "    return super().__call__(iterable_with_config)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 1088, in __call__\n",
            "    while self.dispatch_one_batch(iterator):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 901, in dispatch_one_batch\n",
            "    self._dispatch(tasks)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 819, in _dispatch\n",
            "    job = self._backend.apply_async(batch, callback=cb)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
            "    result = ImmediateResult(func)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py\", line 597, in __init__\n",
            "    self.results = batch()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 288, in __call__\n",
            "    return [func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 288, in <listcomp>\n",
            "    return [func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\", line 123, in __call__\n",
            "    return self.function(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 893, in _fit_transform_one\n",
            "    res = transformer.fit_transform(X, y, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 437, in fit_transform\n",
            "    Xt = self._fit(X, y, **fit_params_steps)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 359, in _fit\n",
            "    X, fitted_transformer = fit_transform_one_cached(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/memory.py\", line 349, in __call__\n",
            "    return self.func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 893, in _fit_transform_one\n",
            "    res = transformer.fit_transform(X, y, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n",
            "    data_to_wrap = f(self, X, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/base.py\", line 878, in fit_transform\n",
            "    return self.fit(X, **fit_params).transform(X)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/impute/_base.py\", line 408, in fit\n",
            "    raise ValueError(\n",
            "ValueError: 'fill_value'=!missing! is invalid. Expected a numerical value when imputing numerical data\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 43, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 101, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 703, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 154, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 248, in _fit\n",
            "    self._fit_folds(X=X, y=y, model_base=model_base, X_pseudo=X_pseudo, y_pseudo=y_pseudo,\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 540, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 537, in after_all_folds_scheduled\n",
            "    raise processed_exception\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 505, in after_all_folds_scheduled\n",
            "    time_end_fit, predict_time, predict_1_time = self.ray.get(finished)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/client_mode_hook.py\", line 105, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/worker.py\", line 2309, in get\n",
            "    raise value.as_instanceof_cause()\n",
            "ray.exceptions.RayTaskError(ValueError): \u001b[36mray::_ray_fit()\u001b[39m (pid=17015, ip=172.28.0.12)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 374, in _ray_fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold,\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 703, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py\", line 156, in _fit\n",
            "    train_dataset, val_dataset = self.generate_datasets(X=X, y=y, params=params, X_val=X_val, y_val=y_val)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py\", line 446, in generate_datasets\n",
            "    train_dataset = self.process_train_data(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py\", line 511, in process_train_data\n",
            "    df = self.processor.fit_transform(df) # 2D numpy array\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n",
            "    data_to_wrap = f(self, X, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py\", line 727, in fit_transform\n",
            "    result = self._fit_transform(X, y, _fit_transform_one)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py\", line 658, in _fit_transform\n",
            "    return Parallel(n_jobs=self.n_jobs)(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\", line 63, in __call__\n",
            "    return super().__call__(iterable_with_config)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 1088, in __call__\n",
            "    while self.dispatch_one_batch(iterator):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 901, in dispatch_one_batch\n",
            "    self._dispatch(tasks)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 819, in _dispatch\n",
            "    job = self._backend.apply_async(batch, callback=cb)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
            "    result = ImmediateResult(func)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py\", line 597, in __init__\n",
            "    self.results = batch()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 288, in __call__\n",
            "    return [func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 288, in <listcomp>\n",
            "    return [func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\", line 123, in __call__\n",
            "    return self.function(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 893, in _fit_transform_one\n",
            "    res = transformer.fit_transform(X, y, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 437, in fit_transform\n",
            "    Xt = self._fit(X, y, **fit_params_steps)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 359, in _fit\n",
            "    X, fitted_transformer = fit_transform_one_cached(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/memory.py\", line 349, in __call__\n",
            "    return self.func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 893, in _fit_transform_one\n",
            "    res = transformer.fit_transform(X, y, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n",
            "    data_to_wrap = f(self, X, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/base.py\", line 878, in fit_transform\n",
            "    return self.fit(X, **fit_params).transform(X)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/impute/_base.py\", line 408, in fit\n",
            "    raise ValueError(\n",
            "ValueError: 'fill_value'=!missing! is invalid. Expected a numerical value when imputing numerical data\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
            "2023-06-06 19:18:33,899\tERROR worker.py:400 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
            "\u001b[36mray::_ray_fit()\u001b[39m (pid=17121, ip=172.28.0.12)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 374, in _ray_fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold,\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 703, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py\", line 156, in _fit\n",
            "    train_dataset, val_dataset = self.generate_datasets(X=X, y=y, params=params, X_val=X_val, y_val=y_val)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py\", line 446, in generate_datasets\n",
            "    train_dataset = self.process_train_data(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py\", line 511, in process_train_data\n",
            "    df = self.processor.fit_transform(df) # 2D numpy array\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n",
            "    data_to_wrap = f(self, X, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py\", line 727, in fit_transform\n",
            "    result = self._fit_transform(X, y, _fit_transform_one)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py\", line 658, in _fit_transform\n",
            "    return Parallel(n_jobs=self.n_jobs)(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\", line 63, in __call__\n",
            "    return super().__call__(iterable_with_config)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 1088, in __call__\n",
            "    while self.dispatch_one_batch(iterator):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 901, in dispatch_one_batch\n",
            "    self._dispatch(tasks)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 819, in _dispatch\n",
            "    job = self._backend.apply_async(batch, callback=cb)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
            "    result = ImmediateResult(func)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py\", line 597, in __init__\n",
            "    self.results = batch()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 288, in __call__\n",
            "    return [func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 288, in <listcomp>\n",
            "    return [func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\", line 123, in __call__\n",
            "    return self.function(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 893, in _fit_transform_one\n",
            "    res = transformer.fit_transform(X, y, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 437, in fit_transform\n",
            "    Xt = self._fit(X, y, **fit_params_steps)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 359, in _fit\n",
            "    X, fitted_transformer = fit_transform_one_cached(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/memory.py\", line 349, in __call__\n",
            "    return self.func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 893, in _fit_transform_one\n",
            "    res = transformer.fit_transform(X, y, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n",
            "    data_to_wrap = f(self, X, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/base.py\", line 878, in fit_transform\n",
            "    return self.fit(X, **fit_params).transform(X)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/impute/_base.py\", line 408, in fit\n",
            "    raise ValueError(\n",
            "ValueError: 'fill_value'=!missing! is invalid. Expected a numerical value when imputing numerical data\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 43, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 101, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 703, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 154, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 248, in _fit\n",
            "    self._fit_folds(X=X, y=y, model_base=model_base, X_pseudo=X_pseudo, y_pseudo=y_pseudo,\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 540, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 537, in after_all_folds_scheduled\n",
            "    raise processed_exception\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 505, in after_all_folds_scheduled\n",
            "    time_end_fit, predict_time, predict_1_time = self.ray.get(finished)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/client_mode_hook.py\", line 105, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/worker.py\", line 2309, in get\n",
            "    raise value.as_instanceof_cause()\n",
            "ray.exceptions.RayTaskError(ValueError): \u001b[36mray::_ray_fit()\u001b[39m (pid=17121, ip=172.28.0.12)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 374, in _ray_fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold,\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 703, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py\", line 156, in _fit\n",
            "    train_dataset, val_dataset = self.generate_datasets(X=X, y=y, params=params, X_val=X_val, y_val=y_val)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py\", line 446, in generate_datasets\n",
            "    train_dataset = self.process_train_data(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py\", line 511, in process_train_data\n",
            "    df = self.processor.fit_transform(df) # 2D numpy array\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n",
            "    data_to_wrap = f(self, X, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py\", line 727, in fit_transform\n",
            "    result = self._fit_transform(X, y, _fit_transform_one)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py\", line 658, in _fit_transform\n",
            "    return Parallel(n_jobs=self.n_jobs)(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\", line 63, in __call__\n",
            "    return super().__call__(iterable_with_config)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 1088, in __call__\n",
            "    while self.dispatch_one_batch(iterator):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 901, in dispatch_one_batch\n",
            "    self._dispatch(tasks)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 819, in _dispatch\n",
            "    job = self._backend.apply_async(batch, callback=cb)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
            "    result = ImmediateResult(func)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py\", line 597, in __init__\n",
            "    self.results = batch()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 288, in __call__\n",
            "    return [func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 288, in <listcomp>\n",
            "    return [func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\", line 123, in __call__\n",
            "    return self.function(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 893, in _fit_transform_one\n",
            "    res = transformer.fit_transform(X, y, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 437, in fit_transform\n",
            "    Xt = self._fit(X, y, **fit_params_steps)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 359, in _fit\n",
            "    X, fitted_transformer = fit_transform_one_cached(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/memory.py\", line 349, in __call__\n",
            "    return self.func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 893, in _fit_transform_one\n",
            "    res = transformer.fit_transform(X, y, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n",
            "    data_to_wrap = f(self, X, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/base.py\", line 878, in fit_transform\n",
            "    return self.fit(X, **fit_params).transform(X)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/impute/_base.py\", line 408, in fit\n",
            "    raise ValueError(\n",
            "ValueError: 'fill_value'=!missing! is invalid. Expected a numerical value when imputing numerical data\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
            "2023-06-06 19:18:41,003\tERROR worker.py:400 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
            "\u001b[36mray::_ray_fit()\u001b[39m (pid=17251, ip=172.28.0.12)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 374, in _ray_fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold,\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 703, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py\", line 156, in _fit\n",
            "    train_dataset, val_dataset = self.generate_datasets(X=X, y=y, params=params, X_val=X_val, y_val=y_val)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py\", line 446, in generate_datasets\n",
            "    train_dataset = self.process_train_data(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py\", line 511, in process_train_data\n",
            "    df = self.processor.fit_transform(df) # 2D numpy array\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n",
            "    data_to_wrap = f(self, X, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py\", line 727, in fit_transform\n",
            "    result = self._fit_transform(X, y, _fit_transform_one)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py\", line 658, in _fit_transform\n",
            "    return Parallel(n_jobs=self.n_jobs)(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\", line 63, in __call__\n",
            "    return super().__call__(iterable_with_config)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 1088, in __call__\n",
            "    while self.dispatch_one_batch(iterator):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 901, in dispatch_one_batch\n",
            "    self._dispatch(tasks)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 819, in _dispatch\n",
            "    job = self._backend.apply_async(batch, callback=cb)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
            "    result = ImmediateResult(func)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py\", line 597, in __init__\n",
            "    self.results = batch()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 288, in __call__\n",
            "    return [func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 288, in <listcomp>\n",
            "    return [func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\", line 123, in __call__\n",
            "    return self.function(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 893, in _fit_transform_one\n",
            "    res = transformer.fit_transform(X, y, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 437, in fit_transform\n",
            "    Xt = self._fit(X, y, **fit_params_steps)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 359, in _fit\n",
            "    X, fitted_transformer = fit_transform_one_cached(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/memory.py\", line 349, in __call__\n",
            "    return self.func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 893, in _fit_transform_one\n",
            "    res = transformer.fit_transform(X, y, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n",
            "    data_to_wrap = f(self, X, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/base.py\", line 878, in fit_transform\n",
            "    return self.fit(X, **fit_params).transform(X)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/impute/_base.py\", line 408, in fit\n",
            "    raise ValueError(\n",
            "ValueError: 'fill_value'=!missing! is invalid. Expected a numerical value when imputing numerical data\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 43, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 101, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 703, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 154, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 248, in _fit\n",
            "    self._fit_folds(X=X, y=y, model_base=model_base, X_pseudo=X_pseudo, y_pseudo=y_pseudo,\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 540, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 537, in after_all_folds_scheduled\n",
            "    raise processed_exception\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 505, in after_all_folds_scheduled\n",
            "    time_end_fit, predict_time, predict_1_time = self.ray.get(finished)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/client_mode_hook.py\", line 105, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/worker.py\", line 2309, in get\n",
            "    raise value.as_instanceof_cause()\n",
            "ray.exceptions.RayTaskError(ValueError): \u001b[36mray::_ray_fit()\u001b[39m (pid=17251, ip=172.28.0.12)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 374, in _ray_fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold,\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 703, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py\", line 156, in _fit\n",
            "    train_dataset, val_dataset = self.generate_datasets(X=X, y=y, params=params, X_val=X_val, y_val=y_val)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py\", line 446, in generate_datasets\n",
            "    train_dataset = self.process_train_data(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py\", line 511, in process_train_data\n",
            "    df = self.processor.fit_transform(df) # 2D numpy array\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n",
            "    data_to_wrap = f(self, X, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py\", line 727, in fit_transform\n",
            "    result = self._fit_transform(X, y, _fit_transform_one)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py\", line 658, in _fit_transform\n",
            "    return Parallel(n_jobs=self.n_jobs)(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\", line 63, in __call__\n",
            "    return super().__call__(iterable_with_config)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 1088, in __call__\n",
            "    while self.dispatch_one_batch(iterator):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 901, in dispatch_one_batch\n",
            "    self._dispatch(tasks)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 819, in _dispatch\n",
            "    job = self._backend.apply_async(batch, callback=cb)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
            "    result = ImmediateResult(func)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py\", line 597, in __init__\n",
            "    self.results = batch()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 288, in __call__\n",
            "    return [func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 288, in <listcomp>\n",
            "    return [func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\", line 123, in __call__\n",
            "    return self.function(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 893, in _fit_transform_one\n",
            "    res = transformer.fit_transform(X, y, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 437, in fit_transform\n",
            "    Xt = self._fit(X, y, **fit_params_steps)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 359, in _fit\n",
            "    X, fitted_transformer = fit_transform_one_cached(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/memory.py\", line 349, in __call__\n",
            "    return self.func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 893, in _fit_transform_one\n",
            "    res = transformer.fit_transform(X, y, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n",
            "    data_to_wrap = f(self, X, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/base.py\", line 878, in fit_transform\n",
            "    return self.fit(X, **fit_params).transform(X)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/impute/_base.py\", line 408, in fit\n",
            "    raise ValueError(\n",
            "ValueError: 'fill_value'=!missing! is invalid. Expected a numerical value when imputing numerical data\n",
            "2023-06-06 19:18:52,494\tERROR worker.py:400 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
            "\u001b[36mray::_ray_fit()\u001b[39m (pid=17397, ip=172.28.0.12)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 374, in _ray_fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold,\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 703, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py\", line 156, in _fit\n",
            "    train_dataset, val_dataset = self.generate_datasets(X=X, y=y, params=params, X_val=X_val, y_val=y_val)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py\", line 446, in generate_datasets\n",
            "    train_dataset = self.process_train_data(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py\", line 511, in process_train_data\n",
            "    df = self.processor.fit_transform(df) # 2D numpy array\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n",
            "    data_to_wrap = f(self, X, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py\", line 727, in fit_transform\n",
            "    result = self._fit_transform(X, y, _fit_transform_one)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py\", line 658, in _fit_transform\n",
            "    return Parallel(n_jobs=self.n_jobs)(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\", line 63, in __call__\n",
            "    return super().__call__(iterable_with_config)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 1088, in __call__\n",
            "    while self.dispatch_one_batch(iterator):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 901, in dispatch_one_batch\n",
            "    self._dispatch(tasks)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 819, in _dispatch\n",
            "    job = self._backend.apply_async(batch, callback=cb)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
            "    result = ImmediateResult(func)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py\", line 597, in __init__\n",
            "    self.results = batch()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 288, in __call__\n",
            "    return [func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 288, in <listcomp>\n",
            "    return [func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\", line 123, in __call__\n",
            "    return self.function(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 893, in _fit_transform_one\n",
            "    res = transformer.fit_transform(X, y, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 437, in fit_transform\n",
            "    Xt = self._fit(X, y, **fit_params_steps)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 359, in _fit\n",
            "    X, fitted_transformer = fit_transform_one_cached(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/memory.py\", line 349, in __call__\n",
            "    return self.func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 893, in _fit_transform_one\n",
            "    res = transformer.fit_transform(X, y, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n",
            "    data_to_wrap = f(self, X, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/base.py\", line 878, in fit_transform\n",
            "    return self.fit(X, **fit_params).transform(X)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/impute/_base.py\", line 408, in fit\n",
            "    raise ValueError(\n",
            "ValueError: 'fill_value'=!missing! is invalid. Expected a numerical value when imputing numerical data\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 43, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 101, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 703, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 154, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 248, in _fit\n",
            "    self._fit_folds(X=X, y=y, model_base=model_base, X_pseudo=X_pseudo, y_pseudo=y_pseudo,\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 540, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 537, in after_all_folds_scheduled\n",
            "    raise processed_exception\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 505, in after_all_folds_scheduled\n",
            "    time_end_fit, predict_time, predict_1_time = self.ray.get(finished)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/client_mode_hook.py\", line 105, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/worker.py\", line 2309, in get\n",
            "    raise value.as_instanceof_cause()\n",
            "ray.exceptions.RayTaskError(ValueError): \u001b[36mray::_ray_fit()\u001b[39m (pid=17397, ip=172.28.0.12)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 374, in _ray_fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold,\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 703, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py\", line 156, in _fit\n",
            "    train_dataset, val_dataset = self.generate_datasets(X=X, y=y, params=params, X_val=X_val, y_val=y_val)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py\", line 446, in generate_datasets\n",
            "    train_dataset = self.process_train_data(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py\", line 511, in process_train_data\n",
            "    df = self.processor.fit_transform(df) # 2D numpy array\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n",
            "    data_to_wrap = f(self, X, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py\", line 727, in fit_transform\n",
            "    result = self._fit_transform(X, y, _fit_transform_one)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py\", line 658, in _fit_transform\n",
            "    return Parallel(n_jobs=self.n_jobs)(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\", line 63, in __call__\n",
            "    return super().__call__(iterable_with_config)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 1088, in __call__\n",
            "    while self.dispatch_one_batch(iterator):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 901, in dispatch_one_batch\n",
            "    self._dispatch(tasks)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 819, in _dispatch\n",
            "    job = self._backend.apply_async(batch, callback=cb)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
            "    result = ImmediateResult(func)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py\", line 597, in __init__\n",
            "    self.results = batch()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 288, in __call__\n",
            "    return [func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 288, in <listcomp>\n",
            "    return [func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\", line 123, in __call__\n",
            "    return self.function(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 893, in _fit_transform_one\n",
            "    res = transformer.fit_transform(X, y, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 437, in fit_transform\n",
            "    Xt = self._fit(X, y, **fit_params_steps)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 359, in _fit\n",
            "    X, fitted_transformer = fit_transform_one_cached(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/memory.py\", line 349, in __call__\n",
            "    return self.func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 893, in _fit_transform_one\n",
            "    res = transformer.fit_transform(X, y, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n",
            "    data_to_wrap = f(self, X, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/base.py\", line 878, in fit_transform\n",
            "    return self.fit(X, **fit_params).transform(X)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/impute/_base.py\", line 408, in fit\n",
            "    raise ValueError(\n",
            "ValueError: 'fill_value'=!missing! is invalid. Expected a numerical value when imputing numerical data\n",
            "2023-06-06 19:18:59,496\tERROR worker.py:400 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
            "\u001b[36mray::_ray_fit()\u001b[39m (pid=17526, ip=172.28.0.12)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 374, in _ray_fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold,\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 703, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py\", line 156, in _fit\n",
            "    train_dataset, val_dataset = self.generate_datasets(X=X, y=y, params=params, X_val=X_val, y_val=y_val)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py\", line 446, in generate_datasets\n",
            "    train_dataset = self.process_train_data(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py\", line 511, in process_train_data\n",
            "    df = self.processor.fit_transform(df) # 2D numpy array\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n",
            "    data_to_wrap = f(self, X, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py\", line 727, in fit_transform\n",
            "    result = self._fit_transform(X, y, _fit_transform_one)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py\", line 658, in _fit_transform\n",
            "    return Parallel(n_jobs=self.n_jobs)(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\", line 63, in __call__\n",
            "    return super().__call__(iterable_with_config)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 1088, in __call__\n",
            "    while self.dispatch_one_batch(iterator):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 901, in dispatch_one_batch\n",
            "    self._dispatch(tasks)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 819, in _dispatch\n",
            "    job = self._backend.apply_async(batch, callback=cb)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
            "    result = ImmediateResult(func)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py\", line 597, in __init__\n",
            "    self.results = batch()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 288, in __call__\n",
            "    return [func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 288, in <listcomp>\n",
            "    return [func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\", line 123, in __call__\n",
            "    return self.function(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 893, in _fit_transform_one\n",
            "    res = transformer.fit_transform(X, y, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 437, in fit_transform\n",
            "    Xt = self._fit(X, y, **fit_params_steps)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 359, in _fit\n",
            "    X, fitted_transformer = fit_transform_one_cached(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/memory.py\", line 349, in __call__\n",
            "    return self.func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 893, in _fit_transform_one\n",
            "    res = transformer.fit_transform(X, y, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n",
            "    data_to_wrap = f(self, X, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/base.py\", line 878, in fit_transform\n",
            "    return self.fit(X, **fit_params).transform(X)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/impute/_base.py\", line 408, in fit\n",
            "    raise ValueError(\n",
            "ValueError: 'fill_value'=!missing! is invalid. Expected a numerical value when imputing numerical data\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 43, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 101, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 703, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 154, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 248, in _fit\n",
            "    self._fit_folds(X=X, y=y, model_base=model_base, X_pseudo=X_pseudo, y_pseudo=y_pseudo,\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 540, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 537, in after_all_folds_scheduled\n",
            "    raise processed_exception\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 505, in after_all_folds_scheduled\n",
            "    time_end_fit, predict_time, predict_1_time = self.ray.get(finished)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/client_mode_hook.py\", line 105, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/worker.py\", line 2309, in get\n",
            "    raise value.as_instanceof_cause()\n",
            "ray.exceptions.RayTaskError(ValueError): \u001b[36mray::_ray_fit()\u001b[39m (pid=17526, ip=172.28.0.12)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 374, in _ray_fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold,\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 703, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py\", line 156, in _fit\n",
            "    train_dataset, val_dataset = self.generate_datasets(X=X, y=y, params=params, X_val=X_val, y_val=y_val)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py\", line 446, in generate_datasets\n",
            "    train_dataset = self.process_train_data(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py\", line 511, in process_train_data\n",
            "    df = self.processor.fit_transform(df) # 2D numpy array\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n",
            "    data_to_wrap = f(self, X, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py\", line 727, in fit_transform\n",
            "    result = self._fit_transform(X, y, _fit_transform_one)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py\", line 658, in _fit_transform\n",
            "    return Parallel(n_jobs=self.n_jobs)(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\", line 63, in __call__\n",
            "    return super().__call__(iterable_with_config)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 1088, in __call__\n",
            "    while self.dispatch_one_batch(iterator):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 901, in dispatch_one_batch\n",
            "    self._dispatch(tasks)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 819, in _dispatch\n",
            "    job = self._backend.apply_async(batch, callback=cb)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
            "    result = ImmediateResult(func)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py\", line 597, in __init__\n",
            "    self.results = batch()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 288, in __call__\n",
            "    return [func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 288, in <listcomp>\n",
            "    return [func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\", line 123, in __call__\n",
            "    return self.function(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 893, in _fit_transform_one\n",
            "    res = transformer.fit_transform(X, y, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 437, in fit_transform\n",
            "    Xt = self._fit(X, y, **fit_params_steps)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 359, in _fit\n",
            "    X, fitted_transformer = fit_transform_one_cached(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/memory.py\", line 349, in __call__\n",
            "    return self.func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 893, in _fit_transform_one\n",
            "    res = transformer.fit_transform(X, y, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n",
            "    data_to_wrap = f(self, X, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/base.py\", line 878, in fit_transform\n",
            "    return self.fit(X, **fit_params).transform(X)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/impute/_base.py\", line 408, in fit\n",
            "    raise ValueError(\n",
            "ValueError: 'fill_value'=!missing! is invalid. Expected a numerical value when imputing numerical data\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
            "2023-06-06 19:19:08,340\tERROR worker.py:400 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
            "\u001b[36mray::_ray_fit()\u001b[39m (pid=17633, ip=172.28.0.12)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 374, in _ray_fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold,\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 703, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py\", line 156, in _fit\n",
            "    train_dataset, val_dataset = self.generate_datasets(X=X, y=y, params=params, X_val=X_val, y_val=y_val)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py\", line 446, in generate_datasets\n",
            "    train_dataset = self.process_train_data(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py\", line 511, in process_train_data\n",
            "    df = self.processor.fit_transform(df) # 2D numpy array\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n",
            "    data_to_wrap = f(self, X, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py\", line 727, in fit_transform\n",
            "    result = self._fit_transform(X, y, _fit_transform_one)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py\", line 658, in _fit_transform\n",
            "    return Parallel(n_jobs=self.n_jobs)(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\", line 63, in __call__\n",
            "    return super().__call__(iterable_with_config)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 1088, in __call__\n",
            "    while self.dispatch_one_batch(iterator):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 901, in dispatch_one_batch\n",
            "    self._dispatch(tasks)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 819, in _dispatch\n",
            "    job = self._backend.apply_async(batch, callback=cb)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
            "    result = ImmediateResult(func)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py\", line 597, in __init__\n",
            "    self.results = batch()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 288, in __call__\n",
            "    return [func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 288, in <listcomp>\n",
            "    return [func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\", line 123, in __call__\n",
            "    return self.function(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 893, in _fit_transform_one\n",
            "    res = transformer.fit_transform(X, y, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 437, in fit_transform\n",
            "    Xt = self._fit(X, y, **fit_params_steps)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 359, in _fit\n",
            "    X, fitted_transformer = fit_transform_one_cached(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/memory.py\", line 349, in __call__\n",
            "    return self.func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 893, in _fit_transform_one\n",
            "    res = transformer.fit_transform(X, y, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n",
            "    data_to_wrap = f(self, X, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/base.py\", line 878, in fit_transform\n",
            "    return self.fit(X, **fit_params).transform(X)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/impute/_base.py\", line 408, in fit\n",
            "    raise ValueError(\n",
            "ValueError: 'fill_value'=!missing! is invalid. Expected a numerical value when imputing numerical data\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 43, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 101, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 703, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 154, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 248, in _fit\n",
            "    self._fit_folds(X=X, y=y, model_base=model_base, X_pseudo=X_pseudo, y_pseudo=y_pseudo,\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 540, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 537, in after_all_folds_scheduled\n",
            "    raise processed_exception\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 505, in after_all_folds_scheduled\n",
            "    time_end_fit, predict_time, predict_1_time = self.ray.get(finished)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/client_mode_hook.py\", line 105, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/worker.py\", line 2309, in get\n",
            "    raise value.as_instanceof_cause()\n",
            "ray.exceptions.RayTaskError(ValueError): \u001b[36mray::_ray_fit()\u001b[39m (pid=17633, ip=172.28.0.12)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 374, in _ray_fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold,\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 703, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py\", line 156, in _fit\n",
            "    train_dataset, val_dataset = self.generate_datasets(X=X, y=y, params=params, X_val=X_val, y_val=y_val)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py\", line 446, in generate_datasets\n",
            "    train_dataset = self.process_train_data(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py\", line 511, in process_train_data\n",
            "    df = self.processor.fit_transform(df) # 2D numpy array\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n",
            "    data_to_wrap = f(self, X, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py\", line 727, in fit_transform\n",
            "    result = self._fit_transform(X, y, _fit_transform_one)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py\", line 658, in _fit_transform\n",
            "    return Parallel(n_jobs=self.n_jobs)(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\", line 63, in __call__\n",
            "    return super().__call__(iterable_with_config)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 1088, in __call__\n",
            "    while self.dispatch_one_batch(iterator):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 901, in dispatch_one_batch\n",
            "    self._dispatch(tasks)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 819, in _dispatch\n",
            "    job = self._backend.apply_async(batch, callback=cb)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
            "    result = ImmediateResult(func)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py\", line 597, in __init__\n",
            "    self.results = batch()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 288, in __call__\n",
            "    return [func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 288, in <listcomp>\n",
            "    return [func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\", line 123, in __call__\n",
            "    return self.function(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 893, in _fit_transform_one\n",
            "    res = transformer.fit_transform(X, y, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 437, in fit_transform\n",
            "    Xt = self._fit(X, y, **fit_params_steps)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 359, in _fit\n",
            "    X, fitted_transformer = fit_transform_one_cached(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/memory.py\", line 349, in __call__\n",
            "    return self.func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 893, in _fit_transform_one\n",
            "    res = transformer.fit_transform(X, y, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n",
            "    data_to_wrap = f(self, X, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/base.py\", line 878, in fit_transform\n",
            "    return self.fit(X, **fit_params).transform(X)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/impute/_base.py\", line 408, in fit\n",
            "    raise ValueError(\n",
            "ValueError: 'fill_value'=!missing! is invalid. Expected a numerical value when imputing numerical data\n",
            "2023-06-06 19:19:21,449\tERROR worker.py:400 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
            "\u001b[36mray::_ray_fit()\u001b[39m (pid=17788, ip=172.28.0.12)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 374, in _ray_fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold,\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 703, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py\", line 156, in _fit\n",
            "    train_dataset, val_dataset = self.generate_datasets(X=X, y=y, params=params, X_val=X_val, y_val=y_val)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py\", line 446, in generate_datasets\n",
            "    train_dataset = self.process_train_data(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py\", line 511, in process_train_data\n",
            "    df = self.processor.fit_transform(df) # 2D numpy array\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n",
            "    data_to_wrap = f(self, X, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py\", line 727, in fit_transform\n",
            "    result = self._fit_transform(X, y, _fit_transform_one)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py\", line 658, in _fit_transform\n",
            "    return Parallel(n_jobs=self.n_jobs)(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\", line 63, in __call__\n",
            "    return super().__call__(iterable_with_config)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 1088, in __call__\n",
            "    while self.dispatch_one_batch(iterator):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 901, in dispatch_one_batch\n",
            "    self._dispatch(tasks)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 819, in _dispatch\n",
            "    job = self._backend.apply_async(batch, callback=cb)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
            "    result = ImmediateResult(func)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py\", line 597, in __init__\n",
            "    self.results = batch()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 288, in __call__\n",
            "    return [func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 288, in <listcomp>\n",
            "    return [func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\", line 123, in __call__\n",
            "    return self.function(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 893, in _fit_transform_one\n",
            "    res = transformer.fit_transform(X, y, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 437, in fit_transform\n",
            "    Xt = self._fit(X, y, **fit_params_steps)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 359, in _fit\n",
            "    X, fitted_transformer = fit_transform_one_cached(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/memory.py\", line 349, in __call__\n",
            "    return self.func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 893, in _fit_transform_one\n",
            "    res = transformer.fit_transform(X, y, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n",
            "    data_to_wrap = f(self, X, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/base.py\", line 878, in fit_transform\n",
            "    return self.fit(X, **fit_params).transform(X)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/impute/_base.py\", line 408, in fit\n",
            "    raise ValueError(\n",
            "ValueError: 'fill_value'=!missing! is invalid. Expected a numerical value when imputing numerical data\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 43, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 101, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 703, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 154, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 248, in _fit\n",
            "    self._fit_folds(X=X, y=y, model_base=model_base, X_pseudo=X_pseudo, y_pseudo=y_pseudo,\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 540, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 537, in after_all_folds_scheduled\n",
            "    raise processed_exception\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 505, in after_all_folds_scheduled\n",
            "    time_end_fit, predict_time, predict_1_time = self.ray.get(finished)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/client_mode_hook.py\", line 105, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/worker.py\", line 2309, in get\n",
            "    raise value.as_instanceof_cause()\n",
            "ray.exceptions.RayTaskError(ValueError): \u001b[36mray::_ray_fit()\u001b[39m (pid=17788, ip=172.28.0.12)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 374, in _ray_fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold,\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 703, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py\", line 156, in _fit\n",
            "    train_dataset, val_dataset = self.generate_datasets(X=X, y=y, params=params, X_val=X_val, y_val=y_val)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py\", line 446, in generate_datasets\n",
            "    train_dataset = self.process_train_data(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py\", line 511, in process_train_data\n",
            "    df = self.processor.fit_transform(df) # 2D numpy array\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n",
            "    data_to_wrap = f(self, X, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py\", line 727, in fit_transform\n",
            "    result = self._fit_transform(X, y, _fit_transform_one)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py\", line 658, in _fit_transform\n",
            "    return Parallel(n_jobs=self.n_jobs)(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\", line 63, in __call__\n",
            "    return super().__call__(iterable_with_config)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 1088, in __call__\n",
            "    while self.dispatch_one_batch(iterator):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 901, in dispatch_one_batch\n",
            "    self._dispatch(tasks)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 819, in _dispatch\n",
            "    job = self._backend.apply_async(batch, callback=cb)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
            "    result = ImmediateResult(func)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py\", line 597, in __init__\n",
            "    self.results = batch()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 288, in __call__\n",
            "    return [func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 288, in <listcomp>\n",
            "    return [func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\", line 123, in __call__\n",
            "    return self.function(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 893, in _fit_transform_one\n",
            "    res = transformer.fit_transform(X, y, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 437, in fit_transform\n",
            "    Xt = self._fit(X, y, **fit_params_steps)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 359, in _fit\n",
            "    X, fitted_transformer = fit_transform_one_cached(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/memory.py\", line 349, in __call__\n",
            "    return self.func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 893, in _fit_transform_one\n",
            "    res = transformer.fit_transform(X, y, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n",
            "    data_to_wrap = f(self, X, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/base.py\", line 878, in fit_transform\n",
            "    return self.fit(X, **fit_params).transform(X)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/impute/_base.py\", line 408, in fit\n",
            "    raise ValueError(\n",
            "ValueError: 'fill_value'=!missing! is invalid. Expected a numerical value when imputing numerical data\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
            "2023-06-06 19:19:35,267\tERROR worker.py:400 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
            "\u001b[36mray::_ray_fit()\u001b[39m (pid=17941, ip=172.28.0.12)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 374, in _ray_fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold,\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 703, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py\", line 156, in _fit\n",
            "    train_dataset, val_dataset = self.generate_datasets(X=X, y=y, params=params, X_val=X_val, y_val=y_val)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py\", line 446, in generate_datasets\n",
            "    train_dataset = self.process_train_data(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py\", line 511, in process_train_data\n",
            "    df = self.processor.fit_transform(df) # 2D numpy array\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n",
            "    data_to_wrap = f(self, X, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py\", line 727, in fit_transform\n",
            "    result = self._fit_transform(X, y, _fit_transform_one)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py\", line 658, in _fit_transform\n",
            "    return Parallel(n_jobs=self.n_jobs)(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\", line 63, in __call__\n",
            "    return super().__call__(iterable_with_config)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 1088, in __call__\n",
            "    while self.dispatch_one_batch(iterator):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 901, in dispatch_one_batch\n",
            "    self._dispatch(tasks)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 819, in _dispatch\n",
            "    job = self._backend.apply_async(batch, callback=cb)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
            "    result = ImmediateResult(func)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py\", line 597, in __init__\n",
            "    self.results = batch()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 288, in __call__\n",
            "    return [func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 288, in <listcomp>\n",
            "    return [func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\", line 123, in __call__\n",
            "    return self.function(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 893, in _fit_transform_one\n",
            "    res = transformer.fit_transform(X, y, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 437, in fit_transform\n",
            "    Xt = self._fit(X, y, **fit_params_steps)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 359, in _fit\n",
            "    X, fitted_transformer = fit_transform_one_cached(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/memory.py\", line 349, in __call__\n",
            "    return self.func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 893, in _fit_transform_one\n",
            "    res = transformer.fit_transform(X, y, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n",
            "    data_to_wrap = f(self, X, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/base.py\", line 878, in fit_transform\n",
            "    return self.fit(X, **fit_params).transform(X)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/impute/_base.py\", line 408, in fit\n",
            "    raise ValueError(\n",
            "ValueError: 'fill_value'=!missing! is invalid. Expected a numerical value when imputing numerical data\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 43, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 101, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 703, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 154, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 248, in _fit\n",
            "    self._fit_folds(X=X, y=y, model_base=model_base, X_pseudo=X_pseudo, y_pseudo=y_pseudo,\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 540, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 537, in after_all_folds_scheduled\n",
            "    raise processed_exception\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 505, in after_all_folds_scheduled\n",
            "    time_end_fit, predict_time, predict_1_time = self.ray.get(finished)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/client_mode_hook.py\", line 105, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/worker.py\", line 2309, in get\n",
            "    raise value.as_instanceof_cause()\n",
            "ray.exceptions.RayTaskError(ValueError): \u001b[36mray::_ray_fit()\u001b[39m (pid=17941, ip=172.28.0.12)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 374, in _ray_fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold,\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 703, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py\", line 156, in _fit\n",
            "    train_dataset, val_dataset = self.generate_datasets(X=X, y=y, params=params, X_val=X_val, y_val=y_val)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py\", line 446, in generate_datasets\n",
            "    train_dataset = self.process_train_data(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py\", line 511, in process_train_data\n",
            "    df = self.processor.fit_transform(df) # 2D numpy array\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n",
            "    data_to_wrap = f(self, X, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py\", line 727, in fit_transform\n",
            "    result = self._fit_transform(X, y, _fit_transform_one)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py\", line 658, in _fit_transform\n",
            "    return Parallel(n_jobs=self.n_jobs)(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\", line 63, in __call__\n",
            "    return super().__call__(iterable_with_config)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 1088, in __call__\n",
            "    while self.dispatch_one_batch(iterator):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 901, in dispatch_one_batch\n",
            "    self._dispatch(tasks)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 819, in _dispatch\n",
            "    job = self._backend.apply_async(batch, callback=cb)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
            "    result = ImmediateResult(func)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py\", line 597, in __init__\n",
            "    self.results = batch()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 288, in __call__\n",
            "    return [func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 288, in <listcomp>\n",
            "    return [func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\", line 123, in __call__\n",
            "    return self.function(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 893, in _fit_transform_one\n",
            "    res = transformer.fit_transform(X, y, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 437, in fit_transform\n",
            "    Xt = self._fit(X, y, **fit_params_steps)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 359, in _fit\n",
            "    X, fitted_transformer = fit_transform_one_cached(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/memory.py\", line 349, in __call__\n",
            "    return self.func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 893, in _fit_transform_one\n",
            "    res = transformer.fit_transform(X, y, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n",
            "    data_to_wrap = f(self, X, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/base.py\", line 878, in fit_transform\n",
            "    return self.fit(X, **fit_params).transform(X)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/impute/_base.py\", line 408, in fit\n",
            "    raise ValueError(\n",
            "ValueError: 'fill_value'=!missing! is invalid. Expected a numerical value when imputing numerical data\n",
            "2023-06-06 19:19:44,650\tERROR worker.py:400 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
            "\u001b[36mray::_ray_fit()\u001b[39m (pid=18081, ip=172.28.0.12)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 374, in _ray_fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold,\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 703, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py\", line 156, in _fit\n",
            "    train_dataset, val_dataset = self.generate_datasets(X=X, y=y, params=params, X_val=X_val, y_val=y_val)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py\", line 446, in generate_datasets\n",
            "    train_dataset = self.process_train_data(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py\", line 511, in process_train_data\n",
            "    df = self.processor.fit_transform(df) # 2D numpy array\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n",
            "    data_to_wrap = f(self, X, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py\", line 727, in fit_transform\n",
            "    result = self._fit_transform(X, y, _fit_transform_one)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py\", line 658, in _fit_transform\n",
            "    return Parallel(n_jobs=self.n_jobs)(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\", line 63, in __call__\n",
            "    return super().__call__(iterable_with_config)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 1088, in __call__\n",
            "    while self.dispatch_one_batch(iterator):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 901, in dispatch_one_batch\n",
            "    self._dispatch(tasks)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 819, in _dispatch\n",
            "    job = self._backend.apply_async(batch, callback=cb)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
            "    result = ImmediateResult(func)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py\", line 597, in __init__\n",
            "    self.results = batch()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 288, in __call__\n",
            "    return [func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 288, in <listcomp>\n",
            "    return [func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\", line 123, in __call__\n",
            "    return self.function(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 893, in _fit_transform_one\n",
            "    res = transformer.fit_transform(X, y, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 437, in fit_transform\n",
            "    Xt = self._fit(X, y, **fit_params_steps)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 359, in _fit\n",
            "    X, fitted_transformer = fit_transform_one_cached(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/memory.py\", line 349, in __call__\n",
            "    return self.func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 893, in _fit_transform_one\n",
            "    res = transformer.fit_transform(X, y, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n",
            "    data_to_wrap = f(self, X, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/base.py\", line 878, in fit_transform\n",
            "    return self.fit(X, **fit_params).transform(X)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/impute/_base.py\", line 408, in fit\n",
            "    raise ValueError(\n",
            "ValueError: 'fill_value'=!missing! is invalid. Expected a numerical value when imputing numerical data\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 43, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 101, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 703, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 154, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 248, in _fit\n",
            "    self._fit_folds(X=X, y=y, model_base=model_base, X_pseudo=X_pseudo, y_pseudo=y_pseudo,\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 540, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 537, in after_all_folds_scheduled\n",
            "    raise processed_exception\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 505, in after_all_folds_scheduled\n",
            "    time_end_fit, predict_time, predict_1_time = self.ray.get(finished)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/client_mode_hook.py\", line 105, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/worker.py\", line 2309, in get\n",
            "    raise value.as_instanceof_cause()\n",
            "ray.exceptions.RayTaskError(ValueError): \u001b[36mray::_ray_fit()\u001b[39m (pid=18081, ip=172.28.0.12)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 374, in _ray_fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold,\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 703, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py\", line 156, in _fit\n",
            "    train_dataset, val_dataset = self.generate_datasets(X=X, y=y, params=params, X_val=X_val, y_val=y_val)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py\", line 446, in generate_datasets\n",
            "    train_dataset = self.process_train_data(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py\", line 511, in process_train_data\n",
            "    df = self.processor.fit_transform(df) # 2D numpy array\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n",
            "    data_to_wrap = f(self, X, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py\", line 727, in fit_transform\n",
            "    result = self._fit_transform(X, y, _fit_transform_one)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py\", line 658, in _fit_transform\n",
            "    return Parallel(n_jobs=self.n_jobs)(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\", line 63, in __call__\n",
            "    return super().__call__(iterable_with_config)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 1088, in __call__\n",
            "    while self.dispatch_one_batch(iterator):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 901, in dispatch_one_batch\n",
            "    self._dispatch(tasks)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 819, in _dispatch\n",
            "    job = self._backend.apply_async(batch, callback=cb)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
            "    result = ImmediateResult(func)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py\", line 597, in __init__\n",
            "    self.results = batch()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 288, in __call__\n",
            "    return [func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 288, in <listcomp>\n",
            "    return [func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\", line 123, in __call__\n",
            "    return self.function(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 893, in _fit_transform_one\n",
            "    res = transformer.fit_transform(X, y, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 437, in fit_transform\n",
            "    Xt = self._fit(X, y, **fit_params_steps)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 359, in _fit\n",
            "    X, fitted_transformer = fit_transform_one_cached(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/memory.py\", line 349, in __call__\n",
            "    return self.func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 893, in _fit_transform_one\n",
            "    res = transformer.fit_transform(X, y, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n",
            "    data_to_wrap = f(self, X, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/base.py\", line 878, in fit_transform\n",
            "    return self.fit(X, **fit_params).transform(X)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/impute/_base.py\", line 408, in fit\n",
            "    raise ValueError(\n",
            "ValueError: 'fill_value'=!missing! is invalid. Expected a numerical value when imputing numerical data\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
            "2023-06-06 19:19:52,553\tERROR worker.py:400 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
            "\u001b[36mray::_ray_fit()\u001b[39m (pid=18209, ip=172.28.0.12)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 374, in _ray_fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold,\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 703, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py\", line 156, in _fit\n",
            "    train_dataset, val_dataset = self.generate_datasets(X=X, y=y, params=params, X_val=X_val, y_val=y_val)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py\", line 446, in generate_datasets\n",
            "    train_dataset = self.process_train_data(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py\", line 511, in process_train_data\n",
            "    df = self.processor.fit_transform(df) # 2D numpy array\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n",
            "    data_to_wrap = f(self, X, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py\", line 727, in fit_transform\n",
            "    result = self._fit_transform(X, y, _fit_transform_one)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py\", line 658, in _fit_transform\n",
            "    return Parallel(n_jobs=self.n_jobs)(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\", line 63, in __call__\n",
            "    return super().__call__(iterable_with_config)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 1088, in __call__\n",
            "    while self.dispatch_one_batch(iterator):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 901, in dispatch_one_batch\n",
            "    self._dispatch(tasks)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 819, in _dispatch\n",
            "    job = self._backend.apply_async(batch, callback=cb)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
            "    result = ImmediateResult(func)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py\", line 597, in __init__\n",
            "    self.results = batch()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 288, in __call__\n",
            "    return [func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 288, in <listcomp>\n",
            "    return [func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\", line 123, in __call__\n",
            "    return self.function(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 893, in _fit_transform_one\n",
            "    res = transformer.fit_transform(X, y, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 437, in fit_transform\n",
            "    Xt = self._fit(X, y, **fit_params_steps)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 359, in _fit\n",
            "    X, fitted_transformer = fit_transform_one_cached(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/memory.py\", line 349, in __call__\n",
            "    return self.func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 893, in _fit_transform_one\n",
            "    res = transformer.fit_transform(X, y, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n",
            "    data_to_wrap = f(self, X, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/base.py\", line 878, in fit_transform\n",
            "    return self.fit(X, **fit_params).transform(X)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/impute/_base.py\", line 408, in fit\n",
            "    raise ValueError(\n",
            "ValueError: 'fill_value'=!missing! is invalid. Expected a numerical value when imputing numerical data\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 43, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 101, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 703, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 154, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 248, in _fit\n",
            "    self._fit_folds(X=X, y=y, model_base=model_base, X_pseudo=X_pseudo, y_pseudo=y_pseudo,\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 540, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 537, in after_all_folds_scheduled\n",
            "    raise processed_exception\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 505, in after_all_folds_scheduled\n",
            "    time_end_fit, predict_time, predict_1_time = self.ray.get(finished)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/client_mode_hook.py\", line 105, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/worker.py\", line 2309, in get\n",
            "    raise value.as_instanceof_cause()\n",
            "ray.exceptions.RayTaskError(ValueError): \u001b[36mray::_ray_fit()\u001b[39m (pid=18209, ip=172.28.0.12)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 374, in _ray_fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold,\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 703, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py\", line 156, in _fit\n",
            "    train_dataset, val_dataset = self.generate_datasets(X=X, y=y, params=params, X_val=X_val, y_val=y_val)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py\", line 446, in generate_datasets\n",
            "    train_dataset = self.process_train_data(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py\", line 511, in process_train_data\n",
            "    df = self.processor.fit_transform(df) # 2D numpy array\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n",
            "    data_to_wrap = f(self, X, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py\", line 727, in fit_transform\n",
            "    result = self._fit_transform(X, y, _fit_transform_one)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py\", line 658, in _fit_transform\n",
            "    return Parallel(n_jobs=self.n_jobs)(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\", line 63, in __call__\n",
            "    return super().__call__(iterable_with_config)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 1088, in __call__\n",
            "    while self.dispatch_one_batch(iterator):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 901, in dispatch_one_batch\n",
            "    self._dispatch(tasks)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 819, in _dispatch\n",
            "    job = self._backend.apply_async(batch, callback=cb)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
            "    result = ImmediateResult(func)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py\", line 597, in __init__\n",
            "    self.results = batch()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 288, in __call__\n",
            "    return [func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 288, in <listcomp>\n",
            "    return [func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\", line 123, in __call__\n",
            "    return self.function(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 893, in _fit_transform_one\n",
            "    res = transformer.fit_transform(X, y, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 437, in fit_transform\n",
            "    Xt = self._fit(X, y, **fit_params_steps)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 359, in _fit\n",
            "    X, fitted_transformer = fit_transform_one_cached(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/memory.py\", line 349, in __call__\n",
            "    return self.func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 893, in _fit_transform_one\n",
            "    res = transformer.fit_transform(X, y, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n",
            "    data_to_wrap = f(self, X, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/base.py\", line 878, in fit_transform\n",
            "    return self.fit(X, **fit_params).transform(X)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/impute/_base.py\", line 408, in fit\n",
            "    raise ValueError(\n",
            "ValueError: 'fill_value'=!missing! is invalid. Expected a numerical value when imputing numerical data\n",
            "\tStopping HPO to satisfy time limit...\n",
            "No model was trained during hyperparameter tuning NeuralNetMXNet_BAG_L1... Skipping this model.\n",
            "Completed 1/20 k-fold bagging repeats ...\n",
            "Fitting model: WeightedEnsemble_L2 ... Training model for up to 360.0s of the 276.54s of remaining time.\n",
            "2023-06-06 19:20:04,390\tERROR worker.py:400 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
            "\t-34.1131\t = Validation score   (-root_mean_squared_error)\n",
            "\t0.89s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "\tWARNING: \"NN\" model has been deprecated in v0.4.0 and renamed to \"NN_MXNET\". Starting in v0.6.0, specifying \"NN\" or \"NN_MXNET\" will raise an exception. Consider instead specifying \"NN_TORCH\".\n",
            "Fitting 3 L2 models ...\n",
            "Hyperparameter tuning model: LightGBM_BAG_L2 ... Tuning model for up to 82.68s of the 275.56s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
            "\tStopping HPO to satisfy time limit...\n",
            "Fitted model: LightGBM_BAG_L2/T1 ...\n",
            "\t-165.328\t = Validation score   (-root_mean_squared_error)\n",
            "\t30.28s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Fitted model: LightGBM_BAG_L2/T2 ...\n",
            "\t-37.4744\t = Validation score   (-root_mean_squared_error)\n",
            "\t42.43s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Hyperparameter tuning model: XGBoost_BAG_L2 ... Tuning model for up to 82.68s of the 202.68s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
            "\tStopping HPO to satisfy time limit...\n",
            "Fitted model: XGBoost_BAG_L2/T1 ...\n",
            "\t-34.92\t = Validation score   (-root_mean_squared_error)\n",
            "\t29.99s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Fitted model: XGBoost_BAG_L2/T2 ...\n",
            "\t-35.2599\t = Validation score   (-root_mean_squared_error)\n",
            "\t49.78s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Hyperparameter tuning model: NeuralNetMXNet_BAG_L2 ... Tuning model for up to 82.68s of the 122.8s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
            "\u001b[36mray::_ray_fit()\u001b[39m (pid=20018, ip=172.28.0.12)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 374, in _ray_fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold,\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 703, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py\", line 156, in _fit\n",
            "    train_dataset, val_dataset = self.generate_datasets(X=X, y=y, params=params, X_val=X_val, y_val=y_val)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py\", line 446, in generate_datasets\n",
            "    train_dataset = self.process_train_data(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py\", line 511, in process_train_data\n",
            "    df = self.processor.fit_transform(df) # 2D numpy array\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n",
            "    data_to_wrap = f(self, X, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py\", line 727, in fit_transform\n",
            "    result = self._fit_transform(X, y, _fit_transform_one)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py\", line 658, in _fit_transform\n",
            "    return Parallel(n_jobs=self.n_jobs)(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\", line 63, in __call__\n",
            "    return super().__call__(iterable_with_config)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 1088, in __call__\n",
            "    while self.dispatch_one_batch(iterator):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 901, in dispatch_one_batch\n",
            "    self._dispatch(tasks)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 819, in _dispatch\n",
            "    job = self._backend.apply_async(batch, callback=cb)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
            "    result = ImmediateResult(func)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py\", line 597, in __init__\n",
            "    self.results = batch()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 288, in __call__\n",
            "    return [func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 288, in <listcomp>\n",
            "    return [func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\", line 123, in __call__\n",
            "    return self.function(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 893, in _fit_transform_one\n",
            "    res = transformer.fit_transform(X, y, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 437, in fit_transform\n",
            "    Xt = self._fit(X, y, **fit_params_steps)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 359, in _fit\n",
            "    X, fitted_transformer = fit_transform_one_cached(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/memory.py\", line 349, in __call__\n",
            "    return self.func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 893, in _fit_transform_one\n",
            "    res = transformer.fit_transform(X, y, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n",
            "    data_to_wrap = f(self, X, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/base.py\", line 878, in fit_transform\n",
            "    return self.fit(X, **fit_params).transform(X)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/impute/_base.py\", line 408, in fit\n",
            "    raise ValueError(\n",
            "ValueError: 'fill_value'=!missing! is invalid. Expected a numerical value when imputing numerical data\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 43, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 101, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 703, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 154, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 248, in _fit\n",
            "    self._fit_folds(X=X, y=y, model_base=model_base, X_pseudo=X_pseudo, y_pseudo=y_pseudo,\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 540, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 537, in after_all_folds_scheduled\n",
            "    raise processed_exception\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 505, in after_all_folds_scheduled\n",
            "    time_end_fit, predict_time, predict_1_time = self.ray.get(finished)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/client_mode_hook.py\", line 105, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/worker.py\", line 2309, in get\n",
            "    raise value.as_instanceof_cause()\n",
            "ray.exceptions.RayTaskError(ValueError): \u001b[36mray::_ray_fit()\u001b[39m (pid=20018, ip=172.28.0.12)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 374, in _ray_fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold,\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 703, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py\", line 156, in _fit\n",
            "    train_dataset, val_dataset = self.generate_datasets(X=X, y=y, params=params, X_val=X_val, y_val=y_val)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py\", line 446, in generate_datasets\n",
            "    train_dataset = self.process_train_data(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py\", line 511, in process_train_data\n",
            "    df = self.processor.fit_transform(df) # 2D numpy array\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n",
            "    data_to_wrap = f(self, X, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py\", line 727, in fit_transform\n",
            "    result = self._fit_transform(X, y, _fit_transform_one)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py\", line 658, in _fit_transform\n",
            "    return Parallel(n_jobs=self.n_jobs)(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\", line 63, in __call__\n",
            "    return super().__call__(iterable_with_config)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 1088, in __call__\n",
            "    while self.dispatch_one_batch(iterator):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 901, in dispatch_one_batch\n",
            "    self._dispatch(tasks)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 819, in _dispatch\n",
            "    job = self._backend.apply_async(batch, callback=cb)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
            "    result = ImmediateResult(func)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py\", line 597, in __init__\n",
            "    self.results = batch()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 288, in __call__\n",
            "    return [func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 288, in <listcomp>\n",
            "    return [func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\", line 123, in __call__\n",
            "    return self.function(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 893, in _fit_transform_one\n",
            "    res = transformer.fit_transform(X, y, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 437, in fit_transform\n",
            "    Xt = self._fit(X, y, **fit_params_steps)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 359, in _fit\n",
            "    X, fitted_transformer = fit_transform_one_cached(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/memory.py\", line 349, in __call__\n",
            "    return self.func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 893, in _fit_transform_one\n",
            "    res = transformer.fit_transform(X, y, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n",
            "    data_to_wrap = f(self, X, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/base.py\", line 878, in fit_transform\n",
            "    return self.fit(X, **fit_params).transform(X)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/impute/_base.py\", line 408, in fit\n",
            "    raise ValueError(\n",
            "ValueError: 'fill_value'=!missing! is invalid. Expected a numerical value when imputing numerical data\n",
            "2023-06-06 19:22:44,598\tERROR worker.py:400 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): \u001b[36mray::_ray_fit()\u001b[39m (pid=20017, ip=172.28.0.12)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 374, in _ray_fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold,\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 703, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py\", line 156, in _fit\n",
            "    train_dataset, val_dataset = self.generate_datasets(X=X, y=y, params=params, X_val=X_val, y_val=y_val)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py\", line 446, in generate_datasets\n",
            "    train_dataset = self.process_train_data(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py\", line 511, in process_train_data\n",
            "    df = self.processor.fit_transform(df) # 2D numpy array\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n",
            "    data_to_wrap = f(self, X, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py\", line 727, in fit_transform\n",
            "    result = self._fit_transform(X, y, _fit_transform_one)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py\", line 658, in _fit_transform\n",
            "    return Parallel(n_jobs=self.n_jobs)(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\", line 63, in __call__\n",
            "    return super().__call__(iterable_with_config)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 1088, in __call__\n",
            "    while self.dispatch_one_batch(iterator):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 901, in dispatch_one_batch\n",
            "    self._dispatch(tasks)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 819, in _dispatch\n",
            "    job = self._backend.apply_async(batch, callback=cb)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
            "    result = ImmediateResult(func)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py\", line 597, in __init__\n",
            "    self.results = batch()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 288, in __call__\n",
            "    return [func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 288, in <listcomp>\n",
            "    return [func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\", line 123, in __call__\n",
            "    return self.function(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 893, in _fit_transform_one\n",
            "    res = transformer.fit_transform(X, y, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 437, in fit_transform\n",
            "    Xt = self._fit(X, y, **fit_params_steps)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 359, in _fit\n",
            "    X, fitted_transformer = fit_transform_one_cached(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/memory.py\", line 349, in __call__\n",
            "    return self.func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 893, in _fit_transform_one\n",
            "    res = transformer.fit_transform(X, y, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n",
            "    data_to_wrap = f(self, X, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/base.py\", line 878, in fit_transform\n",
            "    return self.fit(X, **fit_params).transform(X)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/impute/_base.py\", line 408, in fit\n",
            "    raise ValueError(\n",
            "ValueError: 'fill_value'=!missing! is invalid. Expected a numerical value when imputing numerical data\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
            "\u001b[36mray::_ray_fit()\u001b[39m (pid=20108, ip=172.28.0.12)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 374, in _ray_fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold,\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 703, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py\", line 156, in _fit\n",
            "    train_dataset, val_dataset = self.generate_datasets(X=X, y=y, params=params, X_val=X_val, y_val=y_val)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py\", line 446, in generate_datasets\n",
            "    train_dataset = self.process_train_data(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py\", line 511, in process_train_data\n",
            "    df = self.processor.fit_transform(df) # 2D numpy array\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n",
            "    data_to_wrap = f(self, X, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py\", line 727, in fit_transform\n",
            "    result = self._fit_transform(X, y, _fit_transform_one)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py\", line 658, in _fit_transform\n",
            "    return Parallel(n_jobs=self.n_jobs)(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\", line 63, in __call__\n",
            "    return super().__call__(iterable_with_config)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 1088, in __call__\n",
            "    while self.dispatch_one_batch(iterator):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 901, in dispatch_one_batch\n",
            "    self._dispatch(tasks)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 819, in _dispatch\n",
            "    job = self._backend.apply_async(batch, callback=cb)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
            "    result = ImmediateResult(func)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py\", line 597, in __init__\n",
            "    self.results = batch()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 288, in __call__\n",
            "    return [func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 288, in <listcomp>\n",
            "    return [func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\", line 123, in __call__\n",
            "    return self.function(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 893, in _fit_transform_one\n",
            "    res = transformer.fit_transform(X, y, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 437, in fit_transform\n",
            "    Xt = self._fit(X, y, **fit_params_steps)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 359, in _fit\n",
            "    X, fitted_transformer = fit_transform_one_cached(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/memory.py\", line 349, in __call__\n",
            "    return self.func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 893, in _fit_transform_one\n",
            "    res = transformer.fit_transform(X, y, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n",
            "    data_to_wrap = f(self, X, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/base.py\", line 878, in fit_transform\n",
            "    return self.fit(X, **fit_params).transform(X)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/impute/_base.py\", line 408, in fit\n",
            "    raise ValueError(\n",
            "ValueError: 'fill_value'=!missing! is invalid. Expected a numerical value when imputing numerical data\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 43, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 101, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 703, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 154, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 248, in _fit\n",
            "    self._fit_folds(X=X, y=y, model_base=model_base, X_pseudo=X_pseudo, y_pseudo=y_pseudo,\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 540, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 537, in after_all_folds_scheduled\n",
            "    raise processed_exception\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 505, in after_all_folds_scheduled\n",
            "    time_end_fit, predict_time, predict_1_time = self.ray.get(finished)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/client_mode_hook.py\", line 105, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/worker.py\", line 2309, in get\n",
            "    raise value.as_instanceof_cause()\n",
            "ray.exceptions.RayTaskError(ValueError): \u001b[36mray::_ray_fit()\u001b[39m (pid=20108, ip=172.28.0.12)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 374, in _ray_fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold,\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 703, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py\", line 156, in _fit\n",
            "    train_dataset, val_dataset = self.generate_datasets(X=X, y=y, params=params, X_val=X_val, y_val=y_val)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py\", line 446, in generate_datasets\n",
            "    train_dataset = self.process_train_data(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py\", line 511, in process_train_data\n",
            "    df = self.processor.fit_transform(df) # 2D numpy array\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n",
            "    data_to_wrap = f(self, X, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py\", line 727, in fit_transform\n",
            "    result = self._fit_transform(X, y, _fit_transform_one)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py\", line 658, in _fit_transform\n",
            "    return Parallel(n_jobs=self.n_jobs)(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\", line 63, in __call__\n",
            "    return super().__call__(iterable_with_config)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 1088, in __call__\n",
            "    while self.dispatch_one_batch(iterator):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 901, in dispatch_one_batch\n",
            "    self._dispatch(tasks)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 819, in _dispatch\n",
            "    job = self._backend.apply_async(batch, callback=cb)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
            "    result = ImmediateResult(func)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py\", line 597, in __init__\n",
            "    self.results = batch()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 288, in __call__\n",
            "    return [func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 288, in <listcomp>\n",
            "    return [func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\", line 123, in __call__\n",
            "    return self.function(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 893, in _fit_transform_one\n",
            "    res = transformer.fit_transform(X, y, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 437, in fit_transform\n",
            "    Xt = self._fit(X, y, **fit_params_steps)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 359, in _fit\n",
            "    X, fitted_transformer = fit_transform_one_cached(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/memory.py\", line 349, in __call__\n",
            "    return self.func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 893, in _fit_transform_one\n",
            "    res = transformer.fit_transform(X, y, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n",
            "    data_to_wrap = f(self, X, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/base.py\", line 878, in fit_transform\n",
            "    return self.fit(X, **fit_params).transform(X)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/impute/_base.py\", line 408, in fit\n",
            "    raise ValueError(\n",
            "ValueError: 'fill_value'=!missing! is invalid. Expected a numerical value when imputing numerical data\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
            "2023-06-06 19:22:58,074\tERROR worker.py:400 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
            "\u001b[36mray::_ray_fit()\u001b[39m (pid=20267, ip=172.28.0.12)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 374, in _ray_fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold,\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 703, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py\", line 156, in _fit\n",
            "    train_dataset, val_dataset = self.generate_datasets(X=X, y=y, params=params, X_val=X_val, y_val=y_val)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py\", line 446, in generate_datasets\n",
            "    train_dataset = self.process_train_data(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py\", line 511, in process_train_data\n",
            "    df = self.processor.fit_transform(df) # 2D numpy array\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n",
            "    data_to_wrap = f(self, X, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py\", line 727, in fit_transform\n",
            "    result = self._fit_transform(X, y, _fit_transform_one)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py\", line 658, in _fit_transform\n",
            "    return Parallel(n_jobs=self.n_jobs)(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\", line 63, in __call__\n",
            "    return super().__call__(iterable_with_config)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 1088, in __call__\n",
            "    while self.dispatch_one_batch(iterator):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 901, in dispatch_one_batch\n",
            "    self._dispatch(tasks)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 819, in _dispatch\n",
            "    job = self._backend.apply_async(batch, callback=cb)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
            "    result = ImmediateResult(func)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py\", line 597, in __init__\n",
            "    self.results = batch()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 288, in __call__\n",
            "    return [func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 288, in <listcomp>\n",
            "    return [func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\", line 123, in __call__\n",
            "    return self.function(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 893, in _fit_transform_one\n",
            "    res = transformer.fit_transform(X, y, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 437, in fit_transform\n",
            "    Xt = self._fit(X, y, **fit_params_steps)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 359, in _fit\n",
            "    X, fitted_transformer = fit_transform_one_cached(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/memory.py\", line 349, in __call__\n",
            "    return self.func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 893, in _fit_transform_one\n",
            "    res = transformer.fit_transform(X, y, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n",
            "    data_to_wrap = f(self, X, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/base.py\", line 878, in fit_transform\n",
            "    return self.fit(X, **fit_params).transform(X)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/impute/_base.py\", line 408, in fit\n",
            "    raise ValueError(\n",
            "ValueError: 'fill_value'=!missing! is invalid. Expected a numerical value when imputing numerical data\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 43, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 101, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 703, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 154, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 248, in _fit\n",
            "    self._fit_folds(X=X, y=y, model_base=model_base, X_pseudo=X_pseudo, y_pseudo=y_pseudo,\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 540, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 537, in after_all_folds_scheduled\n",
            "    raise processed_exception\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 505, in after_all_folds_scheduled\n",
            "    time_end_fit, predict_time, predict_1_time = self.ray.get(finished)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/client_mode_hook.py\", line 105, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/worker.py\", line 2309, in get\n",
            "    raise value.as_instanceof_cause()\n",
            "ray.exceptions.RayTaskError(ValueError): \u001b[36mray::_ray_fit()\u001b[39m (pid=20267, ip=172.28.0.12)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 374, in _ray_fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold,\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 703, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py\", line 156, in _fit\n",
            "    train_dataset, val_dataset = self.generate_datasets(X=X, y=y, params=params, X_val=X_val, y_val=y_val)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py\", line 446, in generate_datasets\n",
            "    train_dataset = self.process_train_data(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py\", line 511, in process_train_data\n",
            "    df = self.processor.fit_transform(df) # 2D numpy array\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n",
            "    data_to_wrap = f(self, X, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py\", line 727, in fit_transform\n",
            "    result = self._fit_transform(X, y, _fit_transform_one)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py\", line 658, in _fit_transform\n",
            "    return Parallel(n_jobs=self.n_jobs)(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\", line 63, in __call__\n",
            "    return super().__call__(iterable_with_config)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 1088, in __call__\n",
            "    while self.dispatch_one_batch(iterator):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 901, in dispatch_one_batch\n",
            "    self._dispatch(tasks)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 819, in _dispatch\n",
            "    job = self._backend.apply_async(batch, callback=cb)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
            "    result = ImmediateResult(func)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py\", line 597, in __init__\n",
            "    self.results = batch()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 288, in __call__\n",
            "    return [func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 288, in <listcomp>\n",
            "    return [func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\", line 123, in __call__\n",
            "    return self.function(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 893, in _fit_transform_one\n",
            "    res = transformer.fit_transform(X, y, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 437, in fit_transform\n",
            "    Xt = self._fit(X, y, **fit_params_steps)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 359, in _fit\n",
            "    X, fitted_transformer = fit_transform_one_cached(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/memory.py\", line 349, in __call__\n",
            "    return self.func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 893, in _fit_transform_one\n",
            "    res = transformer.fit_transform(X, y, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n",
            "    data_to_wrap = f(self, X, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/base.py\", line 878, in fit_transform\n",
            "    return self.fit(X, **fit_params).transform(X)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/impute/_base.py\", line 408, in fit\n",
            "    raise ValueError(\n",
            "ValueError: 'fill_value'=!missing! is invalid. Expected a numerical value when imputing numerical data\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
            "2023-06-06 19:23:04,400\tERROR worker.py:400 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
            "\u001b[36mray::_ray_fit()\u001b[39m (pid=20363, ip=172.28.0.12)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 374, in _ray_fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold,\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 703, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py\", line 156, in _fit\n",
            "    train_dataset, val_dataset = self.generate_datasets(X=X, y=y, params=params, X_val=X_val, y_val=y_val)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py\", line 446, in generate_datasets\n",
            "    train_dataset = self.process_train_data(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py\", line 511, in process_train_data\n",
            "    df = self.processor.fit_transform(df) # 2D numpy array\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n",
            "    data_to_wrap = f(self, X, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py\", line 727, in fit_transform\n",
            "    result = self._fit_transform(X, y, _fit_transform_one)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py\", line 658, in _fit_transform\n",
            "    return Parallel(n_jobs=self.n_jobs)(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\", line 63, in __call__\n",
            "    return super().__call__(iterable_with_config)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 1088, in __call__\n",
            "    while self.dispatch_one_batch(iterator):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 901, in dispatch_one_batch\n",
            "    self._dispatch(tasks)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 819, in _dispatch\n",
            "    job = self._backend.apply_async(batch, callback=cb)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
            "    result = ImmediateResult(func)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py\", line 597, in __init__\n",
            "    self.results = batch()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 288, in __call__\n",
            "    return [func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 288, in <listcomp>\n",
            "    return [func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\", line 123, in __call__\n",
            "    return self.function(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 893, in _fit_transform_one\n",
            "    res = transformer.fit_transform(X, y, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 437, in fit_transform\n",
            "    Xt = self._fit(X, y, **fit_params_steps)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 359, in _fit\n",
            "    X, fitted_transformer = fit_transform_one_cached(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/memory.py\", line 349, in __call__\n",
            "    return self.func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 893, in _fit_transform_one\n",
            "    res = transformer.fit_transform(X, y, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n",
            "    data_to_wrap = f(self, X, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/base.py\", line 878, in fit_transform\n",
            "    return self.fit(X, **fit_params).transform(X)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/impute/_base.py\", line 408, in fit\n",
            "    raise ValueError(\n",
            "ValueError: 'fill_value'=!missing! is invalid. Expected a numerical value when imputing numerical data\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 43, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 101, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 703, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 154, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 248, in _fit\n",
            "    self._fit_folds(X=X, y=y, model_base=model_base, X_pseudo=X_pseudo, y_pseudo=y_pseudo,\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 540, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 537, in after_all_folds_scheduled\n",
            "    raise processed_exception\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 505, in after_all_folds_scheduled\n",
            "    time_end_fit, predict_time, predict_1_time = self.ray.get(finished)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/client_mode_hook.py\", line 105, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/worker.py\", line 2309, in get\n",
            "    raise value.as_instanceof_cause()\n",
            "ray.exceptions.RayTaskError(ValueError): \u001b[36mray::_ray_fit()\u001b[39m (pid=20363, ip=172.28.0.12)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 374, in _ray_fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold,\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 703, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py\", line 156, in _fit\n",
            "    train_dataset, val_dataset = self.generate_datasets(X=X, y=y, params=params, X_val=X_val, y_val=y_val)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py\", line 446, in generate_datasets\n",
            "    train_dataset = self.process_train_data(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py\", line 511, in process_train_data\n",
            "    df = self.processor.fit_transform(df) # 2D numpy array\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n",
            "    data_to_wrap = f(self, X, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py\", line 727, in fit_transform\n",
            "    result = self._fit_transform(X, y, _fit_transform_one)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py\", line 658, in _fit_transform\n",
            "    return Parallel(n_jobs=self.n_jobs)(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\", line 63, in __call__\n",
            "    return super().__call__(iterable_with_config)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 1088, in __call__\n",
            "    while self.dispatch_one_batch(iterator):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 901, in dispatch_one_batch\n",
            "    self._dispatch(tasks)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 819, in _dispatch\n",
            "    job = self._backend.apply_async(batch, callback=cb)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
            "    result = ImmediateResult(func)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py\", line 597, in __init__\n",
            "    self.results = batch()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 288, in __call__\n",
            "    return [func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 288, in <listcomp>\n",
            "    return [func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\", line 123, in __call__\n",
            "    return self.function(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 893, in _fit_transform_one\n",
            "    res = transformer.fit_transform(X, y, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 437, in fit_transform\n",
            "    Xt = self._fit(X, y, **fit_params_steps)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 359, in _fit\n",
            "    X, fitted_transformer = fit_transform_one_cached(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/memory.py\", line 349, in __call__\n",
            "    return self.func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 893, in _fit_transform_one\n",
            "    res = transformer.fit_transform(X, y, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n",
            "    data_to_wrap = f(self, X, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/base.py\", line 878, in fit_transform\n",
            "    return self.fit(X, **fit_params).transform(X)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/impute/_base.py\", line 408, in fit\n",
            "    raise ValueError(\n",
            "ValueError: 'fill_value'=!missing! is invalid. Expected a numerical value when imputing numerical data\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
            "2023-06-06 19:23:12,151\tERROR worker.py:400 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
            "\u001b[36mray::_ray_fit()\u001b[39m (pid=20462, ip=172.28.0.12)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 374, in _ray_fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold,\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 703, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py\", line 156, in _fit\n",
            "    train_dataset, val_dataset = self.generate_datasets(X=X, y=y, params=params, X_val=X_val, y_val=y_val)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py\", line 446, in generate_datasets\n",
            "    train_dataset = self.process_train_data(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py\", line 511, in process_train_data\n",
            "    df = self.processor.fit_transform(df) # 2D numpy array\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n",
            "    data_to_wrap = f(self, X, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py\", line 727, in fit_transform\n",
            "    result = self._fit_transform(X, y, _fit_transform_one)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py\", line 658, in _fit_transform\n",
            "    return Parallel(n_jobs=self.n_jobs)(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\", line 63, in __call__\n",
            "    return super().__call__(iterable_with_config)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 1088, in __call__\n",
            "    while self.dispatch_one_batch(iterator):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 901, in dispatch_one_batch\n",
            "    self._dispatch(tasks)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 819, in _dispatch\n",
            "    job = self._backend.apply_async(batch, callback=cb)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
            "    result = ImmediateResult(func)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py\", line 597, in __init__\n",
            "    self.results = batch()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 288, in __call__\n",
            "    return [func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 288, in <listcomp>\n",
            "    return [func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\", line 123, in __call__\n",
            "    return self.function(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 893, in _fit_transform_one\n",
            "    res = transformer.fit_transform(X, y, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 437, in fit_transform\n",
            "    Xt = self._fit(X, y, **fit_params_steps)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 359, in _fit\n",
            "    X, fitted_transformer = fit_transform_one_cached(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/memory.py\", line 349, in __call__\n",
            "    return self.func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 893, in _fit_transform_one\n",
            "    res = transformer.fit_transform(X, y, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n",
            "    data_to_wrap = f(self, X, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/base.py\", line 878, in fit_transform\n",
            "    return self.fit(X, **fit_params).transform(X)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/impute/_base.py\", line 408, in fit\n",
            "    raise ValueError(\n",
            "ValueError: 'fill_value'=!missing! is invalid. Expected a numerical value when imputing numerical data\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 43, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 101, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 703, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 154, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 248, in _fit\n",
            "    self._fit_folds(X=X, y=y, model_base=model_base, X_pseudo=X_pseudo, y_pseudo=y_pseudo,\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 540, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 537, in after_all_folds_scheduled\n",
            "    raise processed_exception\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 505, in after_all_folds_scheduled\n",
            "    time_end_fit, predict_time, predict_1_time = self.ray.get(finished)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/client_mode_hook.py\", line 105, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/worker.py\", line 2309, in get\n",
            "    raise value.as_instanceof_cause()\n",
            "ray.exceptions.RayTaskError(ValueError): \u001b[36mray::_ray_fit()\u001b[39m (pid=20462, ip=172.28.0.12)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 374, in _ray_fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold,\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 703, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py\", line 156, in _fit\n",
            "    train_dataset, val_dataset = self.generate_datasets(X=X, y=y, params=params, X_val=X_val, y_val=y_val)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py\", line 446, in generate_datasets\n",
            "    train_dataset = self.process_train_data(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py\", line 511, in process_train_data\n",
            "    df = self.processor.fit_transform(df) # 2D numpy array\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n",
            "    data_to_wrap = f(self, X, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py\", line 727, in fit_transform\n",
            "    result = self._fit_transform(X, y, _fit_transform_one)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py\", line 658, in _fit_transform\n",
            "    return Parallel(n_jobs=self.n_jobs)(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\", line 63, in __call__\n",
            "    return super().__call__(iterable_with_config)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 1088, in __call__\n",
            "    while self.dispatch_one_batch(iterator):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 901, in dispatch_one_batch\n",
            "    self._dispatch(tasks)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 819, in _dispatch\n",
            "    job = self._backend.apply_async(batch, callback=cb)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
            "    result = ImmediateResult(func)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py\", line 597, in __init__\n",
            "    self.results = batch()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 288, in __call__\n",
            "    return [func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 288, in <listcomp>\n",
            "    return [func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\", line 123, in __call__\n",
            "    return self.function(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 893, in _fit_transform_one\n",
            "    res = transformer.fit_transform(X, y, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 437, in fit_transform\n",
            "    Xt = self._fit(X, y, **fit_params_steps)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 359, in _fit\n",
            "    X, fitted_transformer = fit_transform_one_cached(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/memory.py\", line 349, in __call__\n",
            "    return self.func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 893, in _fit_transform_one\n",
            "    res = transformer.fit_transform(X, y, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n",
            "    data_to_wrap = f(self, X, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/base.py\", line 878, in fit_transform\n",
            "    return self.fit(X, **fit_params).transform(X)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/impute/_base.py\", line 408, in fit\n",
            "    raise ValueError(\n",
            "ValueError: 'fill_value'=!missing! is invalid. Expected a numerical value when imputing numerical data\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
            "2023-06-06 19:23:24,538\tERROR worker.py:400 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
            "\u001b[36mray::_ray_fit()\u001b[39m (pid=20581, ip=172.28.0.12)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 374, in _ray_fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold,\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 703, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py\", line 156, in _fit\n",
            "    train_dataset, val_dataset = self.generate_datasets(X=X, y=y, params=params, X_val=X_val, y_val=y_val)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py\", line 446, in generate_datasets\n",
            "    train_dataset = self.process_train_data(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py\", line 511, in process_train_data\n",
            "    df = self.processor.fit_transform(df) # 2D numpy array\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n",
            "    data_to_wrap = f(self, X, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py\", line 727, in fit_transform\n",
            "    result = self._fit_transform(X, y, _fit_transform_one)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py\", line 658, in _fit_transform\n",
            "    return Parallel(n_jobs=self.n_jobs)(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\", line 63, in __call__\n",
            "    return super().__call__(iterable_with_config)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 1088, in __call__\n",
            "    while self.dispatch_one_batch(iterator):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 901, in dispatch_one_batch\n",
            "    self._dispatch(tasks)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 819, in _dispatch\n",
            "    job = self._backend.apply_async(batch, callback=cb)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
            "    result = ImmediateResult(func)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py\", line 597, in __init__\n",
            "    self.results = batch()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 288, in __call__\n",
            "    return [func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 288, in <listcomp>\n",
            "    return [func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\", line 123, in __call__\n",
            "    return self.function(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 893, in _fit_transform_one\n",
            "    res = transformer.fit_transform(X, y, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 437, in fit_transform\n",
            "    Xt = self._fit(X, y, **fit_params_steps)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 359, in _fit\n",
            "    X, fitted_transformer = fit_transform_one_cached(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/memory.py\", line 349, in __call__\n",
            "    return self.func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 893, in _fit_transform_one\n",
            "    res = transformer.fit_transform(X, y, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n",
            "    data_to_wrap = f(self, X, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/base.py\", line 878, in fit_transform\n",
            "    return self.fit(X, **fit_params).transform(X)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/impute/_base.py\", line 408, in fit\n",
            "    raise ValueError(\n",
            "ValueError: 'fill_value'=!missing! is invalid. Expected a numerical value when imputing numerical data\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 43, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 101, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 703, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 154, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 248, in _fit\n",
            "    self._fit_folds(X=X, y=y, model_base=model_base, X_pseudo=X_pseudo, y_pseudo=y_pseudo,\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 540, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 537, in after_all_folds_scheduled\n",
            "    raise processed_exception\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 505, in after_all_folds_scheduled\n",
            "    time_end_fit, predict_time, predict_1_time = self.ray.get(finished)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/client_mode_hook.py\", line 105, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/worker.py\", line 2309, in get\n",
            "    raise value.as_instanceof_cause()\n",
            "ray.exceptions.RayTaskError(ValueError): \u001b[36mray::_ray_fit()\u001b[39m (pid=20581, ip=172.28.0.12)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 374, in _ray_fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold,\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 703, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py\", line 156, in _fit\n",
            "    train_dataset, val_dataset = self.generate_datasets(X=X, y=y, params=params, X_val=X_val, y_val=y_val)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py\", line 446, in generate_datasets\n",
            "    train_dataset = self.process_train_data(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py\", line 511, in process_train_data\n",
            "    df = self.processor.fit_transform(df) # 2D numpy array\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n",
            "    data_to_wrap = f(self, X, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py\", line 727, in fit_transform\n",
            "    result = self._fit_transform(X, y, _fit_transform_one)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py\", line 658, in _fit_transform\n",
            "    return Parallel(n_jobs=self.n_jobs)(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\", line 63, in __call__\n",
            "    return super().__call__(iterable_with_config)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 1088, in __call__\n",
            "    while self.dispatch_one_batch(iterator):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 901, in dispatch_one_batch\n",
            "    self._dispatch(tasks)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 819, in _dispatch\n",
            "    job = self._backend.apply_async(batch, callback=cb)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
            "    result = ImmediateResult(func)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py\", line 597, in __init__\n",
            "    self.results = batch()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 288, in __call__\n",
            "    return [func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 288, in <listcomp>\n",
            "    return [func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\", line 123, in __call__\n",
            "    return self.function(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 893, in _fit_transform_one\n",
            "    res = transformer.fit_transform(X, y, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 437, in fit_transform\n",
            "    Xt = self._fit(X, y, **fit_params_steps)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 359, in _fit\n",
            "    X, fitted_transformer = fit_transform_one_cached(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/memory.py\", line 349, in __call__\n",
            "    return self.func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 893, in _fit_transform_one\n",
            "    res = transformer.fit_transform(X, y, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n",
            "    data_to_wrap = f(self, X, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/base.py\", line 878, in fit_transform\n",
            "    return self.fit(X, **fit_params).transform(X)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/impute/_base.py\", line 408, in fit\n",
            "    raise ValueError(\n",
            "ValueError: 'fill_value'=!missing! is invalid. Expected a numerical value when imputing numerical data\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
            "2023-06-06 19:23:32,705\tERROR worker.py:400 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
            "\u001b[36mray::_ray_fit()\u001b[39m (pid=20687, ip=172.28.0.12)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 374, in _ray_fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold,\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 703, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py\", line 156, in _fit\n",
            "    train_dataset, val_dataset = self.generate_datasets(X=X, y=y, params=params, X_val=X_val, y_val=y_val)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py\", line 446, in generate_datasets\n",
            "    train_dataset = self.process_train_data(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py\", line 511, in process_train_data\n",
            "    df = self.processor.fit_transform(df) # 2D numpy array\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n",
            "    data_to_wrap = f(self, X, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py\", line 727, in fit_transform\n",
            "    result = self._fit_transform(X, y, _fit_transform_one)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py\", line 658, in _fit_transform\n",
            "    return Parallel(n_jobs=self.n_jobs)(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\", line 63, in __call__\n",
            "    return super().__call__(iterable_with_config)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 1088, in __call__\n",
            "    while self.dispatch_one_batch(iterator):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 901, in dispatch_one_batch\n",
            "    self._dispatch(tasks)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 819, in _dispatch\n",
            "    job = self._backend.apply_async(batch, callback=cb)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
            "    result = ImmediateResult(func)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py\", line 597, in __init__\n",
            "    self.results = batch()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 288, in __call__\n",
            "    return [func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 288, in <listcomp>\n",
            "    return [func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\", line 123, in __call__\n",
            "    return self.function(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 893, in _fit_transform_one\n",
            "    res = transformer.fit_transform(X, y, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 437, in fit_transform\n",
            "    Xt = self._fit(X, y, **fit_params_steps)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 359, in _fit\n",
            "    X, fitted_transformer = fit_transform_one_cached(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/memory.py\", line 349, in __call__\n",
            "    return self.func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 893, in _fit_transform_one\n",
            "    res = transformer.fit_transform(X, y, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n",
            "    data_to_wrap = f(self, X, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/base.py\", line 878, in fit_transform\n",
            "    return self.fit(X, **fit_params).transform(X)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/impute/_base.py\", line 408, in fit\n",
            "    raise ValueError(\n",
            "ValueError: 'fill_value'=!missing! is invalid. Expected a numerical value when imputing numerical data\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 43, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 101, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 703, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 154, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 248, in _fit\n",
            "    self._fit_folds(X=X, y=y, model_base=model_base, X_pseudo=X_pseudo, y_pseudo=y_pseudo,\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 540, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 537, in after_all_folds_scheduled\n",
            "    raise processed_exception\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 505, in after_all_folds_scheduled\n",
            "    time_end_fit, predict_time, predict_1_time = self.ray.get(finished)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/client_mode_hook.py\", line 105, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/worker.py\", line 2309, in get\n",
            "    raise value.as_instanceof_cause()\n",
            "ray.exceptions.RayTaskError(ValueError): \u001b[36mray::_ray_fit()\u001b[39m (pid=20687, ip=172.28.0.12)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 374, in _ray_fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold,\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 703, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py\", line 156, in _fit\n",
            "    train_dataset, val_dataset = self.generate_datasets(X=X, y=y, params=params, X_val=X_val, y_val=y_val)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py\", line 446, in generate_datasets\n",
            "    train_dataset = self.process_train_data(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py\", line 511, in process_train_data\n",
            "    df = self.processor.fit_transform(df) # 2D numpy array\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n",
            "    data_to_wrap = f(self, X, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py\", line 727, in fit_transform\n",
            "    result = self._fit_transform(X, y, _fit_transform_one)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py\", line 658, in _fit_transform\n",
            "    return Parallel(n_jobs=self.n_jobs)(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\", line 63, in __call__\n",
            "    return super().__call__(iterable_with_config)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 1088, in __call__\n",
            "    while self.dispatch_one_batch(iterator):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 901, in dispatch_one_batch\n",
            "    self._dispatch(tasks)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 819, in _dispatch\n",
            "    job = self._backend.apply_async(batch, callback=cb)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
            "    result = ImmediateResult(func)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py\", line 597, in __init__\n",
            "    self.results = batch()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 288, in __call__\n",
            "    return [func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 288, in <listcomp>\n",
            "    return [func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\", line 123, in __call__\n",
            "    return self.function(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 893, in _fit_transform_one\n",
            "    res = transformer.fit_transform(X, y, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 437, in fit_transform\n",
            "    Xt = self._fit(X, y, **fit_params_steps)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 359, in _fit\n",
            "    X, fitted_transformer = fit_transform_one_cached(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/memory.py\", line 349, in __call__\n",
            "    return self.func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 893, in _fit_transform_one\n",
            "    res = transformer.fit_transform(X, y, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n",
            "    data_to_wrap = f(self, X, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/base.py\", line 878, in fit_transform\n",
            "    return self.fit(X, **fit_params).transform(X)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/impute/_base.py\", line 408, in fit\n",
            "    raise ValueError(\n",
            "ValueError: 'fill_value'=!missing! is invalid. Expected a numerical value when imputing numerical data\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
            "2023-06-06 19:23:45,750\tERROR worker.py:400 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
            "\u001b[36mray::_ray_fit()\u001b[39m (pid=20835, ip=172.28.0.12)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 374, in _ray_fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold,\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 703, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py\", line 156, in _fit\n",
            "    train_dataset, val_dataset = self.generate_datasets(X=X, y=y, params=params, X_val=X_val, y_val=y_val)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py\", line 446, in generate_datasets\n",
            "    train_dataset = self.process_train_data(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py\", line 511, in process_train_data\n",
            "    df = self.processor.fit_transform(df) # 2D numpy array\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n",
            "    data_to_wrap = f(self, X, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py\", line 727, in fit_transform\n",
            "    result = self._fit_transform(X, y, _fit_transform_one)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py\", line 658, in _fit_transform\n",
            "    return Parallel(n_jobs=self.n_jobs)(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\", line 63, in __call__\n",
            "    return super().__call__(iterable_with_config)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 1088, in __call__\n",
            "    while self.dispatch_one_batch(iterator):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 901, in dispatch_one_batch\n",
            "    self._dispatch(tasks)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 819, in _dispatch\n",
            "    job = self._backend.apply_async(batch, callback=cb)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
            "    result = ImmediateResult(func)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py\", line 597, in __init__\n",
            "    self.results = batch()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 288, in __call__\n",
            "    return [func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 288, in <listcomp>\n",
            "    return [func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\", line 123, in __call__\n",
            "    return self.function(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 893, in _fit_transform_one\n",
            "    res = transformer.fit_transform(X, y, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 437, in fit_transform\n",
            "    Xt = self._fit(X, y, **fit_params_steps)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 359, in _fit\n",
            "    X, fitted_transformer = fit_transform_one_cached(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/memory.py\", line 349, in __call__\n",
            "    return self.func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 893, in _fit_transform_one\n",
            "    res = transformer.fit_transform(X, y, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n",
            "    data_to_wrap = f(self, X, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/base.py\", line 878, in fit_transform\n",
            "    return self.fit(X, **fit_params).transform(X)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/impute/_base.py\", line 408, in fit\n",
            "    raise ValueError(\n",
            "ValueError: 'fill_value'=!missing! is invalid. Expected a numerical value when imputing numerical data\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 43, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 101, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 703, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 154, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 248, in _fit\n",
            "    self._fit_folds(X=X, y=y, model_base=model_base, X_pseudo=X_pseudo, y_pseudo=y_pseudo,\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 540, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 537, in after_all_folds_scheduled\n",
            "    raise processed_exception\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 505, in after_all_folds_scheduled\n",
            "    time_end_fit, predict_time, predict_1_time = self.ray.get(finished)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/client_mode_hook.py\", line 105, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/worker.py\", line 2309, in get\n",
            "    raise value.as_instanceof_cause()\n",
            "ray.exceptions.RayTaskError(ValueError): \u001b[36mray::_ray_fit()\u001b[39m (pid=20835, ip=172.28.0.12)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 374, in _ray_fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold,\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 703, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py\", line 156, in _fit\n",
            "    train_dataset, val_dataset = self.generate_datasets(X=X, y=y, params=params, X_val=X_val, y_val=y_val)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py\", line 446, in generate_datasets\n",
            "    train_dataset = self.process_train_data(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py\", line 511, in process_train_data\n",
            "    df = self.processor.fit_transform(df) # 2D numpy array\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n",
            "    data_to_wrap = f(self, X, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py\", line 727, in fit_transform\n",
            "    result = self._fit_transform(X, y, _fit_transform_one)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py\", line 658, in _fit_transform\n",
            "    return Parallel(n_jobs=self.n_jobs)(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\", line 63, in __call__\n",
            "    return super().__call__(iterable_with_config)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 1088, in __call__\n",
            "    while self.dispatch_one_batch(iterator):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 901, in dispatch_one_batch\n",
            "    self._dispatch(tasks)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 819, in _dispatch\n",
            "    job = self._backend.apply_async(batch, callback=cb)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
            "    result = ImmediateResult(func)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py\", line 597, in __init__\n",
            "    self.results = batch()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 288, in __call__\n",
            "    return [func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 288, in <listcomp>\n",
            "    return [func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\", line 123, in __call__\n",
            "    return self.function(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 893, in _fit_transform_one\n",
            "    res = transformer.fit_transform(X, y, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 437, in fit_transform\n",
            "    Xt = self._fit(X, y, **fit_params_steps)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 359, in _fit\n",
            "    X, fitted_transformer = fit_transform_one_cached(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/memory.py\", line 349, in __call__\n",
            "    return self.func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 893, in _fit_transform_one\n",
            "    res = transformer.fit_transform(X, y, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n",
            "    data_to_wrap = f(self, X, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/base.py\", line 878, in fit_transform\n",
            "    return self.fit(X, **fit_params).transform(X)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/impute/_base.py\", line 408, in fit\n",
            "    raise ValueError(\n",
            "ValueError: 'fill_value'=!missing! is invalid. Expected a numerical value when imputing numerical data\n",
            "\tStopping HPO to satisfy time limit...\n",
            "No model was trained during hyperparameter tuning NeuralNetMXNet_BAG_L2... Skipping this model.\n",
            "Completed 1/20 k-fold bagging repeats ...\n",
            "Fitting model: WeightedEnsemble_L3 ... Training model for up to 360.0s of the 47.57s of remaining time.\n",
            "2023-06-06 19:23:53,377\tERROR worker.py:400 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
            "\t-34.7408\t = Validation score   (-root_mean_squared_error)\n",
            "\t1.05s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "AutoGluon training complete, total runtime = 553.61s ... Best model: \"WeightedEnsemble_L2\"\n",
            "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20230606_191440/\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gci9lpixrRm2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b0e39b76-f48f-44c8-8888-3874eec02de6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "*** Summary of fit() ***\n",
            "Estimated performance of each model:\n",
            "                  model   score_val  pred_time_val    fit_time  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
            "0   WeightedEnsemble_L2  -34.113075       0.009124  105.219887                0.008675           0.891977            2       True          7\n",
            "1   WeightedEnsemble_L3  -34.740845       0.002690  334.444297                0.001318           1.054467            3       True         12\n",
            "2     XGBoost_BAG_L2/T1  -34.919996       0.001061  241.173288                0.000142          29.991919            2       True         10\n",
            "3     XGBoost_BAG_L1/T3  -35.126929       0.000157   33.366094                0.000157          33.366094            1       True          6\n",
            "4     XGBoost_BAG_L1/T2  -35.251587       0.000150   44.253452                0.000150          44.253452            1       True          5\n",
            "5     XGBoost_BAG_L2/T2  -35.259903       0.001079  260.965571                0.000160          49.784202            2       True         11\n",
            "6    LightGBM_BAG_L2/T2  -37.474375       0.001070  253.613709                0.000150          42.432340            2       True          9\n",
            "7     XGBoost_BAG_L1/T1  -38.069996       0.000141   26.708365                0.000141          26.708365            1       True          4\n",
            "8    LightGBM_BAG_L1/T2  -82.913154       0.000151   37.917373                0.000151          37.917373            1       True          2\n",
            "9    LightGBM_BAG_L1/T3  -96.446408       0.000149   36.735491                0.000149          36.735491            1       True          3\n",
            "10   LightGBM_BAG_L2/T1 -165.328027       0.001081  241.462192                0.000162          30.280823            2       True          8\n",
            "11   LightGBM_BAG_L1/T1 -171.445452       0.000170   32.200594                0.000170          32.200594            1       True          1\n",
            "Number of models trained: 12\n",
            "Types of models trained:\n",
            "{'StackerEnsembleModel_LGB', 'StackerEnsembleModel_XGBoost', 'WeightedEnsembleModel'}\n",
            "Bagging used: True  (with 8 folds)\n",
            "Multi-layer stack-ensembling used: True  (with 3 levels)\n",
            "Feature Metadata (Processed):\n",
            "(raw dtype, special dtypes):\n",
            "('category', [])             : 2 | ['season', 'weather']\n",
            "('float', [])                : 3 | ['temp', 'atemp', 'windspeed']\n",
            "('int', [])                  : 4 | ['humidity', 'Month', 'Day', 'Hour']\n",
            "('int', ['bool'])            : 3 | ['holiday', 'workingday', 'Year']\n",
            "('int', ['datetime_as_int']) : 5 | ['datetime', 'datetime.year', 'datetime.month', 'datetime.day', 'datetime.dayofweek']\n",
            "*** End of fit() summary ***\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/autogluon/core/utils/plots.py:138: UserWarning: AutoGluon summary plots cannot be created because bokeh is not installed. To see plots, please do: \"pip install bokeh==2.0.1\"\n",
            "  warnings.warn('AutoGluon summary plots cannot be created because bokeh is not installed. To see plots, please do: \"pip install bokeh==2.0.1\"')\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'model_types': {'LightGBM_BAG_L1/T1': 'StackerEnsembleModel_LGB',\n",
              "  'LightGBM_BAG_L1/T2': 'StackerEnsembleModel_LGB',\n",
              "  'LightGBM_BAG_L1/T3': 'StackerEnsembleModel_LGB',\n",
              "  'XGBoost_BAG_L1/T1': 'StackerEnsembleModel_XGBoost',\n",
              "  'XGBoost_BAG_L1/T2': 'StackerEnsembleModel_XGBoost',\n",
              "  'XGBoost_BAG_L1/T3': 'StackerEnsembleModel_XGBoost',\n",
              "  'WeightedEnsemble_L2': 'WeightedEnsembleModel',\n",
              "  'LightGBM_BAG_L2/T1': 'StackerEnsembleModel_LGB',\n",
              "  'LightGBM_BAG_L2/T2': 'StackerEnsembleModel_LGB',\n",
              "  'XGBoost_BAG_L2/T1': 'StackerEnsembleModel_XGBoost',\n",
              "  'XGBoost_BAG_L2/T2': 'StackerEnsembleModel_XGBoost',\n",
              "  'WeightedEnsemble_L3': 'WeightedEnsembleModel'},\n",
              " 'model_performance': {'LightGBM_BAG_L1/T1': -171.4454523315753,\n",
              "  'LightGBM_BAG_L1/T2': -82.91315413120766,\n",
              "  'LightGBM_BAG_L1/T3': -96.44640803546979,\n",
              "  'XGBoost_BAG_L1/T1': -38.06999646985297,\n",
              "  'XGBoost_BAG_L1/T2': -35.251587056993216,\n",
              "  'XGBoost_BAG_L1/T3': -35.12692862393618,\n",
              "  'WeightedEnsemble_L2': -34.11307533514884,\n",
              "  'LightGBM_BAG_L2/T1': -165.32802656358766,\n",
              "  'LightGBM_BAG_L2/T2': -37.47437498114119,\n",
              "  'XGBoost_BAG_L2/T1': -34.91999649934038,\n",
              "  'XGBoost_BAG_L2/T2': -35.25990315669487,\n",
              "  'WeightedEnsemble_L3': -34.74084477271918},\n",
              " 'model_best': 'WeightedEnsemble_L2',\n",
              " 'model_paths': {'LightGBM_BAG_L1/T1': '/content/AutogluonModels/ag-20230606_191440/models/LightGBM_BAG_L1/T1/',\n",
              "  'LightGBM_BAG_L1/T2': '/content/AutogluonModels/ag-20230606_191440/models/LightGBM_BAG_L1/T2/',\n",
              "  'LightGBM_BAG_L1/T3': '/content/AutogluonModels/ag-20230606_191440/models/LightGBM_BAG_L1/T3/',\n",
              "  'XGBoost_BAG_L1/T1': '/content/AutogluonModels/ag-20230606_191440/models/XGBoost_BAG_L1/T1/',\n",
              "  'XGBoost_BAG_L1/T2': '/content/AutogluonModels/ag-20230606_191440/models/XGBoost_BAG_L1/T2/',\n",
              "  'XGBoost_BAG_L1/T3': '/content/AutogluonModels/ag-20230606_191440/models/XGBoost_BAG_L1/T3/',\n",
              "  'WeightedEnsemble_L2': 'AutogluonModels/ag-20230606_191440/models/WeightedEnsemble_L2/',\n",
              "  'LightGBM_BAG_L2/T1': '/content/AutogluonModels/ag-20230606_191440/models/LightGBM_BAG_L2/T1/',\n",
              "  'LightGBM_BAG_L2/T2': '/content/AutogluonModels/ag-20230606_191440/models/LightGBM_BAG_L2/T2/',\n",
              "  'XGBoost_BAG_L2/T1': '/content/AutogluonModels/ag-20230606_191440/models/XGBoost_BAG_L2/T1/',\n",
              "  'XGBoost_BAG_L2/T2': '/content/AutogluonModels/ag-20230606_191440/models/XGBoost_BAG_L2/T2/',\n",
              "  'WeightedEnsemble_L3': 'AutogluonModels/ag-20230606_191440/models/WeightedEnsemble_L3/'},\n",
              " 'model_fit_times': {'LightGBM_BAG_L1/T1': 32.20059418678284,\n",
              "  'LightGBM_BAG_L1/T2': 37.917373180389404,\n",
              "  'LightGBM_BAG_L1/T3': 36.73549127578735,\n",
              "  'XGBoost_BAG_L1/T1': 26.708364725112915,\n",
              "  'XGBoost_BAG_L1/T2': 44.25345182418823,\n",
              "  'XGBoost_BAG_L1/T3': 33.36609363555908,\n",
              "  'WeightedEnsemble_L2': 0.8919768333435059,\n",
              "  'LightGBM_BAG_L2/T1': 30.280823230743408,\n",
              "  'LightGBM_BAG_L2/T2': 42.432339906692505,\n",
              "  'XGBoost_BAG_L2/T1': 29.99191904067993,\n",
              "  'XGBoost_BAG_L2/T2': 49.784201860427856,\n",
              "  'WeightedEnsemble_L3': 1.0544672012329102},\n",
              " 'model_pred_times': {'LightGBM_BAG_L1/T1': 0.00016999244689941406,\n",
              "  'LightGBM_BAG_L1/T2': 0.0001513957977294922,\n",
              "  'LightGBM_BAG_L1/T3': 0.00014925003051757812,\n",
              "  'XGBoost_BAG_L1/T1': 0.00014138221740722656,\n",
              "  'XGBoost_BAG_L1/T2': 0.00015044212341308594,\n",
              "  'XGBoost_BAG_L1/T3': 0.0001571178436279297,\n",
              "  'WeightedEnsemble_L2': 0.00867462158203125,\n",
              "  'LightGBM_BAG_L2/T1': 0.00016188621520996094,\n",
              "  'LightGBM_BAG_L2/T2': 0.00015044212341308594,\n",
              "  'XGBoost_BAG_L2/T1': 0.00014162063598632812,\n",
              "  'XGBoost_BAG_L2/T2': 0.00015974044799804688,\n",
              "  'WeightedEnsemble_L3': 0.0013184547424316406},\n",
              " 'num_bag_folds': 8,\n",
              " 'max_stack_level': 3,\n",
              " 'model_hyperparams': {'LightGBM_BAG_L1/T1': {'use_orig_features': True,\n",
              "   'max_base_models': 25,\n",
              "   'max_base_models_per_type': 5,\n",
              "   'save_bag_folds': True},\n",
              "  'LightGBM_BAG_L1/T2': {'use_orig_features': True,\n",
              "   'max_base_models': 25,\n",
              "   'max_base_models_per_type': 5,\n",
              "   'save_bag_folds': True},\n",
              "  'LightGBM_BAG_L1/T3': {'use_orig_features': True,\n",
              "   'max_base_models': 25,\n",
              "   'max_base_models_per_type': 5,\n",
              "   'save_bag_folds': True},\n",
              "  'XGBoost_BAG_L1/T1': {'use_orig_features': True,\n",
              "   'max_base_models': 25,\n",
              "   'max_base_models_per_type': 5,\n",
              "   'save_bag_folds': True},\n",
              "  'XGBoost_BAG_L1/T2': {'use_orig_features': True,\n",
              "   'max_base_models': 25,\n",
              "   'max_base_models_per_type': 5,\n",
              "   'save_bag_folds': True},\n",
              "  'XGBoost_BAG_L1/T3': {'use_orig_features': True,\n",
              "   'max_base_models': 25,\n",
              "   'max_base_models_per_type': 5,\n",
              "   'save_bag_folds': True},\n",
              "  'WeightedEnsemble_L2': {'use_orig_features': False,\n",
              "   'max_base_models': 25,\n",
              "   'max_base_models_per_type': 5,\n",
              "   'save_bag_folds': True},\n",
              "  'LightGBM_BAG_L2/T1': {'use_orig_features': True,\n",
              "   'max_base_models': 25,\n",
              "   'max_base_models_per_type': 5,\n",
              "   'save_bag_folds': True},\n",
              "  'LightGBM_BAG_L2/T2': {'use_orig_features': True,\n",
              "   'max_base_models': 25,\n",
              "   'max_base_models_per_type': 5,\n",
              "   'save_bag_folds': True},\n",
              "  'XGBoost_BAG_L2/T1': {'use_orig_features': True,\n",
              "   'max_base_models': 25,\n",
              "   'max_base_models_per_type': 5,\n",
              "   'save_bag_folds': True},\n",
              "  'XGBoost_BAG_L2/T2': {'use_orig_features': True,\n",
              "   'max_base_models': 25,\n",
              "   'max_base_models_per_type': 5,\n",
              "   'save_bag_folds': True},\n",
              "  'WeightedEnsemble_L3': {'use_orig_features': False,\n",
              "   'max_base_models': 25,\n",
              "   'max_base_models_per_type': 5,\n",
              "   'save_bag_folds': True}},\n",
              " 'leaderboard':                   model   score_val  pred_time_val    fit_time  \\\n",
              " 0   WeightedEnsemble_L2  -34.113075       0.009124  105.219887   \n",
              " 1   WeightedEnsemble_L3  -34.740845       0.002690  334.444297   \n",
              " 2     XGBoost_BAG_L2/T1  -34.919996       0.001061  241.173288   \n",
              " 3     XGBoost_BAG_L1/T3  -35.126929       0.000157   33.366094   \n",
              " 4     XGBoost_BAG_L1/T2  -35.251587       0.000150   44.253452   \n",
              " 5     XGBoost_BAG_L2/T2  -35.259903       0.001079  260.965571   \n",
              " 6    LightGBM_BAG_L2/T2  -37.474375       0.001070  253.613709   \n",
              " 7     XGBoost_BAG_L1/T1  -38.069996       0.000141   26.708365   \n",
              " 8    LightGBM_BAG_L1/T2  -82.913154       0.000151   37.917373   \n",
              " 9    LightGBM_BAG_L1/T3  -96.446408       0.000149   36.735491   \n",
              " 10   LightGBM_BAG_L2/T1 -165.328027       0.001081  241.462192   \n",
              " 11   LightGBM_BAG_L1/T1 -171.445452       0.000170   32.200594   \n",
              " \n",
              "     pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  \\\n",
              " 0                 0.008675           0.891977            2       True   \n",
              " 1                 0.001318           1.054467            3       True   \n",
              " 2                 0.000142          29.991919            2       True   \n",
              " 3                 0.000157          33.366094            1       True   \n",
              " 4                 0.000150          44.253452            1       True   \n",
              " 5                 0.000160          49.784202            2       True   \n",
              " 6                 0.000150          42.432340            2       True   \n",
              " 7                 0.000141          26.708365            1       True   \n",
              " 8                 0.000151          37.917373            1       True   \n",
              " 9                 0.000149          36.735491            1       True   \n",
              " 10                0.000162          30.280823            2       True   \n",
              " 11                0.000170          32.200594            1       True   \n",
              " \n",
              "     fit_order  \n",
              " 0           7  \n",
              " 1          12  \n",
              " 2          10  \n",
              " 3           6  \n",
              " 4           5  \n",
              " 5          11  \n",
              " 6           9  \n",
              " 7           4  \n",
              " 8           2  \n",
              " 9           3  \n",
              " 10          8  \n",
              " 11          1  }"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ],
      "source": [
        "predictor_new_hpo.fit_summary()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions_new_hpo = predictor_new_hpo.predict(test)"
      ],
      "metadata": {
        "id": "4p8aqGzgnHE3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions_new_hpo.describe()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RT-ck-c-m3Zc",
        "outputId": "c52702a6-1b6f-49a1-f2f3-6d4618226457"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "count    6493.000000\n",
              "mean      191.010391\n",
              "std       171.119354\n",
              "min       -13.591940\n",
              "25%        48.059174\n",
              "50%       150.577164\n",
              "75%       283.495392\n",
              "max       888.849487\n",
              "Name: count, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ztlxm_XwrRm2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1474fc6e-928c-43c1-a604-eab97b9cf05f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        }
      ],
      "source": [
        "# Remember to set all negative values to zero\n",
        "num_negative_values_new_hpo = (predictions_new_hpo < 0).sum().sum()\n",
        "print(num_negative_values_new)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions_new_hpo[predictions_new_hpo < 0] = 0"
      ],
      "metadata": {
        "id": "1PXZ0be7n0tF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B1EKML74rRm2"
      },
      "outputs": [],
      "source": [
        "# Same submitting predictions\n",
        "submission_new_hpo = pd.DataFrame()\n",
        "submission_new_hpo['datetime'] = test['datetime']\n",
        "submission_new_hpo[\"count\"] = predictions_new_hpo\n",
        "submission_new_hpo.to_csv(\"submission_new_hpo.csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WFRtkrRSrRm2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0acfab74-8ea4-438d-9b8f-6b0e32928c15"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100% 188k/188k [00:03<00:00, 60.5kB/s]\n",
            "Successfully submitted to Bike Sharing Demand"
          ]
        }
      ],
      "source": [
        "!kaggle competitions submit -c bike-sharing-demand -f submission_new_hpo.csv -m \"new features with hyperparameters\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KdSXtClIrRm2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9a079359-f929-463d-fd67-f6a1e01d503a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fileName                     date                 description                        status    publicScore  privateScore  \n",
            "---------------------------  -------------------  ---------------------------------  --------  -----------  ------------  \n",
            "submission_new_hpo.csv       2023-06-06 19:25:32  new features with hyperparameters  complete  0.55740      0.55740       \n",
            "submission_new_features.csv  2023-06-06 19:14:26  new features                       complete  0.62040      0.62040       \n",
            "submission.csv               2023-06-06 19:00:16  first raw submission               complete  1.80288      1.80288       \n",
            "submission_new_hpo.csv       2023-06-06 17:53:05  new features with hyperparameters  complete  0.55740      0.55740       \n"
          ]
        }
      ],
      "source": [
        "!kaggle competitions submissions -c bike-sharing-demand | tail -n +1 | head -n 6"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BgmzuojWrRm3"
      },
      "source": [
        "#### New Score of `0.55740`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7OiV2OSerRm3"
      },
      "source": [
        "## Step 7: Write a Report\n",
        "### Refer to the markdown file for the full report\n",
        "### Creating plots and table for report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": true
        },
        "id": "0AnKoSdDrRm3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "outputId": "3abe099e-6658-45ce-eb46-fd3bde187fb3"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Taking the top model score from each training run and creating a line plot to show improvement\n",
        "# You can create these in the notebook and save them to PNG or use some other tool (e.g. google sheets, excel)\n",
        "fig = pd.DataFrame(\n",
        "    {\n",
        "        \"model\": [\"initial\", \"add_features\", \"hpo\"],\n",
        "        \"score\": [-53.118942, -30.335978 , -34.113075 ]\n",
        "    }\n",
        ").plot(x=\"model\", y=\"score\", figsize=(8, 6)).get_figure()\n",
        "fig.savefig('model_train_score.png')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lZoKx9C7rRm3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "outputId": "a06391bd-38dd-454e-d626-167253e54f44"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Take the 3 kaggle scores and creating a line plot to show improvement\n",
        "fig = pd.DataFrame(\n",
        "    {\n",
        "        \"test_eval\": [\"initial\", \"add_features\", \"hpo\"],\n",
        "        \"score\": [1.80288,0.62040,0.55740]\n",
        "    }\n",
        ").plot(x=\"test_eval\", y=\"score\", figsize=(8, 6)).get_figure()\n",
        "fig.savefig('model_test_score.png')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q1H0sY3crRm3"
      },
      "source": [
        "### Hyperparameter table"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pSaG3xxTrRm3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 257
        },
        "outputId": "ce0e8781-2438-41f9-e10b-5c2cae3b083f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "          model  \\\n",
              "0       initial   \n",
              "1  add_features   \n",
              "2           hpo   \n",
              "\n",
              "                                                                                                                                                        hpo1  \\\n",
              "0                                                                                                                                               default_vals   \n",
              "1                                                                                                                                               default_vals   \n",
              "2  GBM (Light gradient boosting) : num_boost_round: [lower=100, upper=500], num_leaves:[lower=6, upper=10], learning_rate:[lower=0.01, upper=0.3, log scale]   \n",
              "\n",
              "                                                                                                                                              hpo2  \\\n",
              "0                                                                                                                                     default_vals   \n",
              "1                                                                                                                                     default_vals   \n",
              "2  XGB (XGBoost): n_estimators : [lower=100, upper=500], max_depth : [lower=6, upper=10], eta (learning_rate) : [lower=0.01, upper=0.3, log scale]   \n",
              "\n",
              "                                                                                                                                                                                   hpo3  \\\n",
              "0                                                                                                                                                                          default_vals   \n",
              "1                                                                                                                                                                          default_vals   \n",
              "2  NN (neural network) = num_epochs: 10,layers:([100], [1000], [200, 100], [300, 200, 100]),learning_rate:[lower=0.0001,upper=0.01],dropout_prob:[0.0, 0.5],activation_fun:[relu, tanh]   \n",
              "\n",
              "     score  \n",
              "0  1.79594  \n",
              "1  0.63634  \n",
              "2  0.55740  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d349be3f-2058-46f7-8362-e09abe8669cb\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>model</th>\n",
              "      <th>hpo1</th>\n",
              "      <th>hpo2</th>\n",
              "      <th>hpo3</th>\n",
              "      <th>score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>initial</td>\n",
              "      <td>default_vals</td>\n",
              "      <td>default_vals</td>\n",
              "      <td>default_vals</td>\n",
              "      <td>1.79594</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>add_features</td>\n",
              "      <td>default_vals</td>\n",
              "      <td>default_vals</td>\n",
              "      <td>default_vals</td>\n",
              "      <td>0.63634</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>hpo</td>\n",
              "      <td>GBM (Light gradient boosting) : num_boost_round: [lower=100, upper=500], num_leaves:[lower=6, upper=10], learning_rate:[lower=0.01, upper=0.3, log scale]</td>\n",
              "      <td>XGB (XGBoost): n_estimators : [lower=100, upper=500], max_depth : [lower=6, upper=10], eta (learning_rate) : [lower=0.01, upper=0.3, log scale]</td>\n",
              "      <td>NN (neural network) = num_epochs: 10,layers:([100], [1000], [200, 100], [300, 200, 100]),learning_rate:[lower=0.0001,upper=0.01],dropout_prob:[0.0, 0.5],activation_fun:[relu, tanh]</td>\n",
              "      <td>0.55740</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d349be3f-2058-46f7-8362-e09abe8669cb')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d349be3f-2058-46f7-8362-e09abe8669cb button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d349be3f-2058-46f7-8362-e09abe8669cb');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ],
      "source": [
        "# The 3 hyperparameters we tuned with the kaggle score as the result\n",
        "table_df = pd.DataFrame({\n",
        "    \"model\": [\"initial\", \"add_features\", \"hpo\"],\n",
        "    \"hpo1\": [\n",
        "        'default_vals',\n",
        "        'default_vals',\n",
        "        'GBM (Light gradient boosting) : num_boost_round: [lower=100, upper=500], num_leaves:[lower=6, upper=10], learning_rate:[lower=0.01, upper=0.3, log scale]'\n",
        "    ],\n",
        "    \"hpo2\": [\n",
        "        'default_vals',\n",
        "        'default_vals',\n",
        "        'XGB (XGBoost): n_estimators : [lower=100, upper=500], max_depth : [lower=6, upper=10], eta (learning_rate) : [lower=0.01, upper=0.3, log scale]'\n",
        "    ],\n",
        "    \"hpo3\": [\n",
        "        'default_vals',\n",
        "        'default_vals',\n",
        "        'NN (neural network) = num_epochs: 10,layers:([100], [1000], [200, 100], [300, 200, 100]),learning_rate:[lower=0.0001,upper=0.01],dropout_prob:[0.0, 0.5],activation_fun:[relu, tanh]'\n",
        "    ],\n",
        "    \"score\": [1.80288,0.62040,0.55740]\n",
        "})\n",
        "\n",
        "table_df\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.9"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}